2025-03-17 18:42:13,394 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:42:15,941 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 18:49:09,534 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:10,365 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:10,390 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:11,082 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:11,126 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:13,745 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 18:49:14,077 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:14,776 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:14,789 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:15,588 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:15,600 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:16,311 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:16,329 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:17,226 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:17,242 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:17,922 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:17,935 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:18,569 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:18,582 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:20,174 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerShifting HTTP/1.1" 200 None
2025-03-17 18:49:20,195 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:21,145 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=PTI HTTP/1.1" 200 None
2025-03-17 18:49:21,327 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:22,146 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerCleaning HTTP/1.1" 200 None
2025-03-17 18:49:22,158 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:22,970 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Client HTTP/1.1" 200 None
2025-03-17 18:49:22,996 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:23,694 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:23,701 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:24,927 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:24,936 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:25,618 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:25,655 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:26,637 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:26,653 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:27,372 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:27,398 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:28,195 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:28,219 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:28,862 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:49:28,889 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:30,423 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 18:49:30,676 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:31,655 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 18:49:31,804 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:32,609 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 18:49:32,915 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:33,817 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 18:49:33,909 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:34,532 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CrossStuffing HTTP/1.1" 200 None
2025-03-17 18:49:34,589 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:35,454 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 18:49:35,549 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:36,171 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 18:49:36,198 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:36,888 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 18:49:36,913 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:37,571 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 18:49:37,598 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:49:38,322 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSContainerStuffing HTTP/1.1" 200 None
2025-03-17 18:58:12,161 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:13,097 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:13,137 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:13,813 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:13,858 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:16,477 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 18:58:16,809 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:17,505 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:17,516 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:18,217 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:18,230 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:18,833 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:18,848 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:19,548 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:19,560 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:20,265 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:20,293 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:20,982 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:20,995 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:22,313 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerShifting HTTP/1.1" 200 None
2025-03-17 18:58:22,343 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:23,747 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=PTI HTTP/1.1" 200 None
2025-03-17 18:58:23,911 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:24,668 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerCleaning HTTP/1.1" 200 None
2025-03-17 18:58:24,677 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:25,386 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Client HTTP/1.1" 200 None
2025-03-17 18:58:25,402 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:26,102 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:26,125 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:26,819 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:26,833 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:27,433 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:27,462 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:28,150 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:28,164 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:28,855 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:28,876 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:29,481 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:29,495 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:30,197 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:30,210 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:31,531 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 18:58:31,688 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:32,554 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 18:58:32,646 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:33,475 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 18:58:33,636 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:34,442 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 18:58:34,659 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:35,421 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CrossStuffing HTTP/1.1" 200 None
2025-03-17 18:58:35,451 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:36,343 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 18:58:36,523 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:37,264 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 18:58:37,286 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:37,982 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 18:58:38,018 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:38,699 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 18:58:38,729 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:39,415 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSContainerStuffing HTTP/1.1" 200 None
2025-03-17 18:58:39,481 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:40,136 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:40,169 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:40,849 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:40,863 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:41,463 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:41,479 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:42,180 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:42,198 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:42,897 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:42,913 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:43,613 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:43,640 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:44,434 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:44,460 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:45,149 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 18:58:45,173 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:45,867 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=LinerPallet HTTP/1.1" 200 None
2025-03-17 18:58:45,914 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 18:58:46,993 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=containerOperations HTTP/1.1" 200 None
2025-03-17 19:02:04,561 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:05,363 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:05,376 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:05,977 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:05,999 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:07,002 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:02:07,229 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:07,923 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:07,936 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:08,640 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:08,653 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:09,254 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:09,268 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:09,971 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:09,984 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:10,688 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:10,700 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:11,407 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:11,421 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:12,232 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerShifting HTTP/1.1" 200 None
2025-03-17 19:02:12,243 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:13,248 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=PTI HTTP/1.1" 200 None
2025-03-17 19:02:13,552 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:14,169 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerCleaning HTTP/1.1" 200 None
2025-03-17 19:02:14,184 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:14,858 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Client HTTP/1.1" 200 None
2025-03-17 19:02:14,883 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:16,217 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:16,225 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:16,831 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:16,843 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:17,548 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:17,562 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:18,163 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:18,185 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:18,849 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:18,868 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:19,499 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:19,509 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:20,109 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:20,123 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:20,930 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:02:21,200 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:21,962 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:02:22,174 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:23,091 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:02:23,328 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:24,207 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:02:24,367 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:25,231 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CrossStuffing HTTP/1.1" 200 None
2025-03-17 19:02:25,266 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:26,153 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:02:26,567 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:27,279 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:02:27,320 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:27,970 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:02:27,993 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:28,713 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:02:28,732 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:29,532 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSContainerStuffing HTTP/1.1" 200 None
2025-03-17 19:02:29,580 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:30,247 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:30,270 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:30,964 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:30,978 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:31,579 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:31,605 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:32,296 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:32,333 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:32,976 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:32,984 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:33,627 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:33,638 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:34,328 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:34,336 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:34,958 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:02:34,982 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:35,597 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=LinerPallet HTTP/1.1" 200 None
2025-03-17 19:02:35,637 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:02:36,598 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=containerOperations HTTP/1.1" 200 None
2025-03-17 19:04:10,031 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:10,813 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:10,836 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:11,531 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:11,552 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:12,658 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:04:12,834 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:13,579 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:13,593 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:14,296 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:14,309 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:15,012 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:15,029 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:15,729 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:15,742 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:16,424 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:16,445 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:17,060 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:17,073 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:17,778 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerShifting HTTP/1.1" 200 None
2025-03-17 19:04:17,789 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:18,917 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=PTI HTTP/1.1" 200 None
2025-03-17 19:04:19,074 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:19,825 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerCleaning HTTP/1.1" 200 None
2025-03-17 19:04:19,832 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:20,859 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Client HTTP/1.1" 200 None
2025-03-17 19:04:20,893 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:21,566 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:21,580 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:22,181 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:22,195 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:22,849 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:22,863 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:23,512 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:23,525 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:24,229 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:24,241 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:24,845 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:24,858 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:25,560 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:25,570 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:26,482 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:04:26,776 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:27,506 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:04:27,682 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:28,532 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:04:28,766 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:29,656 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:04:29,945 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:30,578 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CrossStuffing HTTP/1.1" 200 None
2025-03-17 19:04:30,608 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:31,500 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:04:31,771 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:32,422 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:04:32,445 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:33,241 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:04:33,272 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:33,958 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:04:33,978 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:34,778 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSContainerStuffing HTTP/1.1" 200 None
2025-03-17 19:04:34,816 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:35,494 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:35,525 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:36,225 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:36,236 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:36,928 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:36,942 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:37,749 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:37,760 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:38,463 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:38,481 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:39,180 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:39,193 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:39,897 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:39,912 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:40,580 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:04:40,603 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:41,332 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=LinerPallet HTTP/1.1" 200 None
2025-03-17 19:04:41,367 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:04:42,362 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=containerOperations HTTP/1.1" 200 None
2025-03-17 19:22:27,140 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:28,242 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:28,270 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:29,164 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:29,187 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:31,520 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:22:32,004 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:32,718 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:32,730 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:33,464 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:33,493 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:34,692 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:34,703 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:35,307 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:35,315 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:35,922 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:35,951 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:36,741 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:36,748 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:37,970 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerShifting HTTP/1.1" 200 None
2025-03-17 19:22:37,976 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:38,792 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=PTI HTTP/1.1" 200 None
2025-03-17 19:22:38,955 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:39,710 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerCleaning HTTP/1.1" 200 None
2025-03-17 19:22:39,718 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:40,428 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Client HTTP/1.1" 200 None
2025-03-17 19:22:40,440 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:41,145 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:41,166 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:41,873 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:41,886 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:42,695 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:42,725 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:43,504 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:43,523 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:44,728 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:44,737 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:45,343 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:45,369 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:46,162 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:46,194 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:47,699 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:22:47,912 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:48,613 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:22:48,884 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:49,749 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:22:49,967 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:50,874 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:22:51,013 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:51,799 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CrossStuffing HTTP/1.1" 200 None
2025-03-17 19:22:51,827 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:52,614 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:22:52,938 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:53,741 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:22:53,782 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:54,560 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:22:54,620 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:55,277 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:22:55,321 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:56,097 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSContainerStuffing HTTP/1.1" 200 None
2025-03-17 19:22:56,157 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:56,916 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:56,943 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:57,735 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:57,760 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:58,555 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:58,585 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:59,269 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:59,279 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:22:59,884 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:22:59,909 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:23:00,704 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:23:00,734 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:23:01,421 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:23:01,448 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:23:02,138 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:23:02,165 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:23:02,957 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=LinerPallet HTTP/1.1" 200 None
2025-03-17 19:23:03,008 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:23:04,083 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=containerOperations HTTP/1.1" 200 None
2025-03-17 19:24:26,536 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:27,342 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:27,351 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:28,156 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:28,170 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:29,283 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:24:29,692 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:30,514 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:30,520 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:31,228 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:31,238 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:32,355 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:32,360 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:32,971 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:32,986 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:33,788 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:33,794 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:34,504 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:34,506 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:35,222 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerShifting HTTP/1.1" 200 None
2025-03-17 19:24:35,228 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:36,042 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=PTI HTTP/1.1" 200 None
2025-03-17 19:24:36,165 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:36,859 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerCleaning HTTP/1.1" 200 None
2025-03-17 19:24:36,864 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:37,474 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Client HTTP/1.1" 200 None
2025-03-17 19:24:37,488 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:38,089 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:38,094 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:39,216 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:39,225 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:39,829 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:39,840 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:40,444 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:40,455 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:41,058 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:41,067 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:41,673 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:41,678 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:42,390 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:42,395 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:43,210 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:24:43,422 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:44,109 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:24:44,367 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:45,258 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:24:45,394 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:46,178 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:24:46,364 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:46,999 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CrossStuffing HTTP/1.1" 200 None
2025-03-17 19:24:47,005 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:47,818 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:24:48,004 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:48,739 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:24:48,756 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:49,559 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:24:49,597 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:50,276 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:24:50,282 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:50,992 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSContainerStuffing HTTP/1.1" 200 None
2025-03-17 19:24:51,024 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:51,709 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:51,719 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:52,324 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:52,330 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:52,938 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:52,954 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:53,552 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:53,561 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:54,166 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:54,178 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:54,781 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:54,785 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:55,497 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:55,505 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:56,112 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:56,117 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:56,828 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=LinerPallet HTTP/1.1" 200 None
2025-03-17 19:24:56,860 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:57,853 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=containerOperations HTTP/1.1" 200 None
2025-03-17 19:24:58,019 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:58,672 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:58,676 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:59,286 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:59,290 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:24:59,906 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:24:59,911 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:25:00,721 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:25:00,926 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:25:09,118 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=RawData HTTP/1.1" 200 None
2025-03-17 19:25:09,911 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:25:11,064 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=UnloadingSummary HTTP/1.1" 200 None
2025-03-17 19:25:11,370 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:25:12,394 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=UnloadingSummary HTTP/1.1" 200 None
2025-03-17 19:25:12,628 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:25:13,228 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:25:13,236 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:25:13,835 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:25:13,849 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:25:14,546 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ShoreCrane HTTP/1.1" 200 None
2025-03-17 19:25:14,552 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:25:15,581 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:25:16,025 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:25:17,105 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ScowTransfer HTTP/1.1" 200 None
2025-03-17 19:25:17,147 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:25:18,436 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ForkliftRecord HTTP/1.1" 200 None
2025-03-17 19:28:12,868 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:14,155 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:14,178 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:15,383 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:15,403 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:16,613 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:28:16,892 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:18,047 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:18,052 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:19,171 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:19,179 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:20,299 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:20,305 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:21,426 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:21,432 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:22,554 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:22,559 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:23,678 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:23,683 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:24,397 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerShifting HTTP/1.1" 200 None
2025-03-17 19:28:24,408 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:25,318 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=PTI HTTP/1.1" 200 None
2025-03-17 19:28:25,410 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:26,035 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerCleaning HTTP/1.1" 200 None
2025-03-17 19:28:26,045 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:27,262 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Client HTTP/1.1" 200 None
2025-03-17 19:28:27,276 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:27,980 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:27,984 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:28,593 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:28,602 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:29,719 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:29,724 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:30,846 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:30,852 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:31,972 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:31,981 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:33,098 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:33,101 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:34,225 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:34,233 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:35,147 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:28:35,405 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:36,272 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:28:36,595 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:37,297 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:28:37,405 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:38,115 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:28:38,357 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:39,037 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CrossStuffing HTTP/1.1" 200 None
2025-03-17 19:28:39,043 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:39,755 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:28:39,850 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:40,476 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:28:40,483 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:41,089 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:28:41,124 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:41,802 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:28:41,835 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:42,519 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSContainerStuffing HTTP/1.1" 200 None
2025-03-17 19:28:42,553 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:43,749 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:43,751 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:44,875 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:44,881 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:46,001 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:46,007 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:47,127 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:47,136 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:48,253 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:48,262 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:49,380 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:49,390 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:50,506 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:50,511 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:51,632 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:51,638 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:52,350 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=LinerPallet HTTP/1.1" 200 None
2025-03-17 19:28:52,383 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:53,475 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=containerOperations HTTP/1.1" 200 None
2025-03-17 19:28:53,599 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:54,807 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:54,815 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:55,933 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:55,942 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:57,061 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:28:57,070 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:28:57,776 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:28:58,094 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:29:04,022 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=RawData HTTP/1.1" 200 None
2025-03-17 19:29:04,917 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:29:06,037 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=UnloadingSummary HTTP/1.1" 200 None
2025-03-17 19:29:06,406 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:29:07,505 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=UnloadingSummary HTTP/1.1" 200 None
2025-03-17 19:29:07,681 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:29:08,323 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:29:08,329 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:29:09,450 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:29:09,458 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:29:10,167 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ShoreCrane HTTP/1.1" 200 None
2025-03-17 19:29:10,179 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:29:11,295 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:29:11,665 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:29:12,626 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ScowTransfer HTTP/1.1" 200 None
2025-03-17 19:29:12,680 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:29:14,161 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ForkliftRecord HTTP/1.1" 200 None
2025-03-17 19:32:23,013 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:24,213 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:24,222 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:24,829 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:24,855 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:26,059 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:32:26,448 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:27,593 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:27,595 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:28,719 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:28,721 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:29,846 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:29,856 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:31,075 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:31,086 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:32,306 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:32,314 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:33,429 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:33,434 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:34,044 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerShifting HTTP/1.1" 200 None
2025-03-17 19:32:34,047 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:34,797 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=PTI HTTP/1.1" 200 None
2025-03-17 19:32:34,976 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:35,579 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerCleaning HTTP/1.1" 200 None
2025-03-17 19:32:35,582 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:36,194 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Client HTTP/1.1" 200 None
2025-03-17 19:32:36,200 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:37,321 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:37,326 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:38,447 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:38,450 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:39,574 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:39,581 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:40,188 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:40,195 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:40,803 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:40,806 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:41,929 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:41,933 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:42,651 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:42,654 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:43,466 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:32:43,547 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:44,387 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:32:44,523 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:45,412 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:32:45,496 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:46,334 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:32:46,542 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:47,254 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CrossStuffing HTTP/1.1" 200 None
2025-03-17 19:32:47,293 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:48,074 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:32:48,238 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:48,995 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:32:49,009 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:49,815 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:32:49,851 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:50,736 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:32:50,771 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:51,555 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSContainerStuffing HTTP/1.1" 200 None
2025-03-17 19:32:51,590 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:52,373 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:52,381 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:52,989 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:52,996 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:53,603 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:53,608 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:54,217 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:54,226 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:54,831 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:54,834 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:55,447 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:55,458 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:56,060 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:56,067 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:56,675 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:56,681 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:57,392 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=LinerPallet HTTP/1.1" 200 None
2025-03-17 19:32:57,431 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:58,621 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=containerOperations HTTP/1.1" 200 None
2025-03-17 19:32:58,807 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:32:59,440 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:32:59,445 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:33:00,054 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:33:00,063 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:33:00,668 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:33:00,679 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:33:01,488 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:33:01,567 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:33:07,530 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=RawData HTTP/1.1" 200 None
2025-03-17 19:33:08,551 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:33:09,681 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=UnloadingSummary HTTP/1.1" 200 None
2025-03-17 19:33:09,950 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:33:11,217 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=UnloadingSummary HTTP/1.1" 200 None
2025-03-17 19:33:11,559 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:33:12,240 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:33:12,249 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:33:12,854 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:33:12,860 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:33:13,572 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ShoreCrane HTTP/1.1" 200 None
2025-03-17 19:33:13,606 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:33:14,957 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:33:15,420 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:33:16,438 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ScowTransfer HTTP/1.1" 200 None
2025-03-17 19:33:16,480 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:33:17,975 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ForkliftRecord HTTP/1.1" 200 None
2025-03-17 19:38:03,207 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:03,984 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:04,002 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:04,665 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:04,685 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:05,726 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:38:06,035 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:07,160 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:07,166 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:07,773 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:07,779 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:08,904 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:08,913 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:09,616 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:09,625 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:10,230 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:10,236 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:11,356 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:11,367 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:12,587 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerShifting HTTP/1.1" 200 None
2025-03-17 19:38:12,593 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:13,404 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=PTI HTTP/1.1" 200 None
2025-03-17 19:38:13,689 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:14,429 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerCleaning HTTP/1.1" 200 None
2025-03-17 19:38:14,435 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:15,555 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Client HTTP/1.1" 200 None
2025-03-17 19:38:15,563 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:16,688 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:16,693 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:17,808 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:17,812 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:18,934 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:18,940 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:19,549 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:19,558 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:20,675 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:20,680 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:21,802 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:21,807 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:22,415 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:22,420 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:23,952 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:38:24,097 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:24,874 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:38:24,949 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:25,694 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:38:25,853 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:26,614 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:38:26,812 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:27,436 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CrossStuffing HTTP/1.1" 200 None
2025-03-17 19:38:27,441 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:28,120 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:38:28,400 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:29,175 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:38:29,186 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:29,759 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:38:29,770 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:30,506 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:38:30,513 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:31,120 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSContainerStuffing HTTP/1.1" 200 None
2025-03-17 19:38:31,247 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:32,451 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:32,455 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:33,065 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:33,075 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:34,192 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:34,202 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:34,807 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:34,813 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:35,934 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:35,944 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:36,547 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:36,553 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:37,674 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:37,683 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:38,801 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:38,813 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:39,620 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=LinerPallet HTTP/1.1" 200 None
2025-03-17 19:38:39,653 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:40,919 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=containerOperations HTTP/1.1" 200 None
2025-03-17 19:38:41,193 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:42,488 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:42,494 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:43,204 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:43,212 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:43,819 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:43,825 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:44,639 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:38:44,812 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:53,548 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=RawData HTTP/1.1" 200 None
2025-03-17 19:38:54,438 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:55,595 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=UnloadingSummary HTTP/1.1" 200 None
2025-03-17 19:38:55,746 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:56,825 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=UnloadingSummary HTTP/1.1" 200 None
2025-03-17 19:38:57,060 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:57,745 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:57,750 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:58,359 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:38:58,365 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:38:59,183 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ShoreCrane HTTP/1.1" 200 None
2025-03-17 19:38:59,197 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:39:00,409 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:39:00,707 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:39:01,742 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ScowTransfer HTTP/1.1" 200 None
2025-03-17 19:39:01,777 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:39:03,275 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ForkliftRecord HTTP/1.1" 200 None
2025-03-17 19:41:40,799 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:41,589 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:41,604 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:42,307 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:42,320 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:43,638 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:41:43,963 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:44,661 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:44,667 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:45,276 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:45,282 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:45,890 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:45,896 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:46,506 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:46,515 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:47,221 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:47,230 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:47,835 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:47,838 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:48,553 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerShifting HTTP/1.1" 200 None
2025-03-17 19:41:48,559 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:49,373 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=PTI HTTP/1.1" 200 None
2025-03-17 19:41:49,634 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:50,293 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerCleaning HTTP/1.1" 200 None
2025-03-17 19:41:50,299 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:50,908 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Client HTTP/1.1" 200 None
2025-03-17 19:41:50,929 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:51,727 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:51,735 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:52,340 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:52,343 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:52,956 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:52,961 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:53,547 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:53,552 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:54,184 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:54,192 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:54,799 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:54,807 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:55,364 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:41:55,372 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:56,233 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:41:56,445 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:57,154 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:41:57,507 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:58,283 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:41:58,554 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:41:59,306 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:41:59,446 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:00,123 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CrossStuffing HTTP/1.1" 200 None
2025-03-17 19:42:00,131 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:00,943 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:42:01,083 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:01,865 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:42:01,872 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:02,478 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:42:02,513 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:03,196 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:42:03,203 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:03,812 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSContainerStuffing HTTP/1.1" 200 None
2025-03-17 19:42:03,868 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:04,526 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:42:04,533 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:05,143 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:42:05,149 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:05,858 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:42:05,869 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:06,472 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:42:06,482 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:07,190 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:42:07,200 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:07,804 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:42:07,813 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:08,418 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:42:08,423 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:09,545 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:42:09,556 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:10,368 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=LinerPallet HTTP/1.1" 200 None
2025-03-17 19:42:10,417 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:11,490 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=containerOperations HTTP/1.1" 200 None
2025-03-17 19:42:11,653 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:12,310 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:42:12,314 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:13,544 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:42:13,549 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:14,665 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:42:14,671 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:15,386 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:42:15,688 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:22,038 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=RawData HTTP/1.1" 200 None
2025-03-17 19:42:22,714 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:23,779 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=UnloadingSummary HTTP/1.1" 200 None
2025-03-17 19:42:23,929 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:25,109 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=UnloadingSummary HTTP/1.1" 200 None
2025-03-17 19:42:25,270 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:26,441 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:42:26,450 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:27,157 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:42:27,165 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:27,772 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ShoreCrane HTTP/1.1" 200 None
2025-03-17 19:42:27,784 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:28,801 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:42:29,025 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:30,026 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ScowTransfer HTTP/1.1" 200 None
2025-03-17 19:42:30,069 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:42:31,459 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ForkliftRecord HTTP/1.1" 200 None
2025-03-17 19:42:31,546 - DEBUG - Using selector: EpollSelector
2025-03-17 19:43:49,030 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:43:49,799 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:43:49,812 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:43:50,513 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:43:50,527 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:43:51,746 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:43:52,201 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:43:52,869 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:43:52,874 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:43:53,483 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:43:53,493 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:43:54,098 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:43:54,104 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:43:54,712 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:43:54,722 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:43:55,348 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:43:55,358 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:43:55,924 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:43:55,939 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:43:56,658 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerShifting HTTP/1.1" 200 None
2025-03-17 19:43:56,665 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:43:57,478 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=PTI HTTP/1.1" 200 None
2025-03-17 19:43:57,728 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:43:58,399 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerCleaning HTTP/1.1" 200 None
2025-03-17 19:43:58,404 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:43:59,013 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Client HTTP/1.1" 200 None
2025-03-17 19:43:59,021 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:43:59,627 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:43:59,635 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:00,243 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:00,248 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:00,857 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:00,862 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:01,575 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:01,580 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:02,188 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:02,193 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:02,802 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:02,807 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:03,416 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:03,425 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:04,339 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:44:04,518 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:05,260 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:44:05,424 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:06,284 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:44:06,474 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:07,206 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:44:07,378 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:08,128 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CrossStuffing HTTP/1.1" 200 None
2025-03-17 19:44:08,134 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:08,844 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:44:09,014 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:09,766 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:44:09,772 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:10,380 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:44:10,392 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:11,097 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:44:11,104 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:11,712 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSContainerStuffing HTTP/1.1" 200 None
2025-03-17 19:44:11,749 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:12,532 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:12,537 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:13,247 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:13,257 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:13,819 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:13,825 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:14,475 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:14,480 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:15,091 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:15,101 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:15,709 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:15,714 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:16,324 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:16,329 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:16,934 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:16,940 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:17,651 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=LinerPallet HTTP/1.1" 200 None
2025-03-17 19:44:17,685 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:18,778 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=containerOperations HTTP/1.1" 200 None
2025-03-17 19:44:19,001 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:19,698 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:19,709 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:20,313 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:20,319 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:20,928 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:20,933 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:21,747 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:44:21,941 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:27,891 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=RawData HTTP/1.1" 200 None
2025-03-17 19:44:29,307 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:30,350 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=UnloadingSummary HTTP/1.1" 200 None
2025-03-17 19:44:30,509 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:31,681 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=UnloadingSummary HTTP/1.1" 200 None
2025-03-17 19:44:31,840 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:32,499 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:32,505 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:33,113 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:44:33,121 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:33,831 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ShoreCrane HTTP/1.1" 200 None
2025-03-17 19:44:33,859 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:35,060 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:44:35,205 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:36,187 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ScowTransfer HTTP/1.1" 200 None
2025-03-17 19:44:36,225 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:44:37,619 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ForkliftRecord HTTP/1.1" 200 None
2025-03-17 19:44:37,673 - DEBUG - Using selector: EpollSelector
2025-03-17 19:44:37,673 - INFO - Starting application
2025-03-17 19:44:37,673 - INFO - Clearing screen
2025-03-17 19:52:29,151 - INFO - Selected: Save files
2025-03-17 19:52:29,152 - INFO - Clearing screen
2025-03-17 19:52:33,547 - INFO - Initiating save operation for all
2025-03-17 19:52:33,548 - INFO - Processing all dataframe categories
2025-03-17 19:52:33,548 - INFO - Processing category: emr
2025-03-17 19:52:33,549 - ERROR - Unexpected error processing cleaning: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,551 - ERROR - Unexpected error processing pti: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,551 - ERROR - Unexpected error processing shifting: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,551 - INFO - Processing category: operations
2025-03-17 19:52:33,551 - ERROR - Unexpected error processing netlist: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,551 - ERROR - Unexpected error processing oss: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,551 - ERROR - Unexpected error processing iot_stuffing: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,551 - INFO - Processing category: stuffing
2025-03-17 19:52:33,551 - ERROR - Unexpected error processing liner_pallet: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,552 - ERROR - Unexpected error processing plugin: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,552 - INFO - Processing category: transport
2025-03-17 19:52:33,552 - ERROR - Unexpected error processing shore_crane: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,552 - ERROR - Unexpected error processing transfer: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,552 - ERROR - Unexpected error processing forklift: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,552 - ERROR - Unexpected error processing scow_transfer: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,552 - INFO - Processing category: miscellaneous
2025-03-17 19:52:33,552 - ERROR - Unexpected error processing static_loader: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,552 - ERROR - Unexpected error processing by_catch: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,552 - ERROR - Unexpected error processing cross_stuffing: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,553 - ERROR - Unexpected error processing cccs_stuffing: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,553 - ERROR - Unexpected error processing scow_transfer: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,553 - ERROR - Unexpected error processing truck_to_cccs: cannot unpack non-iterable coroutine object
2025-03-17 19:52:33,553 - INFO - Completed processing all categories
2025-03-17 19:55:05,472 - INFO - Initiating save operation for all
2025-03-17 19:55:05,472 - INFO - Processing all dataframe categories
2025-03-17 19:55:05,473 - INFO - Processing category: emr
2025-03-17 19:55:05,473 - ERROR - Unexpected error processing cleaning: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,473 - ERROR - Unexpected error processing pti: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,474 - ERROR - Unexpected error processing shifting: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,474 - INFO - Processing category: operations
2025-03-17 19:55:05,475 - ERROR - Unexpected error processing netlist: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,475 - ERROR - Unexpected error processing oss: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,476 - ERROR - Unexpected error processing iot_stuffing: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,476 - INFO - Processing category: stuffing
2025-03-17 19:55:05,476 - ERROR - Unexpected error processing liner_pallet: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,477 - ERROR - Unexpected error processing plugin: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,477 - INFO - Processing category: transport
2025-03-17 19:55:05,477 - ERROR - Unexpected error processing shore_crane: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,478 - ERROR - Unexpected error processing transfer: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,478 - ERROR - Unexpected error processing forklift: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,478 - ERROR - Unexpected error processing scow_transfer: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,479 - INFO - Processing category: miscellaneous
2025-03-17 19:55:05,479 - ERROR - Unexpected error processing static_loader: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,479 - ERROR - Unexpected error processing by_catch: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,480 - ERROR - Unexpected error processing cross_stuffing: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,480 - ERROR - Unexpected error processing cccs_stuffing: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,481 - ERROR - Unexpected error processing scow_transfer: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,481 - ERROR - Unexpected error processing truck_to_cccs: cannot unpack non-iterable coroutine object
2025-03-17 19:55:05,481 - INFO - Completed processing all categories
2025-03-17 19:55:13,571 - INFO - Exiting application
2025-03-17 19:56:49,859 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:56:50,927 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:56:50,937 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:56:51,849 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:56:51,865 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:56:54,614 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:56:55,032 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:56:55,946 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:56:55,951 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:56:56,867 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:56:56,877 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:56:57,788 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:56:57,793 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:56:58,710 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:56:58,715 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:56:59,529 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:56:59,534 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:00,450 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:00,459 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:01,885 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerShifting HTTP/1.1" 200 None
2025-03-17 19:57:01,890 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:02,909 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=PTI HTTP/1.1" 200 None
2025-03-17 19:57:03,108 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:04,034 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1sPK_pSIJ8iR38yJExtvzGgJO2aMz2VN6_uDHh37TqR0/gviz/tq?tqx=out:csv&sheet=ContainerCleaning HTTP/1.1" 200 None
2025-03-17 19:57:04,041 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:04,958 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Client HTTP/1.1" 200 None
2025-03-17 19:57:04,966 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:05,882 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:05,891 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:06,801 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:06,809 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:07,825 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:07,835 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:08,746 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:08,756 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:09,667 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:09,670 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:10,590 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:10,595 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:11,512 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:11,517 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:13,663 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:57:13,865 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:14,994 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:57:15,329 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:16,324 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:57:16,676 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:17,656 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:57:17,866 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:18,884 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CrossStuffing HTTP/1.1" 200 None
2025-03-17 19:57:18,890 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:19,908 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:57:20,141 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:21,137 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:57:21,149 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:22,058 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:57:22,061 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:22,981 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=IPHSBycatchTransfer HTTP/1.1" 200 None
2025-03-17 19:57:22,995 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:23,909 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSContainerStuffing HTTP/1.1" 200 None
2025-03-17 19:57:23,994 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:24,925 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:24,930 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:25,846 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:25,849 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:26,768 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:26,773 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:27,690 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:27,696 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:28,612 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:28,620 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:29,533 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:29,538 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:30,455 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:30,464 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:31,377 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:31,386 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:32,402 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=LinerPallet HTTP/1.1" 200 None
2025-03-17 19:57:32,487 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:33,835 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1L0HlevB-asshOgXMmIQ14bysq56lUPp0lYCrHPB0iGg/gviz/tq?tqx=out:csv&sheet=containerOperations HTTP/1.1" 200 None
2025-03-17 19:57:34,318 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:35,166 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:35,174 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:36,090 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:36,098 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:37,009 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:37,022 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:38,136 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1VbfiiWsp8yxs6KSR1CXpw1S_35tYlWV8UjjWah9Afpw/gviz/tq?tqx=out:csv&sheet=CCCSReport HTTP/1.1" 200 None
2025-03-17 19:57:38,407 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:47,249 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=RawData HTTP/1.1" 200 None
2025-03-17 19:57:48,473 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:49,912 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=UnloadingSummary HTTP/1.1" 200 None
2025-03-17 19:57:50,475 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:51,756 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1PvTkl6DYZdhtaiNshz0qwtSPxC8S1OOeu905NmhFKNs/gviz/tq?tqx=out:csv&sheet=UnloadingSummary HTTP/1.1" 200 None
2025-03-17 19:57:52,031 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:52,881 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:52,885 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:53,804 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1ai-zQMtbPUx0LeQeLmXcpPgKvL5cyvwDfSJqRzxfUQg/gviz/tq?tqx=out:csv&sheet=Price HTTP/1.1" 200 None
2025-03-17 19:57:53,811 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:54,828 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ShoreCrane HTTP/1.1" 200 None
2025-03-17 19:57:54,841 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:56,262 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=Transfer HTTP/1.1" 200 None
2025-03-17 19:57:56,618 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:57,799 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ScowTransfer HTTP/1.1" 200 None
2025-03-17 19:57:57,896 - DEBUG - Starting new HTTPS connection (1): docs.google.com:443
2025-03-17 19:57:59,539 - DEBUG - https://docs.google.com:443 "GET /spreadsheets/d/1O8K26c7CqLSdLr-f2gvZliDpBn9ArxXvj9tEJy-ElUg/gviz/tq?tqx=out:csv&sheet=ForkliftRecord HTTP/1.1" 200 None
2025-03-17 19:57:59,656 - DEBUG - Using selector: EpollSelector
2025-03-17 19:57:59,656 - INFO - Starting application
2025-03-17 19:57:59,656 - INFO - Clearing screen
2025-03-17 19:58:03,240 - INFO - Selected: Save files
2025-03-17 19:58:03,241 - INFO - Clearing screen
2025-03-17 19:58:07,682 - INFO - Initiating save operation for all
2025-03-17 19:58:07,683 - INFO - Processing all dataframe categories
2025-03-17 19:58:07,683 - INFO - Processing category: emr
2025-03-17 19:58:07,683 - ERROR - Unexpected error processing cleaning: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,687 - ERROR - Unexpected error processing pti: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,687 - ERROR - Unexpected error processing shifting: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,688 - INFO - Processing category: operations
2025-03-17 19:58:07,688 - ERROR - Unexpected error processing netlist: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,688 - ERROR - Unexpected error processing oss: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,689 - ERROR - Unexpected error processing iot_stuffing: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,689 - INFO - Processing category: stuffing
2025-03-17 19:58:07,689 - ERROR - Unexpected error processing liner_pallet: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,690 - ERROR - Unexpected error processing plugin: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,690 - INFO - Processing category: transport
2025-03-17 19:58:07,690 - ERROR - Unexpected error processing shore_crane: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,691 - ERROR - Unexpected error processing transfer: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,691 - ERROR - Unexpected error processing forklift: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,691 - ERROR - Unexpected error processing scow_transfer: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,692 - INFO - Processing category: miscellaneous
2025-03-17 19:58:07,692 - ERROR - Unexpected error processing static_loader: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,692 - ERROR - Unexpected error processing by_catch: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,693 - ERROR - Unexpected error processing cross_stuffing: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,693 - ERROR - Unexpected error processing cccs_stuffing: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,693 - ERROR - Unexpected error processing scow_transfer: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,694 - ERROR - Unexpected error processing truck_to_cccs: cannot unpack non-iterable coroutine object
2025-03-17 19:58:07,694 - INFO - Completed processing all categories
2025-03-17 19:59:25,099 - INFO - Exiting application
2025-03-21 20:58:16,649 - DEBUG - Using selector: EpollSelector
2025-03-21 20:58:16,691 - INFO - Starting application
2025-03-21 20:58:16,691 - INFO - Clearing screen
2025-03-21 20:58:20,673 - INFO - Selected: Save files
2025-03-21 20:58:20,674 - INFO - Clearing screen
2025-03-21 20:58:25,414 - INFO - Initiating save operation for all
2025-03-21 20:58:25,414 - INFO - Processing all dataframe categories concurrently
2025-03-21 20:58:25,415 - INFO - Queueing category: emr
2025-03-21 20:58:25,415 - INFO - Queueing category: operations
2025-03-21 20:58:25,415 - INFO - Queueing category: stuffing
2025-03-21 20:58:25,416 - INFO - Queueing category: transport
2025-03-21 20:58:25,416 - INFO - Queueing category: miscellaneous
2025-03-21 20:58:25,417 - ERROR - Error writing shifting: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,418 - ERROR - Error writing washing: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,418 - ERROR - Error writing pti: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,419 - ERROR - Error writing ops: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,419 - ERROR - Error writing hatch_to_hatch: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,419 - ERROR - Error writing pallet_liner: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,420 - ERROR - Error writing container_plugin: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,420 - ERROR - Error writing shore_crane: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,421 - ERROR - Error writing transfer: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,421 - ERROR - Error writing scow_transfer: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,422 - ERROR - Error writing forklift: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,422 - ERROR - Error writing static_loader: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,422 - ERROR - Error writing dispatch_to_cargo: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,423 - ERROR - Error writing truck_to_cccs: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,423 - ERROR - Error writing cross_stuffing: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,424 - ERROR - Error writing cccs_stuffing: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,424 - ERROR - Error writing bycatch: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,425 - ERROR - Error saving shifting: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,425 - ERROR - Error saving washing: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,426 - ERROR - Error saving pti: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,426 - ERROR - Error saving ops: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,426 - ERROR - Error saving hatch_to_hatch: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,427 - ERROR - Error saving pallet_liner: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,427 - ERROR - Error saving container_plugin: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,427 - ERROR - Error saving shore_crane: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,428 - ERROR - Error saving transfer: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,428 - ERROR - Error saving scow_transfer: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,428 - ERROR - Error saving forklift: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,428 - ERROR - Error saving static_loader: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,429 - ERROR - Error saving dispatch_to_cargo: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,429 - ERROR - Error saving truck_to_cccs: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,429 - ERROR - Error saving cross_stuffing: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,429 - ERROR - Error saving cccs_stuffing: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,429 - ERROR - Error saving bycatch: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,430 - INFO - Save completed
2025-03-21 20:58:25,430 - INFO - Successfully saved: 0 files
2025-03-21 20:58:25,430 - ERROR - Failed to save: 17 files
2025-03-21 20:58:25,431 - ERROR -   - shifting: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,431 - ERROR -   - washing: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,431 - ERROR -   - pti: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,431 - ERROR -   - ops: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,432 - ERROR -   - hatch_to_hatch: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,432 - ERROR -   - pallet_liner: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,432 - ERROR -   - container_plugin: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,432 - ERROR -   - shore_crane: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,433 - ERROR -   - transfer: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,433 - ERROR -   - scow_transfer: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,433 - ERROR -   - forklift: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,433 - ERROR -   - static_loader: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,434 - ERROR -   - dispatch_to_cargo: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,434 - ERROR -   - truck_to_cccs: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,434 - ERROR -   - cross_stuffing: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,434 - ERROR -   - cccs_stuffing: [Errno 2] No such file or directory: ''
2025-03-21 20:58:25,435 - ERROR -   - bycatch: [Errno 2] No such file or directory: ''
2025-03-21 21:06:53,184 - INFO - Clearing screen
2025-03-21 21:06:55,418 - INFO - Exiting application
2025-03-21 21:06:58,554 - DEBUG - Using selector: EpollSelector
2025-03-21 21:06:58,554 - INFO - Starting application
2025-03-21 21:06:58,554 - INFO - Clearing screen
2025-03-21 21:07:04,730 - INFO - Clearing screen
2025-03-21 21:07:06,828 - INFO - Clearing screen
2025-03-21 21:07:09,966 - INFO - Clearing screen
2025-03-21 21:07:24,822 - DEBUG - Using selector: EpollSelector
2025-03-21 21:07:24,822 - INFO - Starting application
2025-03-21 21:07:24,822 - INFO - Clearing screen
2025-03-21 21:07:32,260 - INFO - Selected: Save files
2025-03-21 21:07:32,261 - INFO - Clearing screen
2025-03-21 21:07:36,836 - INFO - Initiating save operation for all
2025-03-21 21:07:36,836 - INFO - Processing all dataframe categories concurrently
2025-03-21 21:07:36,837 - INFO - Queueing category: emr
2025-03-21 21:07:36,837 - INFO - Queueing category: operations
2025-03-21 21:07:36,837 - INFO - Queueing category: netlist
2025-03-21 21:07:36,837 - INFO - Queueing category: bin_dispatch
2025-03-21 21:07:36,838 - INFO - Queueing category: shore_handling
2025-03-21 21:07:36,838 - INFO - Queueing category: stuffing
2025-03-21 21:07:36,838 - INFO - Queueing category: transport
2025-03-21 21:07:36,838 - INFO - Queueing category: miscellaneous
2025-03-21 21:07:36,854 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,855 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,855 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,855 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,856 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,856 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,856 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,857 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,857 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,857 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,857 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,858 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,858 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,858 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,858 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,859 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,859 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,859 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,860 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,860 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,860 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,860 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,860 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,861 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:07:36,861 - INFO - Save completed
2025-03-21 21:07:36,861 - INFO - Successfully saved: 0 files
2025-03-21 21:10:53,509 - INFO - Exiting application
2025-03-21 21:10:58,056 - DEBUG - Using selector: EpollSelector
2025-03-21 21:10:58,056 - INFO - Starting application
2025-03-21 21:10:58,056 - INFO - Clearing screen
2025-03-21 21:11:00,125 - INFO - Selected: Save files
2025-03-21 21:11:00,125 - INFO - Clearing screen
2025-03-21 21:11:03,185 - INFO - Initiating save operation for all
2025-03-21 21:11:03,185 - INFO - Processing all dataframe categories concurrently
2025-03-21 21:11:03,185 - INFO - Queueing category: emr
2025-03-21 21:11:03,186 - INFO - Queueing category: operations
2025-03-21 21:11:03,186 - INFO - Queueing category: netlist
2025-03-21 21:11:03,186 - INFO - Queueing category: bin_dispatch
2025-03-21 21:11:03,187 - INFO - Queueing category: shore_handling
2025-03-21 21:11:03,187 - INFO - Queueing category: stuffing
2025-03-21 21:11:03,187 - INFO - Queueing category: transport
2025-03-21 21:11:03,188 - INFO - Queueing category: miscellaneous
2025-03-21 21:11:03,191 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,192 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,192 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,192 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,193 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,193 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,193 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,194 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,194 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,194 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,194 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,195 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,195 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,195 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,196 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,196 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,196 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,196 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,197 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,197 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,197 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,198 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,198 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,198 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:03,198 - INFO - Save completed
2025-03-21 21:11:03,199 - INFO - Successfully saved: 0 files
2025-03-21 21:11:15,680 - INFO - Exiting application
2025-03-21 21:11:19,983 - DEBUG - Using selector: EpollSelector
2025-03-21 21:11:19,983 - INFO - Starting application
2025-03-21 21:11:19,983 - INFO - Clearing screen
2025-03-21 21:11:22,010 - INFO - Selected: View dataframe
2025-03-21 21:11:22,011 - INFO - Clearing screen
2025-03-21 21:11:24,202 - INFO - Selected: Check logistics records
2025-03-21 21:11:24,202 - INFO - Clearing screen
2025-03-21 21:11:24,208 - INFO - Clearing screen
2025-03-21 21:11:25,971 - INFO - Exiting application
2025-03-21 21:11:35,078 - DEBUG - Using selector: EpollSelector
2025-03-21 21:11:35,078 - INFO - Starting application
2025-03-21 21:11:35,078 - INFO - Clearing screen
2025-03-21 21:11:36,982 - INFO - Selected: Save files
2025-03-21 21:11:36,983 - INFO - Clearing screen
2025-03-21 21:11:41,152 - INFO - Initiating save operation for all
2025-03-21 21:11:41,153 - INFO - Processing all dataframe categories concurrently
2025-03-21 21:11:41,153 - INFO - Queueing category: emr
2025-03-21 21:11:41,154 - INFO - Queueing category: operations
2025-03-21 21:11:41,154 - INFO - Queueing category: netlist
2025-03-21 21:11:41,154 - INFO - Queueing category: bin_dispatch
2025-03-21 21:11:41,155 - INFO - Queueing category: shore_handling
2025-03-21 21:11:41,155 - INFO - Queueing category: stuffing
2025-03-21 21:11:41,155 - INFO - Queueing category: transport
2025-03-21 21:11:41,156 - INFO - Queueing category: miscellaneous
2025-03-21 21:11:41,161 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,161 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,162 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,162 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,162 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,163 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,163 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,163 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,164 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,164 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,164 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,164 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,165 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,165 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,165 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,166 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,166 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,166 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,167 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,167 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,167 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,167 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,168 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,168 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:11:41,168 - INFO - Save completed
2025-03-21 21:11:41,169 - INFO - Successfully saved: 0 files
2025-03-21 21:14:27,210 - INFO - Exiting application
2025-03-21 21:14:30,421 - DEBUG - Using selector: EpollSelector
2025-03-21 21:14:30,421 - INFO - Starting application
2025-03-21 21:14:30,421 - INFO - Clearing screen
2025-03-21 21:14:32,265 - INFO - Selected: Save files
2025-03-21 21:14:32,265 - INFO - Clearing screen
2025-03-21 21:14:35,640 - INFO - Initiating save operation for all
2025-03-21 21:14:35,640 - INFO - Processing all dataframe categories concurrently
2025-03-21 21:14:35,641 - INFO - Queueing category: emr
2025-03-21 21:14:35,641 - INFO - Queueing category: operations
2025-03-21 21:14:35,642 - INFO - Queueing category: netlist
2025-03-21 21:14:35,642 - INFO - Queueing category: bin_dispatch
2025-03-21 21:14:35,642 - INFO - Queueing category: shore_handling
2025-03-21 21:14:35,643 - INFO - Queueing category: stuffing
2025-03-21 21:14:35,643 - INFO - Queueing category: transport
2025-03-21 21:14:35,643 - INFO - Queueing category: miscellaneous
2025-03-21 21:14:35,660 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,661 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,661 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,661 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,662 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,662 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,662 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,662 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,663 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,663 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,663 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,663 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,664 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,664 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,664 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,664 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,665 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,665 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,665 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,665 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,666 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,666 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,666 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,666 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:14:35,666 - INFO - Save completed
2025-03-21 21:14:35,667 - INFO - Successfully saved: 0 files
2025-03-21 21:16:05,732 - INFO - Exiting application
2025-03-21 21:16:08,640 - DEBUG - Using selector: EpollSelector
2025-03-21 21:16:08,641 - INFO - Starting application
2025-03-21 21:16:08,641 - INFO - Clearing screen
2025-03-21 21:16:10,427 - INFO - Selected: Save files
2025-03-21 21:16:10,427 - INFO - Clearing screen
2025-03-21 21:16:13,339 - INFO - Initiating save operation for all
2025-03-21 21:16:13,340 - INFO - Processing all dataframe categories concurrently
2025-03-21 21:16:13,340 - INFO - Queueing category: emr
2025-03-21 21:16:13,340 - INFO - Queueing category: operations
2025-03-21 21:16:13,341 - INFO - Queueing category: netlist
2025-03-21 21:16:13,341 - INFO - Queueing category: bin_dispatch
2025-03-21 21:16:13,341 - INFO - Queueing category: shore_handling
2025-03-21 21:16:13,342 - INFO - Queueing category: stuffing
2025-03-21 21:16:13,342 - INFO - Queueing category: transport
2025-03-21 21:16:13,342 - INFO - Queueing category: miscellaneous
2025-03-21 21:16:13,358 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,359 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,359 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,359 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,359 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,360 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,360 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,360 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,361 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,361 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,361 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,361 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,362 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,362 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,362 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,362 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,362 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,363 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,363 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,363 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,363 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,364 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,364 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,364 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:16:13,364 - INFO - Save completed
2025-03-21 21:16:13,364 - INFO - Successfully saved: 0 files
2025-03-21 21:17:18,922 - INFO - Exiting application
2025-03-21 21:17:23,180 - DEBUG - Using selector: EpollSelector
2025-03-21 21:17:23,180 - INFO - Starting application
2025-03-21 21:17:23,180 - INFO - Clearing screen
2025-03-21 21:17:24,544 - INFO - Selected: Save files
2025-03-21 21:17:24,544 - INFO - Clearing screen
2025-03-21 21:17:29,002 - INFO - Initiating save operation for all
2025-03-21 21:17:29,002 - INFO - Processing all dataframe categories concurrently
2025-03-21 21:17:29,003 - INFO - Queueing category: emr
2025-03-21 21:17:29,004 - INFO - Queueing category: operations
2025-03-21 21:17:29,004 - INFO - Queueing category: netlist
2025-03-21 21:17:29,004 - INFO - Queueing category: bin_dispatch
2025-03-21 21:17:29,005 - INFO - Queueing category: shore_handling
2025-03-21 21:17:29,005 - INFO - Queueing category: stuffing
2025-03-21 21:17:29,005 - INFO - Queueing category: transport
2025-03-21 21:17:29,005 - INFO - Queueing category: miscellaneous
2025-03-21 21:17:29,020 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,020 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,020 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,021 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,022 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,022 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,022 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,022 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,022 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,022 - ERROR - Task raised exception: 'function' object has no attribute 'collect'
2025-03-21 21:17:29,022 - INFO - Save completed
2025-03-21 21:17:29,022 - INFO - Successfully saved: 0 files
2025-03-21 21:18:11,723 - INFO - Starting application
2025-03-21 21:18:11,723 - INFO - Clearing screen
2025-03-21 21:18:13,193 - INFO - Exiting application
2025-03-21 21:18:15,857 - DEBUG - Using selector: EpollSelector
2025-03-21 21:18:15,857 - INFO - Starting application
2025-03-21 21:18:15,857 - INFO - Clearing screen
2025-03-21 21:18:17,333 - INFO - Selected: Save files
2025-03-21 21:18:17,334 - INFO - Clearing screen
2025-03-21 21:18:20,544 - INFO - Initiating save operation for all
2025-03-21 21:18:20,544 - INFO - Processing all dataframe categories concurrently
2025-03-21 21:18:20,544 - INFO - Queueing category: emr
2025-03-21 21:18:20,545 - INFO - Queueing category: operations
2025-03-21 21:18:20,545 - INFO - Queueing category: netlist
2025-03-21 21:18:20,545 - INFO - Queueing category: bin_dispatch
2025-03-21 21:18:20,545 - INFO - Queueing category: shore_handling
2025-03-21 21:18:20,545 - INFO - Queueing category: stuffing
2025-03-21 21:18:20,546 - INFO - Queueing category: transport
2025-03-21 21:18:20,546 - INFO - Queueing category: miscellaneous
2025-03-21 21:18:20,560 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,561 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,561 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,561 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,561 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,562 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,562 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,562 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,562 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,562 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,562 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,563 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,563 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,563 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,563 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,564 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,564 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,564 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,564 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,564 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,565 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,565 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,565 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,565 - ERROR - Task raised exception: 'function' object has no attribute 'write_csv'
2025-03-21 21:18:20,566 - INFO - Save completed
2025-03-21 21:18:20,566 - INFO - Successfully saved: 0 files
2025-03-21 21:21:51,256 - INFO - Exiting application
2025-03-21 21:21:54,802 - DEBUG - Using selector: EpollSelector
2025-03-21 21:21:54,803 - INFO - Starting application
2025-03-21 21:21:54,803 - INFO - Clearing screen
2025-03-21 21:21:56,552 - INFO - Selected: Save files
2025-03-21 21:21:56,553 - INFO - Clearing screen
2025-03-21 21:22:00,091 - INFO - Initiating save operation for all
2025-03-21 21:22:00,091 - INFO - Processing all dataframe categories concurrently
2025-03-21 21:22:00,091 - INFO - Queueing category: emr
2025-03-21 21:22:00,091 - INFO - Queueing category: operations
2025-03-21 21:22:00,092 - INFO - Queueing category: netlist
2025-03-21 21:22:00,092 - INFO - Queueing category: bin_dispatch
2025-03-21 21:22:00,092 - INFO - Queueing category: shore_handling
2025-03-21 21:22:00,092 - INFO - Queueing category: stuffing
2025-03-21 21:22:00,092 - INFO - Queueing category: transport
2025-03-21 21:22:00,092 - INFO - Queueing category: miscellaneous
2025-03-21 21:22:00,093 - INFO - Processing dataframe shifting of type <class 'function'>
2025-03-21 21:22:00,093 - INFO - Successfully collected dataframe shifting
2025-03-21 21:22:00,095 - INFO - Processing dataframe washing of type <class 'function'>
2025-03-21 21:22:00,095 - INFO - Successfully collected dataframe washing
2025-03-21 21:22:00,095 - INFO - Processing dataframe pti of type <class 'function'>
2025-03-21 21:22:00,096 - INFO - Successfully collected dataframe pti
2025-03-21 21:22:00,096 - INFO - Processing dataframe ops of type <class 'function'>
2025-03-21 21:22:00,097 - INFO - Successfully collected dataframe ops
2025-03-21 21:22:00,098 - INFO - Processing dataframe hatch_to_hatch of type <class 'function'>
2025-03-21 21:22:00,098 - INFO - Successfully collected dataframe hatch_to_hatch
2025-03-21 21:22:00,099 - INFO - Processing dataframe net_list of type <class 'function'>
2025-03-21 21:22:00,099 - INFO - Successfully collected dataframe net_list
2025-03-21 21:22:00,099 - INFO - Processing dataframe iot_container_stuffing of type <class 'function'>
2025-03-21 21:22:00,100 - INFO - Successfully collected dataframe iot_container_stuffing
2025-03-21 21:22:00,100 - INFO - Processing dataframe oss_stuffing of type <class 'function'>
2025-03-21 21:22:00,101 - INFO - Successfully collected dataframe oss_stuffing
2025-03-21 21:22:00,101 - INFO - Processing dataframe full_scows_transfer of type <class 'function'>
2025-03-21 21:22:00,101 - INFO - Successfully collected dataframe full_scows_transfer
2025-03-21 21:22:00,101 - INFO - Processing dataframe empty_scows_transfer of type <class 'function'>
2025-03-21 21:22:00,102 - INFO - Successfully collected dataframe empty_scows_transfer
2025-03-21 21:22:00,102 - ERROR - Error collecting dataframe shifting: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,102 - ERROR - Error collecting dataframe washing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,102 - ERROR - Error collecting dataframe pti: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,102 - ERROR - Error collecting dataframe ops: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,102 - ERROR - Error collecting dataframe hatch_to_hatch: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,102 - ERROR - Error collecting dataframe net_list: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,102 - ERROR - Error collecting dataframe iot_container_stuffing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,103 - ERROR - Error collecting dataframe oss_stuffing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,103 - ERROR - Error collecting dataframe full_scows_transfer: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,103 - INFO - Processing dataframe salt of type <class 'function'>
2025-03-21 21:22:00,103 - INFO - Successfully collected dataframe salt
2025-03-21 21:22:00,103 - INFO - Processing dataframe bin_tipping of type <class 'function'>
2025-03-21 21:22:00,103 - INFO - Successfully collected dataframe bin_tipping
2025-03-21 21:22:00,105 - INFO - Processing dataframe pallet_liner of type <class 'function'>
2025-03-21 21:22:00,105 - INFO - Successfully collected dataframe pallet_liner
2025-03-21 21:22:00,105 - INFO - Processing dataframe container_plugin of type <class 'function'>
2025-03-21 21:22:00,105 - INFO - Successfully collected dataframe container_plugin
2025-03-21 21:22:00,106 - INFO - Processing dataframe shore_crane of type <class 'function'>
2025-03-21 21:22:00,106 - INFO - Successfully collected dataframe shore_crane
2025-03-21 21:22:00,106 - INFO - Processing dataframe transfer of type <class 'function'>
2025-03-21 21:22:00,106 - INFO - Successfully collected dataframe transfer
2025-03-21 21:22:00,107 - INFO - Processing dataframe scow_transfer of type <class 'function'>
2025-03-21 21:22:00,107 - INFO - Successfully collected dataframe scow_transfer
2025-03-21 21:22:00,107 - INFO - Processing dataframe forklift of type <class 'function'>
2025-03-21 21:22:00,107 - INFO - Successfully collected dataframe forklift
2025-03-21 21:22:00,108 - INFO - Processing dataframe static_loader of type <class 'function'>
2025-03-21 21:22:00,108 - INFO - Successfully collected dataframe static_loader
2025-03-21 21:22:00,109 - ERROR - Error collecting dataframe empty_scows_transfer: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,109 - INFO - Processing dataframe dispatch_to_cargo of type <class 'function'>
2025-03-21 21:22:00,109 - INFO - Successfully collected dataframe dispatch_to_cargo
2025-03-21 21:22:00,110 - ERROR - Error collecting dataframe salt: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,110 - ERROR - Error collecting dataframe bin_tipping: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,110 - ERROR - Error collecting dataframe pallet_liner: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,110 - ERROR - Error collecting dataframe container_plugin: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,110 - ERROR - Error collecting dataframe shore_crane: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,110 - ERROR - Error collecting dataframe transfer: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,110 - ERROR - Error collecting dataframe scow_transfer: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,111 - ERROR - Error collecting dataframe forklift: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,111 - ERROR - Error collecting dataframe static_loader: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,111 - INFO - Processing dataframe truck_to_cccs of type <class 'function'>
2025-03-21 21:22:00,111 - INFO - Successfully collected dataframe truck_to_cccs
2025-03-21 21:22:00,111 - INFO - Processing dataframe cross_stuffing of type <class 'function'>
2025-03-21 21:22:00,111 - INFO - Successfully collected dataframe cross_stuffing
2025-03-21 21:22:00,111 - INFO - Processing dataframe cccs_stuffing of type <class 'function'>
2025-03-21 21:22:00,111 - INFO - Successfully collected dataframe cccs_stuffing
2025-03-21 21:22:00,112 - INFO - Processing dataframe bycatch of type <class 'function'>
2025-03-21 21:22:00,112 - INFO - Successfully collected dataframe bycatch
2025-03-21 21:22:00,112 - ERROR - Error collecting dataframe dispatch_to_cargo: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,112 - ERROR - Error collecting dataframe truck_to_cccs: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,112 - ERROR - Error collecting dataframe cross_stuffing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,112 - ERROR - Error collecting dataframe cccs_stuffing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,112 - ERROR - Error collecting dataframe bycatch: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving shifting: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving washing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving pti: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving ops: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving hatch_to_hatch: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving net_list: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving iot_container_stuffing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving oss_stuffing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving full_scows_transfer: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving empty_scows_transfer: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving salt: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving bin_tipping: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving pallet_liner: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving container_plugin: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving shore_crane: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving transfer: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving scow_transfer: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving forklift: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving static_loader: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,113 - ERROR - Error saving dispatch_to_cargo: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - ERROR - Error saving truck_to_cccs: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - ERROR - Error saving cross_stuffing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - ERROR - Error saving cccs_stuffing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - ERROR - Error saving bycatch: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - INFO - Save completed
2025-03-21 21:22:00,114 - INFO - Successfully saved: 0 files
2025-03-21 21:22:00,114 - ERROR - Failed to save: 24 files
2025-03-21 21:22:00,114 - ERROR -   - shifting: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - ERROR -   - washing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - ERROR -   - pti: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - ERROR -   - ops: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - ERROR -   - hatch_to_hatch: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - ERROR -   - net_list: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - ERROR -   - iot_container_stuffing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - ERROR -   - oss_stuffing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - ERROR -   - full_scows_transfer: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - ERROR -   - empty_scows_transfer: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,114 - ERROR -   - salt: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,115 - ERROR -   - bin_tipping: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,115 - ERROR -   - pallet_liner: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,115 - ERROR -   - container_plugin: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,115 - ERROR -   - shore_crane: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,115 - ERROR -   - transfer: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,115 - ERROR -   - scow_transfer: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,115 - ERROR -   - forklift: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,115 - ERROR -   - static_loader: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,115 - ERROR -   - dispatch_to_cargo: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,115 - ERROR -   - truck_to_cccs: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,115 - ERROR -   - cross_stuffing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,115 - ERROR -   - cccs_stuffing: 'function' object has no attribute 'write_csv'
2025-03-21 21:22:00,115 - ERROR -   - bycatch: 'function' object has no attribute 'write_csv'
2025-03-21 21:24:31,762 - INFO - Exiting application
2025-03-21 21:24:35,096 - DEBUG - Using selector: EpollSelector
2025-03-21 21:24:35,096 - INFO - Starting application
2025-03-21 21:24:35,096 - INFO - Clearing screen
2025-03-21 21:24:36,996 - INFO - Selected: Save files
2025-03-21 21:24:36,996 - INFO - Clearing screen
2025-03-21 21:24:43,295 - INFO - Initiating save operation for all
2025-03-21 21:24:43,296 - INFO - Processing all dataframe categories concurrently
2025-03-21 21:24:43,296 - INFO - Queueing category: emr
2025-03-21 21:24:43,296 - INFO - Queueing category: operations
2025-03-21 21:24:43,296 - INFO - Queueing category: netlist
2025-03-21 21:24:43,297 - INFO - Queueing category: bin_dispatch
2025-03-21 21:24:43,297 - INFO - Queueing category: shore_handling
2025-03-21 21:24:43,297 - INFO - Queueing category: stuffing
2025-03-21 21:24:43,297 - INFO - Queueing category: transport
2025-03-21 21:24:43,297 - INFO - Queueing category: miscellaneous
2025-03-21 21:24:43,298 - INFO - Processing dataframe shifting of type <class 'function'>
2025-03-21 21:24:43,298 - INFO - Calling function to get dataframe for shifting
2025-03-21 21:24:43,298 - INFO - Successfully processed dataframe shifting
2025-03-21 21:24:43,299 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,299 - INFO - Processing dataframe washing of type <class 'function'>
2025-03-21 21:24:43,300 - INFO - Calling function to get dataframe for washing
2025-03-21 21:24:43,300 - INFO - Successfully processed dataframe washing
2025-03-21 21:24:43,300 - INFO - Processing dataframe pti of type <class 'function'>
2025-03-21 21:24:43,301 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,301 - INFO - Calling function to get dataframe for pti
2025-03-21 21:24:43,301 - INFO - Successfully processed dataframe pti
2025-03-21 21:24:43,302 - INFO - Processing dataframe ops of type <class 'function'>
2025-03-21 21:24:43,302 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,302 - INFO - Calling function to get dataframe for ops
2025-03-21 21:24:43,302 - INFO - Successfully processed dataframe ops
2025-03-21 21:24:43,302 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,302 - INFO - Processing dataframe hatch_to_hatch of type <class 'function'>
2025-03-21 21:24:43,302 - INFO - Calling function to get dataframe for hatch_to_hatch
2025-03-21 21:24:43,302 - INFO - Successfully processed dataframe hatch_to_hatch
2025-03-21 21:24:43,303 - INFO - Processing dataframe net_list of type <class 'function'>
2025-03-21 21:24:43,303 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,303 - INFO - Calling function to get dataframe for net_list
2025-03-21 21:24:43,303 - INFO - Successfully processed dataframe net_list
2025-03-21 21:24:43,303 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,303 - INFO - Processing dataframe iot_container_stuffing of type <class 'function'>
2025-03-21 21:24:43,303 - INFO - Calling function to get dataframe for iot_container_stuffing
2025-03-21 21:24:43,303 - INFO - Successfully processed dataframe iot_container_stuffing
2025-03-21 21:24:43,303 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,304 - INFO - Processing dataframe oss_stuffing of type <class 'function'>
2025-03-21 21:24:43,304 - INFO - Calling function to get dataframe for oss_stuffing
2025-03-21 21:24:43,304 - INFO - Successfully processed dataframe oss_stuffing
2025-03-21 21:24:43,304 - INFO - Processing dataframe full_scows_transfer of type <class 'function'>
2025-03-21 21:24:43,304 - INFO - Calling function to get dataframe for full_scows_transfer
2025-03-21 21:24:43,304 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,304 - INFO - Successfully processed dataframe full_scows_transfer
2025-03-21 21:24:43,304 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,304 - INFO - Processing dataframe empty_scows_transfer of type <class 'function'>
2025-03-21 21:24:43,305 - INFO - Calling function to get dataframe for empty_scows_transfer
2025-03-21 21:24:43,305 - INFO - Successfully processed dataframe empty_scows_transfer
2025-03-21 21:24:43,305 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,305 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,305 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,305 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,305 - ERROR - Error processing dataframe ops: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,305 - ERROR - Error processing dataframe hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,306 - ERROR - Error processing dataframe net_list: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,306 - ERROR - Error processing dataframe iot_container_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,306 - ERROR - Error processing dataframe oss_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,306 - ERROR - Error processing dataframe full_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,306 - INFO - Processing dataframe salt of type <class 'function'>
2025-03-21 21:24:43,306 - INFO - Calling function to get dataframe for salt
2025-03-21 21:24:43,306 - INFO - Successfully processed dataframe salt
2025-03-21 21:24:43,306 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,306 - INFO - Processing dataframe bin_tipping of type <class 'function'>
2025-03-21 21:24:43,306 - INFO - Calling function to get dataframe for bin_tipping
2025-03-21 21:24:43,306 - INFO - Successfully processed dataframe bin_tipping
2025-03-21 21:24:43,307 - INFO - Processing dataframe pallet_liner of type <class 'function'>
2025-03-21 21:24:43,307 - INFO - Calling function to get dataframe for pallet_liner
2025-03-21 21:24:43,307 - INFO - Successfully processed dataframe pallet_liner
2025-03-21 21:24:43,307 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,307 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,307 - INFO - Processing dataframe container_plugin of type <class 'function'>
2025-03-21 21:24:43,309 - INFO - Calling function to get dataframe for container_plugin
2025-03-21 21:24:43,309 - INFO - Successfully processed dataframe container_plugin
2025-03-21 21:24:43,309 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,309 - INFO - Processing dataframe shore_crane of type <class 'function'>
2025-03-21 21:24:43,309 - INFO - Calling function to get dataframe for shore_crane
2025-03-21 21:24:43,309 - INFO - Successfully processed dataframe shore_crane
2025-03-21 21:24:43,310 - INFO - Processing dataframe transfer of type <class 'function'>
2025-03-21 21:24:43,310 - INFO - Calling function to get dataframe for transfer
2025-03-21 21:24:43,310 - INFO - Successfully processed dataframe transfer
2025-03-21 21:24:43,310 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,310 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,310 - INFO - Processing dataframe scow_transfer of type <class 'function'>
2025-03-21 21:24:43,310 - INFO - Calling function to get dataframe for scow_transfer
2025-03-21 21:24:43,310 - INFO - Successfully processed dataframe scow_transfer
2025-03-21 21:24:43,311 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,311 - INFO - Processing dataframe forklift of type <class 'function'>
2025-03-21 21:24:43,311 - INFO - Calling function to get dataframe for forklift
2025-03-21 21:24:43,311 - INFO - Successfully processed dataframe forklift
2025-03-21 21:24:43,311 - INFO - Processing dataframe static_loader of type <class 'function'>
2025-03-21 21:24:43,311 - INFO - Calling function to get dataframe for static_loader
2025-03-21 21:24:43,311 - INFO - Successfully processed dataframe static_loader
2025-03-21 21:24:43,311 - ERROR - Error processing dataframe empty_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,311 - INFO - Processing dataframe dispatch_to_cargo of type <class 'function'>
2025-03-21 21:24:43,312 - INFO - Calling function to get dataframe for dispatch_to_cargo
2025-03-21 21:24:43,312 - INFO - Successfully processed dataframe dispatch_to_cargo
2025-03-21 21:24:43,312 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,312 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,312 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,312 - ERROR - Error processing dataframe salt: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,312 - ERROR - Error processing dataframe bin_tipping: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,313 - ERROR - Error processing dataframe pallet_liner: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,313 - ERROR - Error processing dataframe container_plugin: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,313 - ERROR - Error processing dataframe shore_crane: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,313 - ERROR - Error processing dataframe transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,313 - ERROR - Error processing dataframe scow_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,313 - INFO - Processing dataframe truck_to_cccs of type <class 'function'>
2025-03-21 21:24:43,313 - INFO - Calling function to get dataframe for truck_to_cccs
2025-03-21 21:24:43,313 - INFO - Successfully processed dataframe truck_to_cccs
2025-03-21 21:24:43,313 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,313 - INFO - Processing dataframe cross_stuffing of type <class 'function'>
2025-03-21 21:24:43,314 - INFO - Calling function to get dataframe for cross_stuffing
2025-03-21 21:24:43,314 - INFO - Successfully processed dataframe cross_stuffing
2025-03-21 21:24:43,314 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,314 - INFO - Processing dataframe cccs_stuffing of type <class 'function'>
2025-03-21 21:24:43,314 - INFO - Calling function to get dataframe for cccs_stuffing
2025-03-21 21:24:43,314 - INFO - Successfully processed dataframe cccs_stuffing
2025-03-21 21:24:43,315 - INFO - Processing dataframe bycatch of type <class 'function'>
2025-03-21 21:24:43,315 - INFO - Calling function to get dataframe for bycatch
2025-03-21 21:24:43,315 - INFO - Successfully processed dataframe bycatch
2025-03-21 21:24:43,315 - ERROR - Error processing dataframe forklift: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,315 - ERROR - Error processing dataframe static_loader: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,315 - ERROR - Error processing dataframe dispatch_to_cargo: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,315 - ERROR - Error processing dataframe truck_to_cccs: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,315 - ERROR - Error processing dataframe cross_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,315 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,315 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,315 - ERROR - Error processing dataframe cccs_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error processing dataframe bycatch: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving washing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving pti: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving ops: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving net_list: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving iot_container_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving oss_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving full_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving empty_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving salt: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving bin_tipping: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving pallet_liner: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving container_plugin: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving shore_crane: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,316 - ERROR - Error saving transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR - Error saving scow_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR - Error saving forklift: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR - Error saving static_loader: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR - Error saving dispatch_to_cargo: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR - Error saving truck_to_cccs: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR - Error saving cross_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR - Error saving cccs_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR - Error saving bycatch: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - INFO - Save completed
2025-03-21 21:24:43,317 - INFO - Successfully saved: 0 files
2025-03-21 21:24:43,317 - ERROR - Failed to save: 24 files
2025-03-21 21:24:43,317 - ERROR -   - shifting: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR -   - washing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR -   - pti: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR -   - ops: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR -   - hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR -   - net_list: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR -   - iot_container_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR -   - oss_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR -   - full_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,317 - ERROR -   - empty_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,318 - ERROR -   - salt: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,318 - ERROR -   - bin_tipping: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,318 - ERROR -   - pallet_liner: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,318 - ERROR -   - container_plugin: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,318 - ERROR -   - shore_crane: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,318 - ERROR -   - transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,318 - ERROR -   - scow_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,318 - ERROR -   - forklift: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,318 - ERROR -   - static_loader: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,318 - ERROR -   - dispatch_to_cargo: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,318 - ERROR -   - truck_to_cccs: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,318 - ERROR -   - cross_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,318 - ERROR -   - cccs_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:24:43,318 - ERROR -   - bycatch: 'coroutine' object has no attribute 'write_csv'
2025-03-21 21:31:01,065 - DEBUG - Using selector: EpollSelector
2025-03-21 21:31:01,066 - INFO - Starting application
2025-03-21 21:31:01,066 - INFO - Clearing screen
2025-03-21 21:31:03,527 - INFO - Selected: Save files
2025-03-21 21:31:03,527 - INFO - Clearing screen
2025-03-21 21:31:07,340 - INFO - Initiating save operation for all
2025-03-21 21:31:07,340 - INFO - Processing all dataframe categories concurrently
2025-03-21 21:31:07,341 - INFO - Queueing category: emr
2025-03-21 21:31:07,341 - INFO - Queueing category: operations
2025-03-21 21:31:07,341 - INFO - Queueing category: netlist
2025-03-21 21:31:07,342 - INFO - Queueing category: bin_dispatch
2025-03-21 21:31:07,342 - INFO - Queueing category: shore_handling
2025-03-21 21:31:07,342 - INFO - Queueing category: stuffing
2025-03-21 21:31:07,343 - INFO - Queueing category: transport
2025-03-21 21:31:07,343 - INFO - Queueing category: miscellaneous
2025-03-21 21:31:07,344 - INFO - Processing dataframe shifting of type <class 'function'>
2025-03-21 21:31:07,344 - INFO - Callable found for shifting, checking if it's a coroutine
2025-03-21 21:31:07,344 - INFO - Awaiting coroutine to get dataframe for shifting
2025-03-21 21:31:07,345 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:31:07,345 - INFO - Processing dataframe washing of type <class 'function'>
2025-03-21 21:31:07,345 - INFO - Callable found for washing, checking if it's a coroutine
2025-03-21 21:31:07,345 - INFO - Awaiting coroutine to get dataframe for washing
2025-03-21 21:31:07,345 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,346 - INFO - Processing dataframe pti of type <class 'function'>
2025-03-21 21:31:07,346 - INFO - Callable found for pti, checking if it's a coroutine
2025-03-21 21:31:07,346 - INFO - Awaiting coroutine to get dataframe for pti
2025-03-21 21:31:07,346 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:31:07,347 - INFO - Processing dataframe ops of type <class 'function'>
2025-03-21 21:31:07,347 - INFO - Callable found for ops, checking if it's a coroutine
2025-03-21 21:31:07,347 - INFO - Awaiting coroutine to get dataframe for ops
2025-03-21 21:31:07,347 - ERROR - Error processing dataframe ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,348 - INFO - Processing dataframe hatch_to_hatch of type <class 'function'>
2025-03-21 21:31:07,348 - INFO - Callable found for hatch_to_hatch, checking if it's a coroutine
2025-03-21 21:31:07,348 - INFO - Awaiting coroutine to get dataframe for hatch_to_hatch
2025-03-21 21:31:07,348 - ERROR - Error processing dataframe hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,348 - INFO - Processing dataframe net_list of type <class 'function'>
2025-03-21 21:31:07,348 - INFO - Callable found for net_list, checking if it's a coroutine
2025-03-21 21:31:07,349 - INFO - Awaiting coroutine to get dataframe for net_list
2025-03-21 21:31:07,349 - ERROR - Error processing dataframe net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,349 - INFO - Processing dataframe iot_container_stuffing of type <class 'function'>
2025-03-21 21:31:07,349 - INFO - Callable found for iot_container_stuffing, checking if it's a coroutine
2025-03-21 21:31:07,349 - INFO - Awaiting coroutine to get dataframe for iot_container_stuffing
2025-03-21 21:31:07,349 - ERROR - Error processing dataframe iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,350 - INFO - Processing dataframe oss_stuffing of type <class 'function'>
2025-03-21 21:31:07,350 - INFO - Callable found for oss_stuffing, checking if it's a coroutine
2025-03-21 21:31:07,350 - INFO - Awaiting coroutine to get dataframe for oss_stuffing
2025-03-21 21:31:07,350 - ERROR - Error processing dataframe oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,350 - INFO - Processing dataframe full_scows_transfer of type <class 'function'>
2025-03-21 21:31:07,350 - INFO - Callable found for full_scows_transfer, checking if it's a coroutine
2025-03-21 21:31:07,350 - INFO - Awaiting coroutine to get dataframe for full_scows_transfer
2025-03-21 21:31:07,350 - ERROR - Error processing dataframe full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,351 - INFO - Processing dataframe empty_scows_transfer of type <class 'function'>
2025-03-21 21:31:07,351 - INFO - Callable found for empty_scows_transfer, checking if it's a coroutine
2025-03-21 21:31:07,351 - INFO - Awaiting coroutine to get dataframe for empty_scows_transfer
2025-03-21 21:31:07,351 - ERROR - Error processing dataframe empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,351 - INFO - Processing dataframe salt of type <class 'function'>
2025-03-21 21:31:07,351 - INFO - Callable found for salt, checking if it's a coroutine
2025-03-21 21:31:07,351 - INFO - Awaiting coroutine to get dataframe for salt
2025-03-21 21:31:07,352 - ERROR - Error processing dataframe salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,352 - INFO - Processing dataframe bin_tipping of type <class 'function'>
2025-03-21 21:31:07,352 - INFO - Callable found for bin_tipping, checking if it's a coroutine
2025-03-21 21:31:07,352 - INFO - Awaiting coroutine to get dataframe for bin_tipping
2025-03-21 21:31:07,352 - ERROR - Error processing dataframe bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,352 - INFO - Processing dataframe pallet_liner of type <class 'function'>
2025-03-21 21:31:07,352 - INFO - Callable found for pallet_liner, checking if it's a coroutine
2025-03-21 21:31:07,352 - INFO - Awaiting coroutine to get dataframe for pallet_liner
2025-03-21 21:31:07,353 - ERROR - Error processing dataframe pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:31:07,353 - INFO - Processing dataframe container_plugin of type <class 'function'>
2025-03-21 21:31:07,353 - INFO - Callable found for container_plugin, checking if it's a coroutine
2025-03-21 21:31:07,353 - INFO - Awaiting coroutine to get dataframe for container_plugin
2025-03-21 21:31:07,353 - ERROR - Error processing dataframe container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,353 - INFO - Processing dataframe shore_crane of type <class 'function'>
2025-03-21 21:31:07,353 - INFO - Callable found for shore_crane, checking if it's a coroutine
2025-03-21 21:31:07,354 - INFO - Awaiting coroutine to get dataframe for shore_crane
2025-03-21 21:31:07,354 - ERROR - Error processing dataframe shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,354 - INFO - Processing dataframe transfer of type <class 'function'>
2025-03-21 21:31:07,354 - INFO - Callable found for transfer, checking if it's a coroutine
2025-03-21 21:31:07,354 - INFO - Awaiting coroutine to get dataframe for transfer
2025-03-21 21:31:07,354 - ERROR - Error processing dataframe transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:31:07,354 - INFO - Processing dataframe scow_transfer of type <class 'function'>
2025-03-21 21:31:07,354 - INFO - Callable found for scow_transfer, checking if it's a coroutine
2025-03-21 21:31:07,354 - INFO - Awaiting coroutine to get dataframe for scow_transfer
2025-03-21 21:31:07,354 - ERROR - Error processing dataframe scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,355 - INFO - Processing dataframe forklift of type <class 'function'>
2025-03-21 21:31:07,355 - INFO - Callable found for forklift, checking if it's a coroutine
2025-03-21 21:31:07,355 - INFO - Awaiting coroutine to get dataframe for forklift
2025-03-21 21:31:07,355 - ERROR - Error processing dataframe forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,355 - INFO - Processing dataframe static_loader of type <class 'function'>
2025-03-21 21:31:07,355 - INFO - Callable found for static_loader, checking if it's a coroutine
2025-03-21 21:31:07,355 - INFO - Awaiting coroutine to get dataframe for static_loader
2025-03-21 21:31:07,355 - ERROR - Error processing dataframe static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,355 - INFO - Processing dataframe dispatch_to_cargo of type <class 'function'>
2025-03-21 21:31:07,355 - INFO - Callable found for dispatch_to_cargo, checking if it's a coroutine
2025-03-21 21:31:07,355 - INFO - Awaiting coroutine to get dataframe for dispatch_to_cargo
2025-03-21 21:31:07,355 - ERROR - Error processing dataframe dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,356 - INFO - Processing dataframe truck_to_cccs of type <class 'function'>
2025-03-21 21:31:07,356 - INFO - Callable found for truck_to_cccs, checking if it's a coroutine
2025-03-21 21:31:07,356 - INFO - Awaiting coroutine to get dataframe for truck_to_cccs
2025-03-21 21:31:07,356 - ERROR - Error processing dataframe truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,356 - INFO - Processing dataframe cross_stuffing of type <class 'function'>
2025-03-21 21:31:07,356 - INFO - Callable found for cross_stuffing, checking if it's a coroutine
2025-03-21 21:31:07,356 - INFO - Awaiting coroutine to get dataframe for cross_stuffing
2025-03-21 21:31:07,356 - ERROR - Error processing dataframe cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:31:07,356 - INFO - Processing dataframe cccs_stuffing of type <class 'function'>
2025-03-21 21:31:07,356 - INFO - Callable found for cccs_stuffing, checking if it's a coroutine
2025-03-21 21:31:07,356 - INFO - Awaiting coroutine to get dataframe for cccs_stuffing
2025-03-21 21:31:07,356 - ERROR - Error processing dataframe cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:31:07,357 - INFO - Processing dataframe bycatch of type <class 'function'>
2025-03-21 21:31:07,357 - INFO - Callable found for bycatch, checking if it's a coroutine
2025-03-21 21:31:07,357 - INFO - Awaiting coroutine to get dataframe for bycatch
2025-03-21 21:31:07,357 - ERROR - Error processing dataframe bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:31:07,357 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:31:07,357 - ERROR - Error saving washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,357 - ERROR - Error saving pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:31:07,357 - ERROR - Error saving ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,357 - ERROR - Error saving hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,358 - ERROR - Error saving net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,358 - ERROR - Error saving iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,358 - ERROR - Error saving oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,360 - ERROR - Error saving full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,360 - ERROR - Error saving empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,360 - ERROR - Error saving salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,360 - ERROR - Error saving bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,360 - ERROR - Error saving pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:31:07,360 - ERROR - Error saving container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,360 - ERROR - Error saving shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,361 - ERROR - Error saving transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:31:07,361 - ERROR - Error saving scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,361 - ERROR - Error saving forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,361 - ERROR - Error saving static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,361 - ERROR - Error saving dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,361 - ERROR - Error saving truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,361 - ERROR - Error saving cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:31:07,361 - ERROR - Error saving cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:31:07,361 - ERROR - Error saving bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:31:07,361 - INFO - Save completed
2025-03-21 21:31:07,361 - INFO - Successfully saved: 0 files
2025-03-21 21:31:07,361 - ERROR - Failed to save: 24 files
2025-03-21 21:31:07,362 - ERROR -   - shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:31:07,362 - ERROR -   - washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,362 - ERROR -   - pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:31:07,362 - ERROR -   - ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,362 - ERROR -   - hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,362 - ERROR -   - net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,362 - ERROR -   - iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,362 - ERROR -   - oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,362 - ERROR -   - full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,362 - ERROR -   - empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,362 - ERROR -   - salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,362 - ERROR -   - bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,362 - ERROR -   - pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:31:07,363 - ERROR -   - container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,363 - ERROR -   - shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,363 - ERROR -   - transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:31:07,363 - ERROR -   - scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,363 - ERROR -   - forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,364 - ERROR -   - static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:31:07,364 - ERROR -   - dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,364 - ERROR -   - truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:31:07,364 - ERROR -   - cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:31:07,364 - ERROR -   - cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:31:07,364 - ERROR -   - bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:33:19,076 - INFO - Exiting application
2025-03-21 21:33:21,246 - DEBUG - Using selector: EpollSelector
2025-03-21 21:33:21,246 - INFO - Starting application
2025-03-21 21:33:21,246 - INFO - Clearing screen
2025-03-21 21:33:24,042 - INFO - Selected: Save files
2025-03-21 21:33:24,043 - INFO - Clearing screen
2025-03-21 21:33:28,796 - INFO - Initiating save operation for all
2025-03-21 21:33:28,797 - INFO - Processing all dataframe categories concurrently
2025-03-21 21:33:28,797 - INFO - Queueing category: emr
2025-03-21 21:33:28,797 - INFO - Queueing category: operations
2025-03-21 21:33:28,798 - INFO - Queueing category: netlist
2025-03-21 21:33:28,798 - INFO - Queueing category: bin_dispatch
2025-03-21 21:33:28,798 - INFO - Queueing category: shore_handling
2025-03-21 21:33:28,798 - INFO - Queueing category: stuffing
2025-03-21 21:33:28,799 - INFO - Queueing category: transport
2025-03-21 21:33:28,799 - INFO - Queueing category: miscellaneous
2025-03-21 21:33:28,800 - INFO - Processing dataframe shifting of type <class 'function'>
2025-03-21 21:33:28,800 - INFO - Callable found for shifting, checking if it's a coroutine function
2025-03-21 21:33:28,801 - INFO - shifting is a coroutine function, awaiting it
2025-03-21 21:33:28,801 - ERROR - Error in get_actual_df for shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:33:28,801 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:33:28,802 - INFO - Processing dataframe washing of type <class 'function'>
2025-03-21 21:33:28,802 - INFO - Callable found for washing, checking if it's a coroutine function
2025-03-21 21:33:28,803 - INFO - washing is a coroutine function, awaiting it
2025-03-21 21:33:28,803 - ERROR - Error in get_actual_df for washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,803 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,804 - INFO - Processing dataframe pti of type <class 'function'>
2025-03-21 21:33:28,804 - INFO - Callable found for pti, checking if it's a coroutine function
2025-03-21 21:33:28,805 - INFO - pti is a coroutine function, awaiting it
2025-03-21 21:33:28,805 - ERROR - Error in get_actual_df for pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:33:28,805 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:33:28,805 - INFO - Processing dataframe ops of type <class 'function'>
2025-03-21 21:33:28,806 - INFO - Callable found for ops, checking if it's a coroutine function
2025-03-21 21:33:28,806 - INFO - ops is a coroutine function, awaiting it
2025-03-21 21:33:28,806 - ERROR - Error in get_actual_df for ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,806 - ERROR - Error processing dataframe ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,807 - INFO - Processing dataframe hatch_to_hatch of type <class 'function'>
2025-03-21 21:33:28,807 - INFO - Callable found for hatch_to_hatch, checking if it's a coroutine function
2025-03-21 21:33:28,807 - INFO - hatch_to_hatch is a coroutine function, awaiting it
2025-03-21 21:33:28,807 - ERROR - Error in get_actual_df for hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,808 - ERROR - Error processing dataframe hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,808 - INFO - Processing dataframe net_list of type <class 'function'>
2025-03-21 21:33:28,808 - INFO - Callable found for net_list, checking if it's a coroutine function
2025-03-21 21:33:28,809 - INFO - net_list is a coroutine function, awaiting it
2025-03-21 21:33:28,809 - ERROR - Error in get_actual_df for net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,809 - ERROR - Error processing dataframe net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,809 - INFO - Processing dataframe iot_container_stuffing of type <class 'function'>
2025-03-21 21:33:28,810 - INFO - Callable found for iot_container_stuffing, checking if it's a coroutine function
2025-03-21 21:33:28,810 - INFO - iot_container_stuffing is a coroutine function, awaiting it
2025-03-21 21:33:28,810 - ERROR - Error in get_actual_df for iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,810 - ERROR - Error processing dataframe iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,811 - INFO - Processing dataframe oss_stuffing of type <class 'function'>
2025-03-21 21:33:28,811 - INFO - Callable found for oss_stuffing, checking if it's a coroutine function
2025-03-21 21:33:28,811 - INFO - oss_stuffing is a coroutine function, awaiting it
2025-03-21 21:33:28,811 - ERROR - Error in get_actual_df for oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,812 - ERROR - Error processing dataframe oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,812 - INFO - Processing dataframe full_scows_transfer of type <class 'function'>
2025-03-21 21:33:28,812 - INFO - Callable found for full_scows_transfer, checking if it's a coroutine function
2025-03-21 21:33:28,813 - INFO - full_scows_transfer is a coroutine function, awaiting it
2025-03-21 21:33:28,813 - ERROR - Error in get_actual_df for full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,813 - ERROR - Error processing dataframe full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,813 - INFO - Processing dataframe empty_scows_transfer of type <class 'function'>
2025-03-21 21:33:28,814 - INFO - Callable found for empty_scows_transfer, checking if it's a coroutine function
2025-03-21 21:33:28,814 - INFO - empty_scows_transfer is a coroutine function, awaiting it
2025-03-21 21:33:28,814 - ERROR - Error in get_actual_df for empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,815 - ERROR - Error processing dataframe empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,815 - INFO - Processing dataframe salt of type <class 'function'>
2025-03-21 21:33:28,815 - INFO - Callable found for salt, checking if it's a coroutine function
2025-03-21 21:33:28,815 - INFO - salt is a coroutine function, awaiting it
2025-03-21 21:33:28,815 - ERROR - Error in get_actual_df for salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,816 - ERROR - Error processing dataframe salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,816 - INFO - Processing dataframe bin_tipping of type <class 'function'>
2025-03-21 21:33:28,816 - INFO - Callable found for bin_tipping, checking if it's a coroutine function
2025-03-21 21:33:28,816 - INFO - bin_tipping is a coroutine function, awaiting it
2025-03-21 21:33:28,816 - ERROR - Error in get_actual_df for bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,816 - ERROR - Error processing dataframe bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,817 - INFO - Processing dataframe pallet_liner of type <class 'function'>
2025-03-21 21:33:28,817 - INFO - Callable found for pallet_liner, checking if it's a coroutine function
2025-03-21 21:33:28,817 - INFO - pallet_liner is a coroutine function, awaiting it
2025-03-21 21:33:28,817 - ERROR - Error in get_actual_df for pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:33:28,817 - ERROR - Error processing dataframe pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:33:28,818 - INFO - Processing dataframe container_plugin of type <class 'function'>
2025-03-21 21:33:28,818 - INFO - Callable found for container_plugin, checking if it's a coroutine function
2025-03-21 21:33:28,818 - INFO - container_plugin is a coroutine function, awaiting it
2025-03-21 21:33:28,818 - ERROR - Error in get_actual_df for container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,818 - ERROR - Error processing dataframe container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,819 - INFO - Processing dataframe shore_crane of type <class 'function'>
2025-03-21 21:33:28,819 - INFO - Callable found for shore_crane, checking if it's a coroutine function
2025-03-21 21:33:28,819 - INFO - shore_crane is a coroutine function, awaiting it
2025-03-21 21:33:28,819 - ERROR - Error in get_actual_df for shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,819 - ERROR - Error processing dataframe shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,820 - INFO - Processing dataframe transfer of type <class 'function'>
2025-03-21 21:33:28,820 - INFO - Callable found for transfer, checking if it's a coroutine function
2025-03-21 21:33:28,820 - INFO - transfer is a coroutine function, awaiting it
2025-03-21 21:33:28,820 - ERROR - Error in get_actual_df for transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:33:28,821 - ERROR - Error processing dataframe transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:33:28,821 - INFO - Processing dataframe scow_transfer of type <class 'function'>
2025-03-21 21:33:28,821 - INFO - Callable found for scow_transfer, checking if it's a coroutine function
2025-03-21 21:33:28,821 - INFO - scow_transfer is a coroutine function, awaiting it
2025-03-21 21:33:28,821 - ERROR - Error in get_actual_df for scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,822 - ERROR - Error processing dataframe scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,822 - INFO - Processing dataframe forklift of type <class 'function'>
2025-03-21 21:33:28,822 - INFO - Callable found for forklift, checking if it's a coroutine function
2025-03-21 21:33:28,822 - INFO - forklift is a coroutine function, awaiting it
2025-03-21 21:33:28,822 - ERROR - Error in get_actual_df for forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,823 - ERROR - Error processing dataframe forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,823 - INFO - Processing dataframe static_loader of type <class 'function'>
2025-03-21 21:33:28,823 - INFO - Callable found for static_loader, checking if it's a coroutine function
2025-03-21 21:33:28,823 - INFO - static_loader is a coroutine function, awaiting it
2025-03-21 21:33:28,824 - ERROR - Error in get_actual_df for static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,824 - ERROR - Error processing dataframe static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,824 - INFO - Processing dataframe dispatch_to_cargo of type <class 'function'>
2025-03-21 21:33:28,824 - INFO - Callable found for dispatch_to_cargo, checking if it's a coroutine function
2025-03-21 21:33:28,825 - INFO - dispatch_to_cargo is a coroutine function, awaiting it
2025-03-21 21:33:28,825 - ERROR - Error in get_actual_df for dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,825 - ERROR - Error processing dataframe dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,825 - INFO - Processing dataframe truck_to_cccs of type <class 'function'>
2025-03-21 21:33:28,826 - INFO - Callable found for truck_to_cccs, checking if it's a coroutine function
2025-03-21 21:33:28,826 - INFO - truck_to_cccs is a coroutine function, awaiting it
2025-03-21 21:33:28,826 - ERROR - Error in get_actual_df for truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,826 - ERROR - Error processing dataframe truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,827 - INFO - Processing dataframe cross_stuffing of type <class 'function'>
2025-03-21 21:33:28,827 - INFO - Callable found for cross_stuffing, checking if it's a coroutine function
2025-03-21 21:33:28,827 - INFO - cross_stuffing is a coroutine function, awaiting it
2025-03-21 21:33:28,827 - ERROR - Error in get_actual_df for cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:33:28,828 - ERROR - Error processing dataframe cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:33:28,828 - INFO - Processing dataframe cccs_stuffing of type <class 'function'>
2025-03-21 21:33:28,829 - INFO - Callable found for cccs_stuffing, checking if it's a coroutine function
2025-03-21 21:33:28,829 - INFO - cccs_stuffing is a coroutine function, awaiting it
2025-03-21 21:33:28,829 - ERROR - Error in get_actual_df for cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:33:28,829 - ERROR - Error processing dataframe cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:33:28,829 - INFO - Processing dataframe bycatch of type <class 'function'>
2025-03-21 21:33:28,830 - INFO - Callable found for bycatch, checking if it's a coroutine function
2025-03-21 21:33:28,830 - INFO - bycatch is a coroutine function, awaiting it
2025-03-21 21:33:28,830 - ERROR - Error in get_actual_df for bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:33:28,830 - ERROR - Error processing dataframe bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:33:28,831 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:33:28,831 - ERROR - Error saving washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,831 - ERROR - Error saving pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:33:28,831 - ERROR - Error saving ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,832 - ERROR - Error saving hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,832 - ERROR - Error saving net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,832 - ERROR - Error saving iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,832 - ERROR - Error saving oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,832 - ERROR - Error saving full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,832 - ERROR - Error saving empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,833 - ERROR - Error saving salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,833 - ERROR - Error saving bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,833 - ERROR - Error saving pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:33:28,833 - ERROR - Error saving container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,833 - ERROR - Error saving shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,834 - ERROR - Error saving transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:33:28,834 - ERROR - Error saving scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,834 - ERROR - Error saving forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,834 - ERROR - Error saving static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,834 - ERROR - Error saving dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,834 - ERROR - Error saving truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,835 - ERROR - Error saving cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:33:28,835 - ERROR - Error saving cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:33:28,835 - ERROR - Error saving bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:33:28,835 - INFO - Save completed
2025-03-21 21:33:28,835 - INFO - Successfully saved: 0 files
2025-03-21 21:33:28,836 - ERROR - Failed to save: 24 files
2025-03-21 21:33:28,836 - ERROR -   - shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:33:28,836 - ERROR -   - washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,836 - ERROR -   - pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:33:28,836 - ERROR -   - ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,836 - ERROR -   - hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,837 - ERROR -   - net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,837 - ERROR -   - iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,837 - ERROR -   - oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,837 - ERROR -   - full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,837 - ERROR -   - empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,837 - ERROR -   - salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,837 - ERROR -   - bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,838 - ERROR -   - pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:33:28,838 - ERROR -   - container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,838 - ERROR -   - shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,838 - ERROR -   - transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:33:28,838 - ERROR -   - scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,838 - ERROR -   - forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,838 - ERROR -   - static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:33:28,839 - ERROR -   - dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,839 - ERROR -   - truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:33:28,839 - ERROR -   - cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:33:28,839 - ERROR -   - cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:33:28,839 - ERROR -   - bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:33:45,459 - INFO - Exiting application
2025-03-21 21:33:59,696 - DEBUG - Using selector: EpollSelector
2025-03-21 21:33:59,696 - INFO - Starting application
2025-03-21 21:33:59,696 - INFO - Clearing screen
2025-03-21 21:34:01,988 - INFO - Selected: Save files
2025-03-21 21:34:01,988 - INFO - Clearing screen
2025-03-21 21:34:07,343 - INFO - Initiating save operation for all
2025-03-21 21:34:07,343 - INFO - Processing all dataframe categories concurrently
2025-03-21 21:34:07,344 - INFO - Queueing category: emr
2025-03-21 21:34:07,344 - INFO - Queueing category: operations
2025-03-21 21:34:07,344 - INFO - Queueing category: netlist
2025-03-21 21:34:07,345 - INFO - Queueing category: bin_dispatch
2025-03-21 21:34:07,345 - INFO - Queueing category: shore_handling
2025-03-21 21:34:07,345 - INFO - Queueing category: stuffing
2025-03-21 21:34:07,345 - INFO - Queueing category: transport
2025-03-21 21:34:07,346 - INFO - Queueing category: miscellaneous
2025-03-21 21:34:07,347 - INFO - Processing dataframe shifting of type <class 'function'>
2025-03-21 21:34:07,347 - INFO - Callable found for shifting, checking if it's a coroutine function
2025-03-21 21:34:07,347 - INFO - shifting is a coroutine function, awaiting it
2025-03-21 21:34:07,347 - ERROR - Error in get_actual_df for shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:34:07,348 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:34:07,348 - INFO - Processing dataframe washing of type <class 'function'>
2025-03-21 21:34:07,348 - INFO - Callable found for washing, checking if it's a coroutine function
2025-03-21 21:34:07,349 - INFO - washing is a coroutine function, awaiting it
2025-03-21 21:34:07,349 - ERROR - Error in get_actual_df for washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,349 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,350 - INFO - Processing dataframe pti of type <class 'function'>
2025-03-21 21:34:07,350 - INFO - Callable found for pti, checking if it's a coroutine function
2025-03-21 21:34:07,350 - INFO - pti is a coroutine function, awaiting it
2025-03-21 21:34:07,350 - ERROR - Error in get_actual_df for pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:34:07,351 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:34:07,351 - INFO - Processing dataframe ops of type <class 'function'>
2025-03-21 21:34:07,351 - INFO - Callable found for ops, checking if it's a coroutine function
2025-03-21 21:34:07,352 - INFO - ops is a coroutine function, awaiting it
2025-03-21 21:34:07,352 - ERROR - Error in get_actual_df for ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,352 - ERROR - Error processing dataframe ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,352 - INFO - Processing dataframe hatch_to_hatch of type <class 'function'>
2025-03-21 21:34:07,353 - INFO - Callable found for hatch_to_hatch, checking if it's a coroutine function
2025-03-21 21:34:07,353 - INFO - hatch_to_hatch is a coroutine function, awaiting it
2025-03-21 21:34:07,353 - ERROR - Error in get_actual_df for hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,353 - ERROR - Error processing dataframe hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,354 - INFO - Processing dataframe net_list of type <class 'function'>
2025-03-21 21:34:07,354 - INFO - Callable found for net_list, checking if it's a coroutine function
2025-03-21 21:34:07,354 - INFO - net_list is a coroutine function, awaiting it
2025-03-21 21:34:07,354 - ERROR - Error in get_actual_df for net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,355 - ERROR - Error processing dataframe net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,355 - INFO - Processing dataframe iot_container_stuffing of type <class 'function'>
2025-03-21 21:34:07,355 - INFO - Callable found for iot_container_stuffing, checking if it's a coroutine function
2025-03-21 21:34:07,356 - INFO - iot_container_stuffing is a coroutine function, awaiting it
2025-03-21 21:34:07,356 - ERROR - Error in get_actual_df for iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,356 - ERROR - Error processing dataframe iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,356 - INFO - Processing dataframe oss_stuffing of type <class 'function'>
2025-03-21 21:34:07,357 - INFO - Callable found for oss_stuffing, checking if it's a coroutine function
2025-03-21 21:34:07,357 - INFO - oss_stuffing is a coroutine function, awaiting it
2025-03-21 21:34:07,357 - ERROR - Error in get_actual_df for oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,357 - ERROR - Error processing dataframe oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,358 - INFO - Processing dataframe full_scows_transfer of type <class 'function'>
2025-03-21 21:34:07,358 - INFO - Callable found for full_scows_transfer, checking if it's a coroutine function
2025-03-21 21:34:07,358 - INFO - full_scows_transfer is a coroutine function, awaiting it
2025-03-21 21:34:07,358 - ERROR - Error in get_actual_df for full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,359 - ERROR - Error processing dataframe full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,359 - INFO - Processing dataframe empty_scows_transfer of type <class 'function'>
2025-03-21 21:34:07,359 - INFO - Callable found for empty_scows_transfer, checking if it's a coroutine function
2025-03-21 21:34:07,359 - INFO - empty_scows_transfer is a coroutine function, awaiting it
2025-03-21 21:34:07,360 - ERROR - Error in get_actual_df for empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,360 - ERROR - Error processing dataframe empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,360 - INFO - Processing dataframe salt of type <class 'function'>
2025-03-21 21:34:07,360 - INFO - Callable found for salt, checking if it's a coroutine function
2025-03-21 21:34:07,361 - INFO - salt is a coroutine function, awaiting it
2025-03-21 21:34:07,361 - ERROR - Error in get_actual_df for salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,361 - ERROR - Error processing dataframe salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,361 - INFO - Processing dataframe bin_tipping of type <class 'function'>
2025-03-21 21:34:07,362 - INFO - Callable found for bin_tipping, checking if it's a coroutine function
2025-03-21 21:34:07,362 - INFO - bin_tipping is a coroutine function, awaiting it
2025-03-21 21:34:07,362 - ERROR - Error in get_actual_df for bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,362 - ERROR - Error processing dataframe bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,363 - INFO - Processing dataframe pallet_liner of type <class 'function'>
2025-03-21 21:34:07,363 - INFO - Callable found for pallet_liner, checking if it's a coroutine function
2025-03-21 21:34:07,363 - INFO - pallet_liner is a coroutine function, awaiting it
2025-03-21 21:34:07,363 - ERROR - Error in get_actual_df for pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:34:07,363 - ERROR - Error processing dataframe pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:34:07,364 - INFO - Processing dataframe container_plugin of type <class 'function'>
2025-03-21 21:34:07,364 - INFO - Callable found for container_plugin, checking if it's a coroutine function
2025-03-21 21:34:07,364 - INFO - container_plugin is a coroutine function, awaiting it
2025-03-21 21:34:07,365 - ERROR - Error in get_actual_df for container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,365 - ERROR - Error processing dataframe container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,365 - INFO - Processing dataframe shore_crane of type <class 'function'>
2025-03-21 21:34:07,365 - INFO - Callable found for shore_crane, checking if it's a coroutine function
2025-03-21 21:34:07,366 - INFO - shore_crane is a coroutine function, awaiting it
2025-03-21 21:34:07,366 - ERROR - Error in get_actual_df for shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,366 - ERROR - Error processing dataframe shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,367 - INFO - Processing dataframe transfer of type <class 'function'>
2025-03-21 21:34:07,367 - INFO - Callable found for transfer, checking if it's a coroutine function
2025-03-21 21:34:07,367 - INFO - transfer is a coroutine function, awaiting it
2025-03-21 21:34:07,367 - ERROR - Error in get_actual_df for transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:34:07,368 - ERROR - Error processing dataframe transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:34:07,368 - INFO - Processing dataframe scow_transfer of type <class 'function'>
2025-03-21 21:34:07,368 - INFO - Callable found for scow_transfer, checking if it's a coroutine function
2025-03-21 21:34:07,368 - INFO - scow_transfer is a coroutine function, awaiting it
2025-03-21 21:34:07,369 - ERROR - Error in get_actual_df for scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,369 - ERROR - Error processing dataframe scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,369 - INFO - Processing dataframe forklift of type <class 'function'>
2025-03-21 21:34:07,369 - INFO - Callable found for forklift, checking if it's a coroutine function
2025-03-21 21:34:07,370 - INFO - forklift is a coroutine function, awaiting it
2025-03-21 21:34:07,370 - ERROR - Error in get_actual_df for forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,370 - ERROR - Error processing dataframe forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,370 - INFO - Processing dataframe static_loader of type <class 'function'>
2025-03-21 21:34:07,371 - INFO - Callable found for static_loader, checking if it's a coroutine function
2025-03-21 21:34:07,371 - INFO - static_loader is a coroutine function, awaiting it
2025-03-21 21:34:07,371 - ERROR - Error in get_actual_df for static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,371 - ERROR - Error processing dataframe static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,372 - INFO - Processing dataframe dispatch_to_cargo of type <class 'function'>
2025-03-21 21:34:07,372 - INFO - Callable found for dispatch_to_cargo, checking if it's a coroutine function
2025-03-21 21:34:07,372 - INFO - dispatch_to_cargo is a coroutine function, awaiting it
2025-03-21 21:34:07,372 - ERROR - Error in get_actual_df for dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,373 - ERROR - Error processing dataframe dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,373 - INFO - Processing dataframe truck_to_cccs of type <class 'function'>
2025-03-21 21:34:07,373 - INFO - Callable found for truck_to_cccs, checking if it's a coroutine function
2025-03-21 21:34:07,373 - INFO - truck_to_cccs is a coroutine function, awaiting it
2025-03-21 21:34:07,373 - ERROR - Error in get_actual_df for truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,374 - ERROR - Error processing dataframe truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,374 - INFO - Processing dataframe cross_stuffing of type <class 'function'>
2025-03-21 21:34:07,374 - INFO - Callable found for cross_stuffing, checking if it's a coroutine function
2025-03-21 21:34:07,374 - INFO - cross_stuffing is a coroutine function, awaiting it
2025-03-21 21:34:07,375 - ERROR - Error in get_actual_df for cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:34:07,375 - ERROR - Error processing dataframe cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:34:07,375 - INFO - Processing dataframe cccs_stuffing of type <class 'function'>
2025-03-21 21:34:07,376 - INFO - Callable found for cccs_stuffing, checking if it's a coroutine function
2025-03-21 21:34:07,376 - INFO - cccs_stuffing is a coroutine function, awaiting it
2025-03-21 21:34:07,376 - ERROR - Error in get_actual_df for cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:34:07,376 - ERROR - Error processing dataframe cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:34:07,376 - INFO - Processing dataframe bycatch of type <class 'function'>
2025-03-21 21:34:07,376 - INFO - Callable found for bycatch, checking if it's a coroutine function
2025-03-21 21:34:07,376 - INFO - bycatch is a coroutine function, awaiting it
2025-03-21 21:34:07,377 - ERROR - Error in get_actual_df for bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:34:07,377 - ERROR - Error processing dataframe bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:34:07,377 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:34:07,377 - ERROR - Error saving washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,377 - ERROR - Error saving pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:34:07,377 - ERROR - Error saving ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,377 - ERROR - Error saving hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,377 - ERROR - Error saving net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,378 - ERROR - Error saving iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,378 - ERROR - Error saving oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,378 - ERROR - Error saving full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,378 - ERROR - Error saving empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,378 - ERROR - Error saving salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,378 - ERROR - Error saving bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,378 - ERROR - Error saving pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:34:07,378 - ERROR - Error saving container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,378 - ERROR - Error saving shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,379 - ERROR - Error saving transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:34:07,379 - ERROR - Error saving scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,379 - ERROR - Error saving forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,379 - ERROR - Error saving static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,379 - ERROR - Error saving dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,379 - ERROR - Error saving truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,379 - ERROR - Error saving cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:34:07,379 - ERROR - Error saving cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:34:07,379 - ERROR - Error saving bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:34:07,380 - INFO - Save completed
2025-03-21 21:34:07,380 - INFO - Successfully saved: 0 files
2025-03-21 21:34:07,380 - ERROR - Failed to save: 24 files
2025-03-21 21:34:07,380 - ERROR -   - shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:34:07,380 - ERROR -   - washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,380 - ERROR -   - pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:34:07,380 - ERROR -   - ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,380 - ERROR -   - hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,381 - ERROR -   - net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,381 - ERROR -   - iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,381 - ERROR -   - oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,381 - ERROR -   - full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,381 - ERROR -   - empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,381 - ERROR -   - salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,381 - ERROR -   - bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,381 - ERROR -   - pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:34:07,381 - ERROR -   - container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,381 - ERROR -   - shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,381 - ERROR -   - transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:34:07,381 - ERROR -   - scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,382 - ERROR -   - forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,382 - ERROR -   - static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:34:07,382 - ERROR -   - dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,382 - ERROR -   - truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:34:07,382 - ERROR -   - cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:34:07,382 - ERROR -   - cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:34:07,382 - ERROR -   - bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:36:12,988 - INFO - Exiting application
2025-03-21 21:36:18,469 - DEBUG - Using selector: EpollSelector
2025-03-21 21:36:18,469 - INFO - Starting application
2025-03-21 21:36:18,469 - INFO - Clearing screen
2025-03-21 21:36:20,398 - INFO - Selected: Save files
2025-03-21 21:36:20,398 - INFO - Clearing screen
2025-03-21 21:36:24,448 - INFO - Initiating save operation for all
2025-03-21 21:36:24,448 - INFO - Processing all dataframe categories concurrently
2025-03-21 21:36:24,448 - INFO - Queueing category: emr
2025-03-21 21:36:24,449 - INFO - Queueing category: operations
2025-03-21 21:36:24,449 - INFO - Queueing category: netlist
2025-03-21 21:36:24,449 - INFO - Queueing category: bin_dispatch
2025-03-21 21:36:24,449 - INFO - Queueing category: shore_handling
2025-03-21 21:36:24,450 - INFO - Queueing category: stuffing
2025-03-21 21:36:24,450 - INFO - Queueing category: transport
2025-03-21 21:36:24,450 - INFO - Queueing category: miscellaneous
2025-03-21 21:36:24,451 - INFO - Processing dataframe shifting of type <class 'function'>
2025-03-21 21:36:24,451 - INFO - Callable found for shifting, checking if it's a coroutine function
2025-03-21 21:36:24,451 - INFO - shifting is a coroutine function, using special handling
2025-03-21 21:36:24,452 - INFO - Coroutine locals for shifting: []
2025-03-21 21:36:24,452 - INFO - Attempting to await coroutine for shifting
2025-03-21 21:36:24,452 - ERROR - Error in call_async_function for shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,452 - ERROR - Error in get_actual_df for shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,453 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,453 - INFO - Processing dataframe washing of type <class 'function'>
2025-03-21 21:36:24,453 - INFO - Callable found for washing, checking if it's a coroutine function
2025-03-21 21:36:24,453 - INFO - washing is a coroutine function, using special handling
2025-03-21 21:36:24,454 - INFO - Coroutine locals for washing: []
2025-03-21 21:36:24,454 - INFO - Attempting to await coroutine for washing
2025-03-21 21:36:24,454 - ERROR - Error in call_async_function for washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,455 - ERROR - Error in get_actual_df for washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,455 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,455 - INFO - Processing dataframe pti of type <class 'function'>
2025-03-21 21:36:24,455 - INFO - Callable found for pti, checking if it's a coroutine function
2025-03-21 21:36:24,456 - INFO - pti is a coroutine function, using special handling
2025-03-21 21:36:24,456 - INFO - Coroutine locals for pti: []
2025-03-21 21:36:24,456 - INFO - Attempting to await coroutine for pti
2025-03-21 21:36:24,457 - ERROR - Error in call_async_function for pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,457 - ERROR - Error in get_actual_df for pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,457 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,457 - INFO - Processing dataframe ops of type <class 'function'>
2025-03-21 21:36:24,458 - INFO - Callable found for ops, checking if it's a coroutine function
2025-03-21 21:36:24,458 - INFO - ops is a coroutine function, using special handling
2025-03-21 21:36:24,458 - INFO - Coroutine locals for ops: []
2025-03-21 21:36:24,458 - INFO - Attempting to await coroutine for ops
2025-03-21 21:36:24,458 - ERROR - Error in call_async_function for ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,458 - ERROR - Error in get_actual_df for ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,459 - ERROR - Error processing dataframe ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,459 - INFO - Processing dataframe hatch_to_hatch of type <class 'function'>
2025-03-21 21:36:24,459 - INFO - Callable found for hatch_to_hatch, checking if it's a coroutine function
2025-03-21 21:36:24,459 - INFO - hatch_to_hatch is a coroutine function, using special handling
2025-03-21 21:36:24,460 - INFO - Coroutine locals for hatch_to_hatch: []
2025-03-21 21:36:24,460 - INFO - Attempting to await coroutine for hatch_to_hatch
2025-03-21 21:36:24,460 - ERROR - Error in call_async_function for hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,460 - ERROR - Error in get_actual_df for hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,461 - ERROR - Error processing dataframe hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,461 - INFO - Processing dataframe net_list of type <class 'function'>
2025-03-21 21:36:24,461 - INFO - Callable found for net_list, checking if it's a coroutine function
2025-03-21 21:36:24,462 - INFO - net_list is a coroutine function, using special handling
2025-03-21 21:36:24,462 - INFO - Coroutine locals for net_list: []
2025-03-21 21:36:24,462 - INFO - Attempting to await coroutine for net_list
2025-03-21 21:36:24,462 - ERROR - Error in call_async_function for net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,462 - ERROR - Error in get_actual_df for net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,463 - ERROR - Error processing dataframe net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,463 - INFO - Processing dataframe iot_container_stuffing of type <class 'function'>
2025-03-21 21:36:24,463 - INFO - Callable found for iot_container_stuffing, checking if it's a coroutine function
2025-03-21 21:36:24,463 - INFO - iot_container_stuffing is a coroutine function, using special handling
2025-03-21 21:36:24,464 - INFO - Coroutine locals for iot_container_stuffing: []
2025-03-21 21:36:24,464 - INFO - Attempting to await coroutine for iot_container_stuffing
2025-03-21 21:36:24,464 - ERROR - Error in call_async_function for iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,464 - ERROR - Error in get_actual_df for iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,465 - ERROR - Error processing dataframe iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,465 - INFO - Processing dataframe oss_stuffing of type <class 'function'>
2025-03-21 21:36:24,465 - INFO - Callable found for oss_stuffing, checking if it's a coroutine function
2025-03-21 21:36:24,465 - INFO - oss_stuffing is a coroutine function, using special handling
2025-03-21 21:36:24,466 - INFO - Coroutine locals for oss_stuffing: []
2025-03-21 21:36:24,466 - INFO - Attempting to await coroutine for oss_stuffing
2025-03-21 21:36:24,466 - ERROR - Error in call_async_function for oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,466 - ERROR - Error in get_actual_df for oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,466 - ERROR - Error processing dataframe oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,467 - INFO - Processing dataframe full_scows_transfer of type <class 'function'>
2025-03-21 21:36:24,467 - INFO - Callable found for full_scows_transfer, checking if it's a coroutine function
2025-03-21 21:36:24,467 - INFO - full_scows_transfer is a coroutine function, using special handling
2025-03-21 21:36:24,467 - INFO - Coroutine locals for full_scows_transfer: []
2025-03-21 21:36:24,468 - INFO - Attempting to await coroutine for full_scows_transfer
2025-03-21 21:36:24,468 - ERROR - Error in call_async_function for full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,468 - ERROR - Error in get_actual_df for full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,468 - ERROR - Error processing dataframe full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,469 - INFO - Processing dataframe empty_scows_transfer of type <class 'function'>
2025-03-21 21:36:24,469 - INFO - Callable found for empty_scows_transfer, checking if it's a coroutine function
2025-03-21 21:36:24,469 - INFO - empty_scows_transfer is a coroutine function, using special handling
2025-03-21 21:36:24,469 - INFO - Coroutine locals for empty_scows_transfer: []
2025-03-21 21:36:24,469 - INFO - Attempting to await coroutine for empty_scows_transfer
2025-03-21 21:36:24,470 - ERROR - Error in call_async_function for empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,470 - ERROR - Error in get_actual_df for empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,470 - ERROR - Error processing dataframe empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,470 - INFO - Processing dataframe salt of type <class 'function'>
2025-03-21 21:36:24,470 - INFO - Callable found for salt, checking if it's a coroutine function
2025-03-21 21:36:24,471 - INFO - salt is a coroutine function, using special handling
2025-03-21 21:36:24,471 - INFO - Coroutine locals for salt: []
2025-03-21 21:36:24,471 - INFO - Attempting to await coroutine for salt
2025-03-21 21:36:24,471 - ERROR - Error in call_async_function for salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,471 - ERROR - Error in get_actual_df for salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,472 - ERROR - Error processing dataframe salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,472 - INFO - Processing dataframe bin_tipping of type <class 'function'>
2025-03-21 21:36:24,472 - INFO - Callable found for bin_tipping, checking if it's a coroutine function
2025-03-21 21:36:24,472 - INFO - bin_tipping is a coroutine function, using special handling
2025-03-21 21:36:24,473 - INFO - Coroutine locals for bin_tipping: []
2025-03-21 21:36:24,473 - INFO - Attempting to await coroutine for bin_tipping
2025-03-21 21:36:24,473 - ERROR - Error in call_async_function for bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,473 - ERROR - Error in get_actual_df for bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,473 - ERROR - Error processing dataframe bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,474 - INFO - Processing dataframe pallet_liner of type <class 'function'>
2025-03-21 21:36:24,474 - INFO - Callable found for pallet_liner, checking if it's a coroutine function
2025-03-21 21:36:24,474 - INFO - pallet_liner is a coroutine function, using special handling
2025-03-21 21:36:24,474 - INFO - Coroutine locals for pallet_liner: []
2025-03-21 21:36:24,474 - INFO - Attempting to await coroutine for pallet_liner
2025-03-21 21:36:24,475 - ERROR - Error in call_async_function for pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,475 - ERROR - Error in get_actual_df for pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,475 - ERROR - Error processing dataframe pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,475 - INFO - Processing dataframe container_plugin of type <class 'function'>
2025-03-21 21:36:24,475 - INFO - Callable found for container_plugin, checking if it's a coroutine function
2025-03-21 21:36:24,476 - INFO - container_plugin is a coroutine function, using special handling
2025-03-21 21:36:24,476 - INFO - Coroutine locals for container_plugin: []
2025-03-21 21:36:24,476 - INFO - Attempting to await coroutine for container_plugin
2025-03-21 21:36:24,476 - ERROR - Error in call_async_function for container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,476 - ERROR - Error in get_actual_df for container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,477 - ERROR - Error processing dataframe container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,477 - INFO - Processing dataframe shore_crane of type <class 'function'>
2025-03-21 21:36:24,477 - INFO - Callable found for shore_crane, checking if it's a coroutine function
2025-03-21 21:36:24,477 - INFO - shore_crane is a coroutine function, using special handling
2025-03-21 21:36:24,478 - INFO - Coroutine locals for shore_crane: []
2025-03-21 21:36:24,478 - INFO - Attempting to await coroutine for shore_crane
2025-03-21 21:36:24,478 - ERROR - Error in call_async_function for shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,478 - ERROR - Error in get_actual_df for shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,478 - ERROR - Error processing dataframe shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,479 - INFO - Processing dataframe transfer of type <class 'function'>
2025-03-21 21:36:24,479 - INFO - Callable found for transfer, checking if it's a coroutine function
2025-03-21 21:36:24,479 - INFO - transfer is a coroutine function, using special handling
2025-03-21 21:36:24,480 - INFO - Coroutine locals for transfer: []
2025-03-21 21:36:24,480 - INFO - Attempting to await coroutine for transfer
2025-03-21 21:36:24,480 - ERROR - Error in call_async_function for transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:36:24,480 - ERROR - Error in get_actual_df for transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:36:24,480 - ERROR - Error processing dataframe transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:36:24,481 - INFO - Processing dataframe scow_transfer of type <class 'function'>
2025-03-21 21:36:24,481 - INFO - Callable found for scow_transfer, checking if it's a coroutine function
2025-03-21 21:36:24,481 - INFO - scow_transfer is a coroutine function, using special handling
2025-03-21 21:36:24,481 - INFO - Coroutine locals for scow_transfer: []
2025-03-21 21:36:24,482 - INFO - Attempting to await coroutine for scow_transfer
2025-03-21 21:36:24,482 - ERROR - Error in call_async_function for scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,482 - ERROR - Error in get_actual_df for scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,483 - ERROR - Error processing dataframe scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,483 - INFO - Processing dataframe forklift of type <class 'function'>
2025-03-21 21:36:24,483 - INFO - Callable found for forklift, checking if it's a coroutine function
2025-03-21 21:36:24,483 - INFO - forklift is a coroutine function, using special handling
2025-03-21 21:36:24,484 - INFO - Coroutine locals for forklift: []
2025-03-21 21:36:24,484 - INFO - Attempting to await coroutine for forklift
2025-03-21 21:36:24,484 - ERROR - Error in call_async_function for forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,484 - ERROR - Error in get_actual_df for forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,485 - ERROR - Error processing dataframe forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,485 - INFO - Processing dataframe static_loader of type <class 'function'>
2025-03-21 21:36:24,485 - INFO - Callable found for static_loader, checking if it's a coroutine function
2025-03-21 21:36:24,485 - INFO - static_loader is a coroutine function, using special handling
2025-03-21 21:36:24,486 - INFO - Coroutine locals for static_loader: []
2025-03-21 21:36:24,486 - INFO - Attempting to await coroutine for static_loader
2025-03-21 21:36:24,486 - ERROR - Error in call_async_function for static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,486 - ERROR - Error in get_actual_df for static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,486 - ERROR - Error processing dataframe static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,487 - INFO - Processing dataframe dispatch_to_cargo of type <class 'function'>
2025-03-21 21:36:24,487 - INFO - Callable found for dispatch_to_cargo, checking if it's a coroutine function
2025-03-21 21:36:24,487 - INFO - dispatch_to_cargo is a coroutine function, using special handling
2025-03-21 21:36:24,487 - INFO - Coroutine locals for dispatch_to_cargo: []
2025-03-21 21:36:24,488 - INFO - Attempting to await coroutine for dispatch_to_cargo
2025-03-21 21:36:24,488 - ERROR - Error in call_async_function for dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,488 - ERROR - Error in get_actual_df for dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,488 - ERROR - Error processing dataframe dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,488 - INFO - Processing dataframe truck_to_cccs of type <class 'function'>
2025-03-21 21:36:24,489 - INFO - Callable found for truck_to_cccs, checking if it's a coroutine function
2025-03-21 21:36:24,489 - INFO - truck_to_cccs is a coroutine function, using special handling
2025-03-21 21:36:24,489 - INFO - Coroutine locals for truck_to_cccs: []
2025-03-21 21:36:24,489 - INFO - Attempting to await coroutine for truck_to_cccs
2025-03-21 21:36:24,489 - ERROR - Error in call_async_function for truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,490 - ERROR - Error in get_actual_df for truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,490 - ERROR - Error processing dataframe truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,490 - INFO - Processing dataframe cross_stuffing of type <class 'function'>
2025-03-21 21:36:24,490 - INFO - Callable found for cross_stuffing, checking if it's a coroutine function
2025-03-21 21:36:24,491 - INFO - cross_stuffing is a coroutine function, using special handling
2025-03-21 21:36:24,491 - INFO - Coroutine locals for cross_stuffing: []
2025-03-21 21:36:24,491 - INFO - Attempting to await coroutine for cross_stuffing
2025-03-21 21:36:24,491 - ERROR - Error in call_async_function for cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:36:24,491 - ERROR - Error in get_actual_df for cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:36:24,492 - ERROR - Error processing dataframe cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:36:24,492 - INFO - Processing dataframe cccs_stuffing of type <class 'function'>
2025-03-21 21:36:24,492 - INFO - Callable found for cccs_stuffing, checking if it's a coroutine function
2025-03-21 21:36:24,492 - INFO - cccs_stuffing is a coroutine function, using special handling
2025-03-21 21:36:24,492 - INFO - Coroutine locals for cccs_stuffing: []
2025-03-21 21:36:24,493 - INFO - Attempting to await coroutine for cccs_stuffing
2025-03-21 21:36:24,493 - ERROR - Error in call_async_function for cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:36:24,493 - ERROR - Error in get_actual_df for cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:36:24,493 - ERROR - Error processing dataframe cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:36:24,493 - INFO - Processing dataframe bycatch of type <class 'function'>
2025-03-21 21:36:24,494 - INFO - Callable found for bycatch, checking if it's a coroutine function
2025-03-21 21:36:24,494 - INFO - bycatch is a coroutine function, using special handling
2025-03-21 21:36:24,494 - INFO - Coroutine locals for bycatch: []
2025-03-21 21:36:24,494 - INFO - Attempting to await coroutine for bycatch
2025-03-21 21:36:24,494 - ERROR - Error in call_async_function for bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:36:24,494 - ERROR - Error in get_actual_df for bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:36:24,495 - ERROR - Error processing dataframe bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:36:24,495 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,495 - ERROR - Error saving washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,495 - ERROR - Error saving pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,496 - ERROR - Error saving ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,496 - ERROR - Error saving hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,496 - ERROR - Error saving net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,496 - ERROR - Error saving iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,496 - ERROR - Error saving oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,496 - ERROR - Error saving full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,497 - ERROR - Error saving empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,497 - ERROR - Error saving salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,497 - ERROR - Error saving bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,497 - ERROR - Error saving pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,497 - ERROR - Error saving container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,497 - ERROR - Error saving shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,498 - ERROR - Error saving transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:36:24,498 - ERROR - Error saving scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,498 - ERROR - Error saving forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,498 - ERROR - Error saving static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,498 - ERROR - Error saving dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,498 - ERROR - Error saving truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,498 - ERROR - Error saving cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:36:24,499 - ERROR - Error saving cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:36:24,499 - ERROR - Error saving bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:36:24,499 - INFO - Save completed
2025-03-21 21:36:24,499 - INFO - Successfully saved: 0 files
2025-03-21 21:36:24,500 - ERROR - Failed to save: 24 files
2025-03-21 21:36:24,500 - ERROR -   - shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,500 - ERROR -   - washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,500 - ERROR -   - pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,500 - ERROR -   - ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,500 - ERROR -   - hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,501 - ERROR -   - net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,501 - ERROR -   - iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,501 - ERROR -   - oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,501 - ERROR -   - full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,501 - ERROR -   - empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,501 - ERROR -   - salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,501 - ERROR -   - bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,502 - ERROR -   - pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:36:24,502 - ERROR -   - container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,502 - ERROR -   - shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,502 - ERROR -   - transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:36:24,502 - ERROR -   - scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,502 - ERROR -   - forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,502 - ERROR -   - static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:36:24,503 - ERROR -   - dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,503 - ERROR -   - truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:36:24,503 - ERROR -   - cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:36:24,503 - ERROR -   - cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:36:24,503 - ERROR -   - bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:39:53,086 - INFO - Exiting application
2025-03-21 21:39:56,927 - DEBUG - Using selector: EpollSelector
2025-03-21 21:39:56,927 - INFO - Starting application
2025-03-21 21:39:56,927 - INFO - Clearing screen
2025-03-21 21:39:58,591 - INFO - Selected: Save files
2025-03-21 21:39:58,591 - INFO - Clearing screen
2025-03-21 21:40:02,206 - INFO - Initiating save operation for all
2025-03-21 21:40:02,207 - INFO - Processing all dataframe categories concurrently
2025-03-21 21:40:02,207 - INFO - Queueing category: emr
2025-03-21 21:40:02,208 - INFO - Queueing category: operations
2025-03-21 21:40:02,208 - INFO - Queueing category: netlist
2025-03-21 21:40:02,208 - INFO - Queueing category: bin_dispatch
2025-03-21 21:40:02,208 - INFO - Queueing category: shore_handling
2025-03-21 21:40:02,209 - INFO - Queueing category: stuffing
2025-03-21 21:40:02,209 - INFO - Queueing category: transport
2025-03-21 21:40:02,209 - INFO - Queueing category: miscellaneous
2025-03-21 21:40:02,210 - INFO - Processing dataframe shifting of type <class 'function'>
2025-03-21 21:40:02,211 - INFO - Calling function for shifting
2025-03-21 21:40:02,211 - INFO - Awaiting result for shifting
2025-03-21 21:40:02,211 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:40:02,212 - INFO - Processing dataframe washing of type <class 'function'>
2025-03-21 21:40:02,212 - INFO - Calling function for washing
2025-03-21 21:40:02,212 - INFO - Awaiting result for washing
2025-03-21 21:40:02,212 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,213 - INFO - Processing dataframe pti of type <class 'function'>
2025-03-21 21:40:02,213 - INFO - Calling function for pti
2025-03-21 21:40:02,213 - INFO - Awaiting result for pti
2025-03-21 21:40:02,214 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:40:02,214 - INFO - Processing dataframe ops of type <class 'function'>
2025-03-21 21:40:02,214 - INFO - Calling function for ops
2025-03-21 21:40:02,215 - INFO - Awaiting result for ops
2025-03-21 21:40:02,215 - ERROR - Error processing dataframe ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,215 - INFO - Processing dataframe hatch_to_hatch of type <class 'function'>
2025-03-21 21:40:02,215 - INFO - Calling function for hatch_to_hatch
2025-03-21 21:40:02,216 - INFO - Awaiting result for hatch_to_hatch
2025-03-21 21:40:02,216 - ERROR - Error processing dataframe hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,216 - INFO - Processing dataframe net_list of type <class 'function'>
2025-03-21 21:40:02,217 - INFO - Calling function for net_list
2025-03-21 21:40:02,217 - INFO - Awaiting result for net_list
2025-03-21 21:40:02,217 - ERROR - Error processing dataframe net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,218 - INFO - Processing dataframe iot_container_stuffing of type <class 'function'>
2025-03-21 21:40:02,218 - INFO - Calling function for iot_container_stuffing
2025-03-21 21:40:02,218 - INFO - Awaiting result for iot_container_stuffing
2025-03-21 21:40:02,219 - ERROR - Error processing dataframe iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,219 - INFO - Processing dataframe oss_stuffing of type <class 'function'>
2025-03-21 21:40:02,219 - INFO - Calling function for oss_stuffing
2025-03-21 21:40:02,220 - INFO - Awaiting result for oss_stuffing
2025-03-21 21:40:02,220 - ERROR - Error processing dataframe oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,221 - INFO - Processing dataframe full_scows_transfer of type <class 'function'>
2025-03-21 21:40:02,221 - INFO - Calling function for full_scows_transfer
2025-03-21 21:40:02,221 - INFO - Awaiting result for full_scows_transfer
2025-03-21 21:40:02,222 - ERROR - Error processing dataframe full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,222 - INFO - Processing dataframe empty_scows_transfer of type <class 'function'>
2025-03-21 21:40:02,222 - INFO - Calling function for empty_scows_transfer
2025-03-21 21:40:02,223 - INFO - Awaiting result for empty_scows_transfer
2025-03-21 21:40:02,223 - ERROR - Error processing dataframe empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,223 - INFO - Processing dataframe salt of type <class 'function'>
2025-03-21 21:40:02,224 - INFO - Calling function for salt
2025-03-21 21:40:02,224 - INFO - Awaiting result for salt
2025-03-21 21:40:02,224 - ERROR - Error processing dataframe salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,224 - INFO - Processing dataframe bin_tipping of type <class 'function'>
2025-03-21 21:40:02,225 - INFO - Calling function for bin_tipping
2025-03-21 21:40:02,225 - INFO - Awaiting result for bin_tipping
2025-03-21 21:40:02,225 - ERROR - Error processing dataframe bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,226 - INFO - Processing dataframe pallet_liner of type <class 'function'>
2025-03-21 21:40:02,226 - INFO - Calling function for pallet_liner
2025-03-21 21:40:02,226 - INFO - Awaiting result for pallet_liner
2025-03-21 21:40:02,226 - ERROR - Error processing dataframe pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:40:02,227 - INFO - Processing dataframe container_plugin of type <class 'function'>
2025-03-21 21:40:02,227 - INFO - Calling function for container_plugin
2025-03-21 21:40:02,227 - INFO - Awaiting result for container_plugin
2025-03-21 21:40:02,227 - ERROR - Error processing dataframe container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,228 - INFO - Processing dataframe shore_crane of type <class 'function'>
2025-03-21 21:40:02,228 - INFO - Calling function for shore_crane
2025-03-21 21:40:02,228 - INFO - Awaiting result for shore_crane
2025-03-21 21:40:02,228 - ERROR - Error processing dataframe shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,229 - INFO - Processing dataframe transfer of type <class 'function'>
2025-03-21 21:40:02,229 - INFO - Calling function for transfer
2025-03-21 21:40:02,229 - INFO - Awaiting result for transfer
2025-03-21 21:40:02,229 - ERROR - Error processing dataframe transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:40:02,230 - INFO - Processing dataframe scow_transfer of type <class 'function'>
2025-03-21 21:40:02,230 - INFO - Calling function for scow_transfer
2025-03-21 21:40:02,230 - INFO - Awaiting result for scow_transfer
2025-03-21 21:40:02,230 - ERROR - Error processing dataframe scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,230 - INFO - Processing dataframe forklift of type <class 'function'>
2025-03-21 21:40:02,231 - INFO - Calling function for forklift
2025-03-21 21:40:02,231 - INFO - Awaiting result for forklift
2025-03-21 21:40:02,231 - ERROR - Error processing dataframe forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,231 - INFO - Processing dataframe static_loader of type <class 'function'>
2025-03-21 21:40:02,232 - INFO - Calling function for static_loader
2025-03-21 21:40:02,232 - INFO - Awaiting result for static_loader
2025-03-21 21:40:02,232 - ERROR - Error processing dataframe static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,233 - INFO - Processing dataframe dispatch_to_cargo of type <class 'function'>
2025-03-21 21:40:02,233 - INFO - Calling function for dispatch_to_cargo
2025-03-21 21:40:02,233 - INFO - Awaiting result for dispatch_to_cargo
2025-03-21 21:40:02,233 - ERROR - Error processing dataframe dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,234 - INFO - Processing dataframe truck_to_cccs of type <class 'function'>
2025-03-21 21:40:02,234 - INFO - Calling function for truck_to_cccs
2025-03-21 21:40:02,234 - INFO - Awaiting result for truck_to_cccs
2025-03-21 21:40:02,234 - ERROR - Error processing dataframe truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,234 - INFO - Processing dataframe cross_stuffing of type <class 'function'>
2025-03-21 21:40:02,235 - INFO - Calling function for cross_stuffing
2025-03-21 21:40:02,235 - INFO - Awaiting result for cross_stuffing
2025-03-21 21:40:02,235 - ERROR - Error processing dataframe cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:40:02,235 - INFO - Processing dataframe cccs_stuffing of type <class 'function'>
2025-03-21 21:40:02,236 - INFO - Calling function for cccs_stuffing
2025-03-21 21:40:02,236 - INFO - Awaiting result for cccs_stuffing
2025-03-21 21:40:02,236 - ERROR - Error processing dataframe cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:40:02,236 - INFO - Processing dataframe bycatch of type <class 'function'>
2025-03-21 21:40:02,236 - INFO - Calling function for bycatch
2025-03-21 21:40:02,236 - INFO - Awaiting result for bycatch
2025-03-21 21:40:02,236 - ERROR - Error processing dataframe bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:40:02,237 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:40:02,237 - ERROR - Error saving washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,237 - ERROR - Error saving pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:40:02,237 - ERROR - Error saving ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,237 - ERROR - Error saving hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,237 - ERROR - Error saving net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,238 - ERROR - Error saving iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,238 - ERROR - Error saving oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,238 - ERROR - Error saving full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,238 - ERROR - Error saving empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,238 - ERROR - Error saving salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,238 - ERROR - Error saving bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,238 - ERROR - Error saving pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:40:02,238 - ERROR - Error saving container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,239 - ERROR - Error saving shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,239 - ERROR - Error saving transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:40:02,239 - ERROR - Error saving scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,239 - ERROR - Error saving forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,239 - ERROR - Error saving static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,239 - ERROR - Error saving dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,239 - ERROR - Error saving truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,240 - ERROR - Error saving cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:40:02,240 - ERROR - Error saving cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:40:02,240 - ERROR - Error saving bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:40:02,240 - INFO - Save completed
2025-03-21 21:40:02,240 - INFO - Successfully saved: 0 files
2025-03-21 21:40:02,241 - ERROR - Failed to save: 24 files
2025-03-21 21:40:02,241 - ERROR -   - shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:40:02,241 - ERROR -   - washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,241 - ERROR -   - pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:40:02,241 - ERROR -   - ops: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,241 - ERROR -   - hatch_to_hatch: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,242 - ERROR -   - net_list: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,242 - ERROR -   - iot_container_stuffing: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,242 - ERROR -   - oss_stuffing: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,242 - ERROR -   - full_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,242 - ERROR -   - empty_scows_transfer: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,242 - ERROR -   - salt: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,242 - ERROR -   - bin_tipping: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,243 - ERROR -   - pallet_liner: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:40:02,243 - ERROR -   - container_plugin: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,243 - ERROR -   - shore_crane: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,243 - ERROR -   - transfer: 'coroutine' object has no attribute 'get'
2025-03-21 21:40:02,243 - ERROR -   - scow_transfer: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,243 - ERROR -   - forklift: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,244 - ERROR -   - static_loader: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:02,244 - ERROR -   - dispatch_to_cargo: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,244 - ERROR -   - truck_to_cccs: 'coroutine' object has no attribute 'filter'
2025-03-21 21:40:02,244 - ERROR -   - cross_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:40:02,244 - ERROR -   - cccs_stuffing: 'coroutine' object has no attribute 'join_asof'
2025-03-21 21:40:02,244 - ERROR -   - bycatch: 'coroutine' object has no attribute 'join'
2025-03-21 21:40:17,582 - INFO - Starting application
2025-03-21 21:40:17,582 - INFO - Clearing screen
2025-03-21 21:40:21,737 - INFO - Selected: Save files
2025-03-21 21:40:21,737 - INFO - Clearing screen
2025-03-21 21:40:25,847 - INFO - Initiating save operation for emr
2025-03-21 21:40:25,847 - INFO - Processing dataframe category: emr
2025-03-21 21:40:25,848 - INFO - Processing dataframes: ['shifting', 'washing', 'pti']
2025-03-21 21:40:25,853 - INFO - Processing dataframe shifting of type <class 'function'>
2025-03-21 21:40:25,854 - INFO - Calling function for shifting
2025-03-21 21:40:25,854 - INFO - Awaiting result for shifting
2025-03-21 21:40:25,854 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:40:25,855 - INFO - Processing dataframe washing of type <class 'function'>
2025-03-21 21:40:25,855 - INFO - Calling function for washing
2025-03-21 21:40:25,856 - INFO - Awaiting result for washing
2025-03-21 21:40:25,856 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:25,856 - INFO - Processing dataframe pti of type <class 'function'>
2025-03-21 21:40:25,857 - INFO - Calling function for pti
2025-03-21 21:40:25,857 - INFO - Awaiting result for pti
2025-03-21 21:40:25,857 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:40:25,858 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:40:25,858 - ERROR - Error saving washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:40:25,858 - ERROR - Error saving pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:40:25,859 - INFO - Save completed
2025-03-21 21:40:25,859 - INFO - Successfully saved: 
2025-03-21 21:40:25,859 - ERROR - Failed to save: shifting: 'coroutine' object has no attribute 'with_columns', washing: 'coroutine' object has no attribute 'select', pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:45:58,508 - INFO - Exiting application
2025-03-21 21:46:02,070 - DEBUG - Using selector: EpollSelector
2025-03-21 21:46:02,071 - INFO - Starting application
2025-03-21 21:46:02,071 - INFO - Clearing screen
2025-03-21 21:46:03,729 - INFO - Selected: Save files
2025-03-21 21:46:03,729 - INFO - Clearing screen
2025-03-21 21:46:07,104 - INFO - Initiating save operation for emr
2025-03-21 21:46:07,105 - INFO - Processing dataframe category: emr
2025-03-21 21:46:07,105 - INFO - Processing dataframes: ['shifting', 'washing', 'pti']
2025-03-21 21:46:07,106 - INFO - Processing dataframe shifting of type <class 'function'>
2025-03-21 21:46:07,106 - INFO - Calling function for shifting
2025-03-21 21:46:07,107 - INFO - Awaiting result for shifting
2025-03-21 21:46:07,107 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:46:07,108 - INFO - Processing dataframe washing of type <class 'function'>
2025-03-21 21:46:07,108 - INFO - Calling function for washing
2025-03-21 21:46:07,108 - INFO - Awaiting result for washing
2025-03-21 21:46:07,108 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:46:07,109 - INFO - Processing dataframe pti of type <class 'function'>
2025-03-21 21:46:07,109 - INFO - Calling function for pti
2025-03-21 21:46:07,109 - INFO - Awaiting result for pti
2025-03-21 21:46:07,110 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:46:07,110 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:46:07,111 - ERROR - Error saving washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:46:07,111 - ERROR - Error saving pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:46:07,111 - INFO - Save completed
2025-03-21 21:46:07,111 - INFO - Successfully saved: 
2025-03-21 21:46:07,112 - ERROR - Failed to save: shifting: 'coroutine' object has no attribute 'with_columns', washing: 'coroutine' object has no attribute 'select', pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:49:10,988 - INFO - Exiting application
2025-03-21 21:49:14,471 - DEBUG - Using selector: EpollSelector
2025-03-21 21:49:14,471 - INFO - Starting application
2025-03-21 21:49:14,471 - INFO - Clearing screen
2025-03-21 21:49:17,256 - INFO - Selected: Save files
2025-03-21 21:49:17,256 - INFO - Clearing screen
2025-03-21 21:49:21,128 - INFO - Initiating save operation for emr
2025-03-21 21:49:21,128 - INFO - Processing dataframe category: emr
2025-03-21 21:49:21,129 - INFO - Processing dataframes: ['shifting', 'washing', 'pti']
2025-03-21 21:49:21,129 - INFO - Processing dataframe shifting of type <class 'function'>
2025-03-21 21:49:21,130 - INFO - Calling function for shifting
2025-03-21 21:49:21,130 - INFO - Awaiting result for shifting
2025-03-21 21:49:21,130 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:49:21,130 - INFO - Processing dataframe washing of type <class 'function'>
2025-03-21 21:49:21,131 - INFO - Calling function for washing
2025-03-21 21:49:21,131 - INFO - Awaiting result for washing
2025-03-21 21:49:21,131 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:49:21,131 - INFO - Processing dataframe pti of type <class 'function'>
2025-03-21 21:49:21,132 - INFO - Calling function for pti
2025-03-21 21:49:21,132 - INFO - Awaiting result for pti
2025-03-21 21:49:21,132 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:49:21,132 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:49:21,133 - ERROR - Error saving washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:49:21,133 - ERROR - Error saving pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:49:21,133 - INFO - Save completed
2025-03-21 21:49:21,133 - INFO - Successfully saved: 
2025-03-21 21:49:21,134 - ERROR - Failed to save: shifting: 'coroutine' object has no attribute 'with_columns', washing: 'coroutine' object has no attribute 'select', pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:52:22,643 - INFO - Exiting application
2025-03-21 21:52:25,198 - DEBUG - Using selector: EpollSelector
2025-03-21 21:52:25,198 - INFO - Starting application
2025-03-21 21:52:25,198 - INFO - Clearing screen
2025-03-21 21:52:26,798 - INFO - Selected: Save files
2025-03-21 21:52:26,799 - INFO - Clearing screen
2025-03-21 21:52:30,502 - INFO - Initiating save operation for emr
2025-03-21 21:52:30,503 - INFO - Processing dataframe category: emr
2025-03-21 21:52:30,503 - INFO - Processing dataframes: ['shifting', 'washing', 'pti']
2025-03-21 21:52:30,504 - INFO - Processing dataframe shifting of type <class 'function'>
2025-03-21 21:52:30,504 - INFO - Calling function for shifting
2025-03-21 21:52:30,505 - INFO - Awaiting result for shifting
2025-03-21 21:52:30,505 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'select'
2025-03-21 21:52:30,506 - INFO - Processing dataframe washing of type <class 'function'>
2025-03-21 21:52:30,506 - INFO - Calling function for washing
2025-03-21 21:52:30,506 - INFO - Awaiting result for washing
2025-03-21 21:52:30,507 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:52:30,507 - INFO - Processing dataframe pti of type <class 'function'>
2025-03-21 21:52:30,507 - INFO - Calling function for pti
2025-03-21 21:52:30,507 - INFO - Awaiting result for pti
2025-03-21 21:52:30,508 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:52:30,508 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'select'
2025-03-21 21:52:30,509 - ERROR - Error saving washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:52:30,509 - ERROR - Error saving pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:52:30,509 - INFO - Save completed
2025-03-21 21:52:30,509 - INFO - Successfully saved: 
2025-03-21 21:52:30,510 - ERROR - Failed to save: shifting: 'coroutine' object has no attribute 'select', washing: 'coroutine' object has no attribute 'select', pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:53:47,062 - INFO - Exiting application
2025-03-21 21:53:49,621 - DEBUG - Using selector: EpollSelector
2025-03-21 21:53:49,621 - INFO - Starting application
2025-03-21 21:53:49,621 - INFO - Clearing screen
2025-03-21 21:53:51,442 - INFO - Selected: Save files
2025-03-21 21:53:51,442 - INFO - Clearing screen
2025-03-21 21:53:55,149 - INFO - Initiating save operation for emr
2025-03-21 21:53:55,149 - INFO - Processing dataframe category: emr
2025-03-21 21:53:55,150 - INFO - Processing dataframes: ['shifting', 'washing', 'pti']
2025-03-21 21:53:55,150 - INFO - Processing dataframe shifting of type <class 'function'>
2025-03-21 21:53:55,151 - INFO - Calling function for shifting
2025-03-21 21:53:55,151 - INFO - Awaiting result for shifting
2025-03-21 21:53:55,151 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'select'
2025-03-21 21:53:55,152 - INFO - Processing dataframe washing of type <class 'function'>
2025-03-21 21:53:55,152 - INFO - Calling function for washing
2025-03-21 21:53:55,152 - INFO - Awaiting result for washing
2025-03-21 21:53:55,153 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:53:55,153 - INFO - Processing dataframe pti of type <class 'function'>
2025-03-21 21:53:55,153 - INFO - Calling function for pti
2025-03-21 21:53:55,153 - INFO - Awaiting result for pti
2025-03-21 21:53:55,154 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:53:55,154 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'select'
2025-03-21 21:53:55,154 - ERROR - Error saving washing: 'coroutine' object has no attribute 'select'
2025-03-21 21:53:55,154 - ERROR - Error saving pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 21:53:55,155 - INFO - Save completed
2025-03-21 21:53:55,155 - INFO - Successfully saved: 
2025-03-21 21:53:55,155 - ERROR - Failed to save: shifting: 'coroutine' object has no attribute 'select', washing: 'coroutine' object has no attribute 'select', pti: 'coroutine' object has no attribute 'with_columns'
2025-03-21 22:05:42,241 - INFO - Exiting application
2025-03-21 22:05:51,318 - DEBUG - Using selector: EpollSelector
2025-03-21 22:05:51,318 - INFO - Starting application
2025-03-21 22:05:51,318 - INFO - Clearing screen
2025-03-21 22:05:53,221 - INFO - Selected: Save files
2025-03-21 22:05:53,221 - INFO - Clearing screen
2025-03-21 22:05:56,625 - INFO - Initiating save operation for emr
2025-03-21 22:05:56,626 - INFO - Processing dataframe category: emr
2025-03-21 22:05:56,626 - INFO - Processing dataframes: ['shifting', 'washing', 'pti']
2025-03-21 22:05:56,627 - INFO - Processing dataframe shifting of type <class 'function'>
2025-03-21 22:05:56,628 - INFO - Calling function for shifting
2025-03-21 22:05:56,628 - INFO - Awaiting result for shifting
2025-03-21 22:05:56,628 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'select'
2025-03-21 22:05:56,628 - INFO - Processing dataframe washing of type <class 'function'>
2025-03-21 22:05:56,629 - INFO - Calling function for washing
2025-03-21 22:05:56,629 - INFO - Awaiting result for washing
2025-03-21 22:05:56,632 - INFO - Processing dataframe pti of type <class 'function'>
2025-03-21 22:05:56,632 - INFO - Calling function for pti
2025-03-21 22:05:56,633 - INFO - Awaiting result for pti
2025-03-21 22:05:58,667 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'select'
2025-03-21 22:05:58,882 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'select'
2025-03-21 22:05:58,883 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'select'
2025-03-21 22:05:58,883 - ERROR - Error saving washing: 'coroutine' object has no attribute 'select'
2025-03-21 22:05:58,883 - ERROR - Error saving pti: 'coroutine' object has no attribute 'select'
2025-03-21 22:05:58,883 - INFO - Save completed
2025-03-21 22:05:58,883 - INFO - Successfully saved: 
2025-03-21 22:05:58,883 - ERROR - Failed to save: shifting: 'coroutine' object has no attribute 'select', washing: 'coroutine' object has no attribute 'select', pti: 'coroutine' object has no attribute 'select'
2025-03-21 22:17:11,055 - INFO - Exiting application
2025-03-22 08:05:49,833 - DEBUG - Using selector: EpollSelector
2025-03-22 08:05:49,833 - INFO - Starting application
2025-03-22 08:05:49,833 - INFO - Clearing screen
2025-03-22 08:05:52,001 - INFO - Selected: Save files
2025-03-22 08:05:52,001 - INFO - Clearing screen
2025-03-22 08:05:55,915 - INFO - Initiating save operation for all
2025-03-22 08:05:55,915 - INFO - Processing all dataframe categories concurrently
2025-03-22 08:05:55,916 - INFO - Queueing category: emr
2025-03-22 08:05:55,916 - INFO - Queueing category: operations
2025-03-22 08:05:55,916 - INFO - Queueing category: netlist
2025-03-22 08:05:55,916 - INFO - Queueing category: bin_dispatch
2025-03-22 08:05:55,917 - INFO - Queueing category: shore_handling
2025-03-22 08:05:55,917 - INFO - Queueing category: stuffing
2025-03-22 08:05:55,917 - INFO - Queueing category: transport
2025-03-22 08:05:55,917 - INFO - Queueing category: miscellaneous
2025-03-22 08:05:55,918 - INFO - Processing dataframe shifting of type <class 'coroutine'>
2025-03-22 08:05:55,919 - INFO - Successfully processed dataframe shifting
2025-03-22 08:05:55,920 - INFO - Writing to output/csv/shifting.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,920 - INFO - Processing dataframe washing of type <class 'coroutine'>
2025-03-22 08:05:55,921 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,921 - INFO - Successfully processed dataframe washing
2025-03-22 08:05:55,923 - INFO - Writing to output/csv/washing.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,924 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,925 - INFO - Processing dataframe pti of type <class 'coroutine'>
2025-03-22 08:05:55,925 - INFO - Successfully processed dataframe pti
2025-03-22 08:05:55,926 - INFO - Writing to output/csv/pti.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,927 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,927 - INFO - Processing dataframe ops of type <class 'coroutine'>
2025-03-22 08:05:55,928 - INFO - Successfully processed dataframe ops
2025-03-22 08:05:55,929 - INFO - Processing dataframe hatch_to_hatch of type <class 'coroutine'>
2025-03-22 08:05:55,929 - INFO - Writing to output/csv/ops.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,929 - INFO - Successfully processed dataframe hatch_to_hatch
2025-03-22 08:05:55,930 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,931 - INFO - Processing dataframe net_list of type <class 'coroutine'>
2025-03-22 08:05:55,931 - INFO - Writing to output/csv/hatch_to_hatch.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,932 - INFO - Successfully processed dataframe net_list
2025-03-22 08:05:55,933 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,933 - INFO - Processing dataframe iot_container_stuffing of type <class 'coroutine'>
2025-03-22 08:05:55,934 - INFO - Writing to output/csv/net_list.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,935 - INFO - Successfully processed dataframe iot_container_stuffing
2025-03-22 08:05:55,936 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,937 - INFO - Writing to output/csv/iot_container_stuffing.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,937 - INFO - Processing dataframe oss_stuffing of type <class 'coroutine'>
2025-03-22 08:05:55,937 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,938 - INFO - Successfully processed dataframe oss_stuffing
2025-03-22 08:05:55,939 - INFO - Writing to output/csv/oss_stuffing.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,940 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,941 - INFO - Processing dataframe full_scows_transfer of type <class 'coroutine'>
2025-03-22 08:05:55,941 - INFO - Successfully processed dataframe full_scows_transfer
2025-03-22 08:05:55,942 - INFO - Processing dataframe empty_scows_transfer of type <class 'coroutine'>
2025-03-22 08:05:55,942 - INFO - Writing to output/csv/full_scows_transfer.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,942 - INFO - Successfully processed dataframe empty_scows_transfer
2025-03-22 08:05:55,943 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,944 - INFO - Writing to output/csv/empty_scows_transfer.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,946 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,946 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,947 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,947 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,947 - ERROR - Error processing dataframe ops: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,947 - ERROR - Error processing dataframe hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,947 - ERROR - Error processing dataframe net_list: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,948 - ERROR - Error processing dataframe iot_container_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,948 - ERROR - Error processing dataframe oss_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,948 - ERROR - Error processing dataframe full_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,948 - INFO - Processing dataframe salt of type <class 'coroutine'>
2025-03-22 08:05:55,948 - INFO - Successfully processed dataframe salt
2025-03-22 08:05:55,949 - INFO - Processing dataframe bin_tipping of type <class 'coroutine'>
2025-03-22 08:05:55,949 - INFO - Writing to output/csv/salt.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,949 - INFO - Successfully processed dataframe bin_tipping
2025-03-22 08:05:55,949 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,950 - INFO - Writing to output/csv/bin_tipping.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,951 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,950 - INFO - Processing dataframe pallet_liner of type <class 'coroutine'>
2025-03-22 08:05:55,951 - INFO - Successfully processed dataframe pallet_liner
2025-03-22 08:05:55,951 - INFO - Processing dataframe container_plugin of type <class 'coroutine'>
2025-03-22 08:05:55,951 - INFO - Successfully processed dataframe container_plugin
2025-03-22 08:05:55,951 - INFO - Processing dataframe shore_crane of type <class 'coroutine'>
2025-03-22 08:05:55,951 - INFO - Successfully processed dataframe shore_crane
2025-03-22 08:05:55,952 - INFO - Processing dataframe transfer of type <class 'coroutine'>
2025-03-22 08:05:55,952 - INFO - Successfully processed dataframe transfer
2025-03-22 08:05:55,952 - INFO - Writing to output/csv/pallet_liner.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,952 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,952 - INFO - Writing to output/csv/container_plugin.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,952 - INFO - Writing to output/csv/shore_crane.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,952 - INFO - Writing to output/csv/transfer.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,952 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,952 - INFO - Processing dataframe scow_transfer of type <class 'coroutine'>
2025-03-22 08:05:55,953 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,953 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,953 - INFO - Successfully processed dataframe scow_transfer
2025-03-22 08:05:55,953 - INFO - Processing dataframe forklift of type <class 'coroutine'>
2025-03-22 08:05:55,953 - INFO - Writing to output/csv/scow_transfer.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,954 - INFO - Successfully processed dataframe forklift
2025-03-22 08:05:55,954 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,954 - INFO - Processing dataframe static_loader of type <class 'coroutine'>
2025-03-22 08:05:55,954 - INFO - Successfully processed dataframe static_loader
2025-03-22 08:05:55,954 - INFO - Writing to output/csv/forklift.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,954 - ERROR - Error processing dataframe empty_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,955 - INFO - Processing dataframe dispatch_to_cargo of type <class 'coroutine'>
2025-03-22 08:05:55,954 - INFO - Writing to output/csv/static_loader.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,955 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,954 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,955 - INFO - Successfully processed dataframe dispatch_to_cargo
2025-03-22 08:05:55,955 - INFO - Writing to output/csv/dispatch_to_cargo.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,955 - ERROR - Error processing dataframe salt: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,955 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,956 - ERROR - Error processing dataframe bin_tipping: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,956 - ERROR - Error processing dataframe pallet_liner: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,956 - ERROR - Error processing dataframe container_plugin: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,956 - ERROR - Error processing dataframe transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,956 - ERROR - Error processing dataframe shore_crane: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,956 - ERROR - Error processing dataframe scow_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,956 - INFO - Processing dataframe truck_to_cccs of type <class 'coroutine'>
2025-03-22 08:05:55,957 - INFO - Successfully processed dataframe truck_to_cccs
2025-03-22 08:05:55,957 - INFO - Processing dataframe cross_stuffing of type <class 'coroutine'>
2025-03-22 08:05:55,957 - INFO - Successfully processed dataframe cross_stuffing
2025-03-22 08:05:55,957 - INFO - Processing dataframe cccs_stuffing of type <class 'coroutine'>
2025-03-22 08:05:55,957 - INFO - Successfully processed dataframe cccs_stuffing
2025-03-22 08:05:55,957 - INFO - Processing dataframe bycatch of type <class 'coroutine'>
2025-03-22 08:05:55,957 - INFO - Successfully processed dataframe bycatch
2025-03-22 08:05:55,957 - INFO - Writing to output/csv/truck_to_cccs.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,957 - INFO - Writing to output/csv/cross_stuffing.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,957 - INFO - Writing to output/csv/cccs_stuffing.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,957 - ERROR - Error processing dataframe static_loader: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,958 - INFO - Writing to output/csv/bycatch.csv, df type: <class 'coroutine'>
2025-03-22 08:05:55,958 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,958 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,958 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,958 - ERROR - Error processing dataframe forklift: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,959 - ERROR - Error processing dataframe dispatch_to_cargo: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,960 - ERROR - Error processing dataframe bycatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,960 - ERROR - Error processing dataframe cross_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,960 - ERROR - Error processing dataframe cccs_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,958 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,960 - ERROR - Error processing dataframe truck_to_cccs: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,960 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,960 - ERROR - Error saving washing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,960 - ERROR - Error saving pti: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,961 - ERROR - Error saving ops: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,961 - ERROR - Error saving hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,961 - ERROR - Error saving net_list: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,961 - ERROR - Error saving iot_container_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,961 - ERROR - Error saving oss_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,961 - ERROR - Error saving full_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,961 - ERROR - Error saving empty_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,961 - ERROR - Error saving salt: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,961 - ERROR - Error saving bin_tipping: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,961 - ERROR - Error saving pallet_liner: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - ERROR - Error saving container_plugin: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - ERROR - Error saving shore_crane: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - ERROR - Error saving transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - ERROR - Error saving scow_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - ERROR - Error saving forklift: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - ERROR - Error saving static_loader: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - ERROR - Error saving dispatch_to_cargo: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - ERROR - Error saving truck_to_cccs: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - ERROR - Error saving cross_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - ERROR - Error saving cccs_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - ERROR - Error saving bycatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - INFO - Save completed
2025-03-22 08:05:55,962 - INFO - Successfully saved: 0 files
2025-03-22 08:05:55,962 - ERROR - Failed to save: 24 files
2025-03-22 08:05:55,962 - ERROR -   - shifting: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - ERROR -   - washing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - ERROR -   - pti: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,962 - ERROR -   - ops: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - net_list: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - iot_container_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - oss_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - full_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - empty_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - salt: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - bin_tipping: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - pallet_liner: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - container_plugin: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - shore_crane: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - scow_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - forklift: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - static_loader: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - dispatch_to_cargo: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - truck_to_cccs: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - cross_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - cccs_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:05:55,963 - ERROR -   - bycatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:10,007 - DEBUG - Using selector: EpollSelector
2025-03-22 08:17:10,007 - INFO - Starting application
2025-03-22 08:17:10,007 - INFO - Clearing screen
2025-03-22 08:17:11,974 - INFO - Selected: Save files
2025-03-22 08:17:11,974 - INFO - Clearing screen
2025-03-22 08:17:15,827 - INFO - Initiating save operation for all
2025-03-22 08:17:15,828 - INFO - Processing all dataframe categories concurrently
2025-03-22 08:17:15,828 - INFO - Queueing category: emr
2025-03-22 08:17:15,829 - INFO - Queueing category: operations
2025-03-22 08:17:15,829 - INFO - Queueing category: netlist
2025-03-22 08:17:15,829 - INFO - Queueing category: bin_dispatch
2025-03-22 08:17:15,829 - INFO - Queueing category: shore_handling
2025-03-22 08:17:15,830 - INFO - Queueing category: stuffing
2025-03-22 08:17:15,830 - INFO - Queueing category: transport
2025-03-22 08:17:15,830 - INFO - Queueing category: miscellaneous
2025-03-22 08:17:15,831 - INFO - Processing dataframe shifting of type <class 'coroutine'>
2025-03-22 08:17:15,832 - INFO - Successfully processed dataframe shifting
2025-03-22 08:17:15,832 - INFO - Writing to output/csv/shifting.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,833 - INFO - Processing dataframe washing of type <class 'coroutine'>
2025-03-22 08:17:15,833 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,834 - INFO - Successfully processed dataframe washing
2025-03-22 08:17:15,835 - INFO - Processing dataframe pti of type <class 'coroutine'>
2025-03-22 08:17:15,836 - INFO - Writing to output/csv/washing.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,836 - INFO - Successfully processed dataframe pti
2025-03-22 08:17:15,837 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,838 - INFO - Writing to output/csv/pti.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,839 - INFO - Processing dataframe ops of type <class 'coroutine'>
2025-03-22 08:17:15,839 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,840 - INFO - Successfully processed dataframe ops
2025-03-22 08:17:15,841 - INFO - Processing dataframe hatch_to_hatch of type <class 'coroutine'>
2025-03-22 08:17:15,842 - INFO - Writing to output/csv/ops.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,842 - INFO - Successfully processed dataframe hatch_to_hatch
2025-03-22 08:17:15,842 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,843 - INFO - Writing to output/csv/hatch_to_hatch.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,844 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,844 - INFO - Processing dataframe net_list of type <class 'coroutine'>
2025-03-22 08:17:15,845 - INFO - Successfully processed dataframe net_list
2025-03-22 08:17:15,845 - INFO - Processing dataframe iot_container_stuffing of type <class 'coroutine'>
2025-03-22 08:17:15,846 - INFO - Writing to output/csv/net_list.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,846 - INFO - Successfully processed dataframe iot_container_stuffing
2025-03-22 08:17:15,847 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,848 - INFO - Writing to output/csv/iot_container_stuffing.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,848 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,850 - INFO - Processing dataframe oss_stuffing of type <class 'coroutine'>
2025-03-22 08:17:15,850 - INFO - Successfully processed dataframe oss_stuffing
2025-03-22 08:17:15,850 - INFO - Processing dataframe full_scows_transfer of type <class 'coroutine'>
2025-03-22 08:17:15,851 - INFO - Writing to output/csv/oss_stuffing.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,851 - INFO - Successfully processed dataframe full_scows_transfer
2025-03-22 08:17:15,852 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,852 - INFO - Writing to output/csv/full_scows_transfer.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,853 - INFO - Processing dataframe empty_scows_transfer of type <class 'coroutine'>
2025-03-22 08:17:15,854 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,854 - INFO - Successfully processed dataframe empty_scows_transfer
2025-03-22 08:17:15,856 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,856 - INFO - Writing to output/csv/empty_scows_transfer.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,857 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,857 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,858 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,858 - ERROR - Error processing dataframe ops: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,859 - ERROR - Error processing dataframe hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,859 - ERROR - Error processing dataframe net_list: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,859 - ERROR - Error processing dataframe iot_container_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,860 - ERROR - Error processing dataframe oss_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,860 - ERROR - Error processing dataframe full_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,860 - INFO - Processing dataframe salt of type <class 'coroutine'>
2025-03-22 08:17:15,861 - INFO - Successfully processed dataframe salt
2025-03-22 08:17:15,861 - INFO - Processing dataframe bin_tipping of type <class 'coroutine'>
2025-03-22 08:17:15,861 - INFO - Writing to output/csv/salt.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,862 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,862 - INFO - Successfully processed dataframe bin_tipping
2025-03-22 08:17:15,863 - INFO - Writing to output/csv/bin_tipping.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,863 - INFO - Processing dataframe pallet_liner of type <class 'coroutine'>
2025-03-22 08:17:15,863 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,863 - INFO - Successfully processed dataframe pallet_liner
2025-03-22 08:17:15,864 - INFO - Writing to output/csv/pallet_liner.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,864 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,864 - INFO - Processing dataframe container_plugin of type <class 'coroutine'>
2025-03-22 08:17:15,865 - INFO - Successfully processed dataframe container_plugin
2025-03-22 08:17:15,865 - INFO - Processing dataframe shore_crane of type <class 'coroutine'>
2025-03-22 08:17:15,865 - INFO - Writing to output/csv/container_plugin.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,866 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,866 - INFO - Successfully processed dataframe shore_crane
2025-03-22 08:17:15,866 - INFO - Processing dataframe transfer of type <class 'coroutine'>
2025-03-22 08:17:15,867 - INFO - Successfully processed dataframe transfer
2025-03-22 08:17:15,867 - INFO - Processing dataframe scow_transfer of type <class 'coroutine'>
2025-03-22 08:17:15,867 - INFO - Successfully processed dataframe scow_transfer
2025-03-22 08:17:15,867 - INFO - Writing to output/csv/shore_crane.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,868 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,868 - INFO - Writing to output/csv/transfer.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,868 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,868 - INFO - Writing to output/csv/scow_transfer.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,869 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,869 - INFO - Processing dataframe forklift of type <class 'coroutine'>
2025-03-22 08:17:15,869 - INFO - Successfully processed dataframe forklift
2025-03-22 08:17:15,870 - INFO - Processing dataframe static_loader of type <class 'coroutine'>
2025-03-22 08:17:15,870 - INFO - Successfully processed dataframe static_loader
2025-03-22 08:17:15,870 - INFO - Writing to output/csv/static_loader.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,870 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,871 - ERROR - Error processing dataframe empty_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,871 - ERROR - Error processing dataframe salt: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,870 - INFO - Writing to output/csv/forklift.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,871 - INFO - Processing dataframe dispatch_to_cargo of type <class 'coroutine'>
2025-03-22 08:17:15,872 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,872 - INFO - Successfully processed dataframe dispatch_to_cargo
2025-03-22 08:17:15,872 - ERROR - Error processing dataframe bin_tipping: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,872 - INFO - Writing to output/csv/dispatch_to_cargo.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,872 - ERROR - Error processing dataframe pallet_liner: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,873 - ERROR - Error processing dataframe container_plugin: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,873 - ERROR - Error processing dataframe shore_crane: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,873 - ERROR - Error processing dataframe transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,873 - ERROR - Error processing dataframe scow_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,873 - ERROR - Error processing dataframe static_loader: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,874 - INFO - Processing dataframe truck_to_cccs of type <class 'coroutine'>
2025-03-22 08:17:15,874 - INFO - Successfully processed dataframe truck_to_cccs
2025-03-22 08:17:15,874 - INFO - Processing dataframe cross_stuffing of type <class 'coroutine'>
2025-03-22 08:17:15,874 - INFO - Successfully processed dataframe cross_stuffing
2025-03-22 08:17:15,874 - INFO - Processing dataframe cccs_stuffing of type <class 'coroutine'>
2025-03-22 08:17:15,874 - INFO - Successfully processed dataframe cccs_stuffing
2025-03-22 08:17:15,873 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,875 - INFO - Writing to output/csv/truck_to_cccs.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,875 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,875 - INFO - Writing to output/csv/cross_stuffing.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,875 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,875 - INFO - Writing to output/csv/cccs_stuffing.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,875 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,876 - INFO - Processing dataframe bycatch of type <class 'coroutine'>
2025-03-22 08:17:15,876 - INFO - Successfully processed dataframe bycatch
2025-03-22 08:17:15,876 - ERROR - Error processing dataframe forklift: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,876 - INFO - Writing to output/csv/bycatch.csv, df type: <class 'coroutine'>
2025-03-22 08:17:15,876 - ERROR - Error processing dataframe dispatch_to_cargo: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,877 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,877 - ERROR - Error processing dataframe truck_to_cccs: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,877 - ERROR - Error processing dataframe cross_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,877 - ERROR - Error processing dataframe cccs_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,877 - ERROR - Error processing dataframe bycatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,877 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,878 - ERROR - Error saving washing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,878 - ERROR - Error saving pti: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,878 - ERROR - Error saving ops: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,878 - ERROR - Error saving hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,878 - ERROR - Error saving net_list: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,878 - ERROR - Error saving iot_container_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,878 - ERROR - Error saving oss_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,878 - ERROR - Error saving full_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,878 - ERROR - Error saving empty_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,878 - ERROR - Error saving salt: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,878 - ERROR - Error saving bin_tipping: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,879 - ERROR - Error saving pallet_liner: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,879 - ERROR - Error saving container_plugin: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,879 - ERROR - Error saving shore_crane: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,879 - ERROR - Error saving transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,879 - ERROR - Error saving scow_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,879 - ERROR - Error saving forklift: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,879 - ERROR - Error saving static_loader: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,879 - ERROR - Error saving dispatch_to_cargo: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,879 - ERROR - Error saving truck_to_cccs: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,879 - ERROR - Error saving cross_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,879 - ERROR - Error saving cccs_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,879 - ERROR - Error saving bycatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,880 - INFO - Save completed
2025-03-22 08:17:15,880 - INFO - Successfully saved: 0 files
2025-03-22 08:17:15,880 - ERROR - Failed to save: 24 files
2025-03-22 08:17:15,880 - ERROR -   - shifting: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,880 - ERROR -   - washing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,880 - ERROR -   - pti: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,880 - ERROR -   - ops: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,880 - ERROR -   - hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,880 - ERROR -   - net_list: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,881 - ERROR -   - iot_container_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,881 - ERROR -   - oss_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,881 - ERROR -   - full_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,881 - ERROR -   - empty_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,881 - ERROR -   - salt: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,881 - ERROR -   - bin_tipping: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,881 - ERROR -   - pallet_liner: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,881 - ERROR -   - container_plugin: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,881 - ERROR -   - shore_crane: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,881 - ERROR -   - transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,881 - ERROR -   - scow_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,882 - ERROR -   - forklift: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,882 - ERROR -   - static_loader: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,882 - ERROR -   - dispatch_to_cargo: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,882 - ERROR -   - truck_to_cccs: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,882 - ERROR -   - cross_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,882 - ERROR -   - cccs_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:17:15,882 - ERROR -   - bycatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:26:46,971 - INFO - Exiting application
2025-03-22 08:26:50,116 - DEBUG - Using selector: EpollSelector
2025-03-22 08:26:50,117 - INFO - Starting application
2025-03-22 08:26:50,117 - INFO - Clearing screen
2025-03-22 08:26:52,130 - INFO - Selected: Save files
2025-03-22 08:26:52,130 - INFO - Clearing screen
2025-03-22 08:26:58,039 - INFO - Initiating save operation for operations
2025-03-22 08:26:58,040 - INFO - Processing dataframe category: operations
2025-03-22 08:26:58,040 - INFO - Processing dataframes: ['ops', 'hatch_to_hatch']
2025-03-22 08:26:58,041 - INFO - Processing dataframe ops of type <class 'coroutine'>
2025-03-22 08:26:58,041 - INFO - Successfully processed dataframe ops
2025-03-22 08:26:58,043 - INFO - Writing to output/csv/ops.csv, df type: <class 'coroutine'>
2025-03-22 08:26:58,043 - INFO - Processing dataframe hatch_to_hatch of type <class 'coroutine'>
2025-03-22 08:26:58,044 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:26:58,044 - INFO - Successfully processed dataframe hatch_to_hatch
2025-03-22 08:26:58,046 - INFO - Writing to output/csv/hatch_to_hatch.csv, df type: <class 'coroutine'>
2025-03-22 08:26:58,046 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:26:58,047 - ERROR - Error processing dataframe ops: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:26:58,048 - ERROR - Error processing dataframe hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:26:58,048 - ERROR - Error saving ops: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:26:58,048 - ERROR - Error saving hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 08:26:58,049 - INFO - Save completed
2025-03-22 08:26:58,049 - INFO - Successfully saved: 
2025-03-22 08:26:58,049 - ERROR - Failed to save: ops: 'coroutine' object has no attribute 'write_csv', hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:08:43,493 - INFO - Exiting application
2025-03-22 09:08:48,152 - DEBUG - Using selector: EpollSelector
2025-03-22 09:08:48,152 - INFO - Starting application
2025-03-22 09:08:48,152 - INFO - Clearing screen
2025-03-22 09:08:49,929 - INFO - Selected: Save files
2025-03-22 09:08:49,930 - INFO - Clearing screen
2025-03-22 09:08:53,934 - INFO - Initiating save operation for emr
2025-03-22 09:08:53,934 - INFO - Processing dataframe category: emr
2025-03-22 09:08:53,934 - INFO - Processing dataframes: ['shifting', 'washing', 'pti']
2025-03-22 09:08:53,935 - INFO - Processing dataframe shifting of type <class 'coroutine'>
2025-03-22 09:08:53,935 - INFO - Successfully processed dataframe shifting
2025-03-22 09:08:53,935 - INFO - Writing to output/csv/shifting.csv, df type: <class 'coroutine'>
2025-03-22 09:08:53,935 - INFO - Processing dataframe washing of type <class 'coroutine'>
2025-03-22 09:08:53,936 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:08:53,936 - INFO - Successfully processed dataframe washing
2025-03-22 09:08:53,936 - INFO - Writing to output/csv/washing.csv, df type: <class 'coroutine'>
2025-03-22 09:08:53,936 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:08:53,936 - INFO - Processing dataframe pti of type <class 'coroutine'>
2025-03-22 09:08:53,936 - INFO - Successfully processed dataframe pti
2025-03-22 09:08:53,937 - INFO - Writing to output/csv/pti.csv, df type: <class 'coroutine'>
2025-03-22 09:08:53,937 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:08:53,937 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:08:53,937 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:08:53,937 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:08:53,937 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:08:53,937 - ERROR - Error saving washing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:08:53,937 - ERROR - Error saving pti: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:08:53,937 - INFO - Save completed
2025-03-22 09:08:53,938 - INFO - Successfully saved: 
2025-03-22 09:08:53,938 - ERROR - Failed to save: shifting: 'coroutine' object has no attribute 'write_csv', washing: 'coroutine' object has no attribute 'write_csv', pti: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:11,746 - INFO - Exiting application
2025-03-22 09:22:15,023 - DEBUG - Using selector: EpollSelector
2025-03-22 09:22:15,023 - INFO - Starting application
2025-03-22 09:22:15,023 - INFO - Clearing screen
2025-03-22 09:22:17,190 - INFO - Selected: Save files
2025-03-22 09:22:17,191 - INFO - Clearing screen
2025-03-22 09:22:20,596 - INFO - Initiating save operation for all
2025-03-22 09:22:20,597 - INFO - Processing all dataframe categories concurrently
2025-03-22 09:22:20,597 - INFO - Queueing category: emr
2025-03-22 09:22:20,598 - INFO - Queueing category: operations
2025-03-22 09:22:20,598 - INFO - Queueing category: netlist
2025-03-22 09:22:20,599 - INFO - Queueing category: bin_dispatch
2025-03-22 09:22:20,599 - INFO - Queueing category: shore_handling
2025-03-22 09:22:20,599 - INFO - Queueing category: stuffing
2025-03-22 09:22:20,600 - INFO - Queueing category: transport
2025-03-22 09:22:20,600 - INFO - Queueing category: miscellaneous
2025-03-22 09:22:20,601 - INFO - Processing dataframe shifting of type <class 'coroutine'>
2025-03-22 09:22:20,601 - INFO - Successfully processed dataframe shifting
2025-03-22 09:22:20,603 - INFO - Writing to output/csv/shifting.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,603 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,604 - INFO - Processing dataframe washing of type <class 'coroutine'>
2025-03-22 09:22:20,605 - INFO - Successfully processed dataframe washing
2025-03-22 09:22:20,605 - INFO - Processing dataframe pti of type <class 'coroutine'>
2025-03-22 09:22:20,606 - INFO - Writing to output/csv/washing.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,606 - INFO - Successfully processed dataframe pti
2025-03-22 09:22:20,606 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,608 - INFO - Writing to output/csv/pti.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,609 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,608 - INFO - Processing dataframe ops of type <class 'coroutine'>
2025-03-22 09:22:20,610 - INFO - Successfully processed dataframe ops
2025-03-22 09:22:20,611 - INFO - Processing dataframe hatch_to_hatch of type <class 'coroutine'>
2025-03-22 09:22:20,611 - INFO - Writing to output/csv/ops.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,611 - INFO - Successfully processed dataframe hatch_to_hatch
2025-03-22 09:22:20,612 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,613 - INFO - Processing dataframe net_list of type <class 'coroutine'>
2025-03-22 09:22:20,614 - INFO - Writing to output/csv/hatch_to_hatch.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,614 - INFO - Successfully processed dataframe net_list
2025-03-22 09:22:20,615 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,616 - INFO - Processing dataframe iot_container_stuffing of type <class 'coroutine'>
2025-03-22 09:22:20,616 - INFO - Writing to output/csv/net_list.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,617 - INFO - Successfully processed dataframe iot_container_stuffing
2025-03-22 09:22:20,618 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,619 - INFO - Processing dataframe oss_stuffing of type <class 'coroutine'>
2025-03-22 09:22:20,619 - INFO - Writing to output/csv/iot_container_stuffing.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,620 - INFO - Successfully processed dataframe oss_stuffing
2025-03-22 09:22:20,620 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,621 - INFO - Writing to output/csv/oss_stuffing.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,622 - INFO - Processing dataframe full_scows_transfer of type <class 'coroutine'>
2025-03-22 09:22:20,622 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,623 - INFO - Successfully processed dataframe full_scows_transfer
2025-03-22 09:22:20,624 - INFO - Processing dataframe empty_scows_transfer of type <class 'coroutine'>
2025-03-22 09:22:20,624 - INFO - Writing to output/csv/full_scows_transfer.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,625 - INFO - Successfully processed dataframe empty_scows_transfer
2025-03-22 09:22:20,625 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,626 - ERROR - Error processing dataframe shifting: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,629 - INFO - Writing to output/csv/empty_scows_transfer.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,630 - ERROR - Error processing dataframe washing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,630 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,631 - ERROR - Error processing dataframe pti: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,632 - ERROR - Error processing dataframe ops: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,632 - ERROR - Error processing dataframe hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,632 - ERROR - Error processing dataframe net_list: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,633 - ERROR - Error processing dataframe iot_container_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,633 - ERROR - Error processing dataframe oss_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,633 - INFO - Processing dataframe salt of type <class 'coroutine'>
2025-03-22 09:22:20,634 - INFO - Successfully processed dataframe salt
2025-03-22 09:22:20,634 - INFO - Writing to output/csv/salt.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,635 - INFO - Processing dataframe bin_tipping of type <class 'coroutine'>
2025-03-22 09:22:20,635 - INFO - Successfully processed dataframe bin_tipping
2025-03-22 09:22:20,635 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,636 - INFO - Writing to output/csv/bin_tipping.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,637 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,637 - INFO - Processing dataframe pallet_liner of type <class 'coroutine'>
2025-03-22 09:22:20,637 - INFO - Successfully processed dataframe pallet_liner
2025-03-22 09:22:20,638 - INFO - Processing dataframe container_plugin of type <class 'coroutine'>
2025-03-22 09:22:20,638 - INFO - Successfully processed dataframe container_plugin
2025-03-22 09:22:20,638 - INFO - Writing to output/csv/pallet_liner.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,639 - INFO - Writing to output/csv/container_plugin.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,640 - INFO - Processing dataframe shore_crane of type <class 'coroutine'>
2025-03-22 09:22:20,640 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,640 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,641 - INFO - Successfully processed dataframe shore_crane
2025-03-22 09:22:20,642 - INFO - Writing to output/csv/shore_crane.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,643 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,644 - INFO - Processing dataframe transfer of type <class 'coroutine'>
2025-03-22 09:22:20,644 - INFO - Successfully processed dataframe transfer
2025-03-22 09:22:20,644 - INFO - Processing dataframe scow_transfer of type <class 'coroutine'>
2025-03-22 09:22:20,645 - INFO - Writing to output/csv/transfer.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,646 - INFO - Successfully processed dataframe scow_transfer
2025-03-22 09:22:20,646 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,647 - INFO - Writing to output/csv/scow_transfer.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,648 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,647 - INFO - Processing dataframe forklift of type <class 'coroutine'>
2025-03-22 09:22:20,649 - INFO - Successfully processed dataframe forklift
2025-03-22 09:22:20,649 - INFO - Writing to output/csv/forklift.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,650 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,651 - ERROR - Error processing dataframe full_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,651 - ERROR - Error processing dataframe empty_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,652 - INFO - Processing dataframe static_loader of type <class 'coroutine'>
2025-03-22 09:22:20,652 - INFO - Successfully processed dataframe static_loader
2025-03-22 09:22:20,653 - INFO - Processing dataframe dispatch_to_cargo of type <class 'coroutine'>
2025-03-22 09:22:20,653 - INFO - Successfully processed dataframe dispatch_to_cargo
2025-03-22 09:22:20,654 - ERROR - Error processing dataframe salt: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,654 - ERROR - Error processing dataframe bin_tipping: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,654 - ERROR - Error processing dataframe pallet_liner: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,654 - ERROR - Error processing dataframe container_plugin: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,655 - ERROR - Error processing dataframe shore_crane: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,656 - INFO - Writing to output/csv/static_loader.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,656 - INFO - Writing to output/csv/dispatch_to_cargo.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,657 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,657 - ERROR - Error processing dataframe transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,658 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,659 - ERROR - Error processing dataframe scow_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,659 - ERROR - Error processing dataframe forklift: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,660 - INFO - Processing dataframe truck_to_cccs of type <class 'coroutine'>
2025-03-22 09:22:20,660 - INFO - Successfully processed dataframe truck_to_cccs
2025-03-22 09:22:20,661 - INFO - Writing to output/csv/truck_to_cccs.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,661 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,662 - INFO - Processing dataframe cross_stuffing of type <class 'coroutine'>
2025-03-22 09:22:20,662 - INFO - Successfully processed dataframe cross_stuffing
2025-03-22 09:22:20,662 - INFO - Writing to output/csv/cross_stuffing.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,662 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,663 - INFO - Processing dataframe cccs_stuffing of type <class 'coroutine'>
2025-03-22 09:22:20,663 - INFO - Successfully processed dataframe cccs_stuffing
2025-03-22 09:22:20,663 - INFO - Writing to output/csv/cccs_stuffing.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,664 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,664 - INFO - Processing dataframe bycatch of type <class 'coroutine'>
2025-03-22 09:22:20,664 - INFO - Successfully processed dataframe bycatch
2025-03-22 09:22:20,665 - INFO - Writing to output/csv/bycatch.csv, df type: <class 'coroutine'>
2025-03-22 09:22:20,665 - ERROR - Error in write_df_to_csv: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,665 - ERROR - Error processing dataframe static_loader: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,666 - ERROR - Error processing dataframe dispatch_to_cargo: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,666 - ERROR - Error processing dataframe truck_to_cccs: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,666 - ERROR - Error processing dataframe cross_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,666 - ERROR - Error processing dataframe cccs_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,667 - ERROR - Error processing dataframe bycatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,667 - ERROR - Error saving shifting: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,667 - ERROR - Error saving washing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,667 - ERROR - Error saving pti: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,668 - ERROR - Error saving ops: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,668 - ERROR - Error saving hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,668 - ERROR - Error saving net_list: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,668 - ERROR - Error saving iot_container_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,668 - ERROR - Error saving oss_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,668 - ERROR - Error saving full_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,669 - ERROR - Error saving empty_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,669 - ERROR - Error saving salt: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,669 - ERROR - Error saving bin_tipping: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,669 - ERROR - Error saving pallet_liner: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,669 - ERROR - Error saving container_plugin: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,669 - ERROR - Error saving shore_crane: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,669 - ERROR - Error saving transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,670 - ERROR - Error saving scow_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,670 - ERROR - Error saving forklift: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,670 - ERROR - Error saving static_loader: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,670 - ERROR - Error saving dispatch_to_cargo: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,670 - ERROR - Error saving truck_to_cccs: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,671 - ERROR - Error saving cross_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,671 - ERROR - Error saving cccs_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,671 - ERROR - Error saving bycatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,671 - INFO - Save completed
2025-03-22 09:22:20,671 - INFO - Successfully saved: 0 files
2025-03-22 09:22:20,672 - ERROR - Failed to save: 24 files
2025-03-22 09:22:20,672 - ERROR -   - shifting: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,672 - ERROR -   - washing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,672 - ERROR -   - pti: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,672 - ERROR -   - ops: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,672 - ERROR -   - hatch_to_hatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,673 - ERROR -   - net_list: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,673 - ERROR -   - iot_container_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,673 - ERROR -   - oss_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,673 - ERROR -   - full_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,673 - ERROR -   - empty_scows_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,673 - ERROR -   - salt: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,674 - ERROR -   - bin_tipping: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,674 - ERROR -   - pallet_liner: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,674 - ERROR -   - container_plugin: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,674 - ERROR -   - shore_crane: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,674 - ERROR -   - transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,674 - ERROR -   - scow_transfer: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,674 - ERROR -   - forklift: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,675 - ERROR -   - static_loader: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,675 - ERROR -   - dispatch_to_cargo: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,675 - ERROR -   - truck_to_cccs: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,675 - ERROR -   - cross_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,675 - ERROR -   - cccs_stuffing: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:22:20,675 - ERROR -   - bycatch: 'coroutine' object has no attribute 'write_csv'
2025-03-22 09:23:48,031 - INFO - Exiting application
2025-03-22 09:23:50,273 - DEBUG - Using selector: EpollSelector
2025-03-22 09:23:50,273 - INFO - Starting application
2025-03-22 09:23:50,273 - INFO - Clearing screen
2025-03-22 09:23:51,931 - INFO - Selected: Save files
2025-03-22 09:23:51,931 - INFO - Clearing screen
2025-03-22 09:23:55,291 - INFO - Initiating save operation for all
2025-03-22 09:23:56,482 - INFO - Using cached data for Price
2025-03-22 09:25:45,965 - DEBUG - Using selector: EpollSelector
2025-03-22 09:25:45,966 - INFO - Starting application
2025-03-22 09:25:45,966 - INFO - Clearing screen
2025-03-22 09:25:47,384 - INFO - Selected: Save files
2025-03-22 09:25:47,385 - INFO - Clearing screen
2025-03-22 09:25:50,264 - INFO - Initiating save operation for all
2025-03-22 09:25:50,970 - INFO - Using cached data for Price
2025-03-22 09:25:54,599 - INFO - Using cached data for Transfer
2025-03-22 09:25:54,602 - INFO - Using cached data for Price
2025-03-22 09:25:54,602 - INFO - Using cached data for Price
2025-03-22 09:25:55,873 - INFO - Using cached data for Transfer
2025-03-22 09:25:55,875 - INFO - Using cached data for Price
2025-03-22 09:25:55,875 - INFO - Using cached data for Price
2025-03-22 09:25:55,878 - INFO - Using cached data for Price
2025-03-22 09:25:55,878 - INFO - Using cached data for Price
2025-03-22 09:27:29,289 - DEBUG - Using selector: EpollSelector
2025-03-22 09:27:29,290 - INFO - Starting application
2025-03-22 09:27:29,290 - INFO - Clearing screen
2025-03-22 09:27:30,703 - INFO - Selected: Save files
2025-03-22 09:27:30,704 - INFO - Clearing screen
2025-03-22 09:27:33,373 - INFO - Initiating save operation for all
2025-03-22 09:27:34,080 - INFO - Using cached data for Price
2025-03-22 09:27:38,035 - INFO - Using cached data for Transfer
2025-03-22 09:27:38,040 - INFO - Using cached data for Price
2025-03-22 09:27:38,040 - INFO - Using cached data for Price
2025-03-22 09:27:39,235 - INFO - Using cached data for Transfer
2025-03-22 09:27:39,237 - INFO - Using cached data for Price
2025-03-22 09:27:39,237 - INFO - Using cached data for Price
2025-03-22 09:27:39,240 - INFO - Using cached data for Price
2025-03-22 09:27:39,240 - INFO - Using cached data for Price
2025-03-22 09:31:05,643 - DEBUG - Using selector: EpollSelector
2025-03-22 09:31:05,644 - INFO - Starting application
2025-03-22 09:31:05,644 - INFO - Clearing screen
2025-03-22 09:31:07,121 - INFO - Selected: Save files
2025-03-22 09:31:07,121 - INFO - Clearing screen
2025-03-22 09:31:10,706 - INFO - Initiating save operation for emr
2025-03-22 09:31:11,591 - INFO - Using cached data for Price
2025-03-22 09:31:15,676 - INFO - Using cached data for Transfer
2025-03-22 09:31:15,681 - INFO - Using cached data for Price
2025-03-22 09:31:15,681 - INFO - Using cached data for Price
2025-03-22 09:31:16,948 - INFO - Using cached data for Transfer
2025-03-22 09:31:16,951 - INFO - Using cached data for Price
2025-03-22 09:31:16,951 - INFO - Using cached data for Price
2025-03-22 09:31:16,953 - INFO - Using cached data for Price
2025-03-22 09:31:16,953 - INFO - Using cached data for Price
2025-03-22 09:35:40,074 - DEBUG - Using selector: EpollSelector
2025-03-22 09:35:40,075 - INFO - Starting application
2025-03-22 09:35:40,075 - INFO - Clearing screen
2025-03-22 09:35:41,619 - INFO - Selected: Save files
2025-03-22 09:35:41,619 - INFO - Clearing screen
2025-03-22 09:35:44,756 - INFO - Initiating save operation for emr
2025-03-22 09:35:45,552 - INFO - Using cached data for Price
2025-03-22 09:35:49,247 - INFO - Using cached data for Transfer
2025-03-22 09:35:49,251 - INFO - Using cached data for Price
2025-03-22 09:35:49,251 - INFO - Using cached data for Price
2025-03-22 09:35:50,447 - INFO - Using cached data for Transfer
2025-03-22 09:35:50,449 - INFO - Using cached data for Price
2025-03-22 09:35:50,520 - INFO - Using cached data for Price
2025-03-22 09:35:50,532 - INFO - Using cached data for Price
2025-03-22 09:35:50,532 - INFO - Using cached data for Price
2025-03-22 09:42:14,308 - DEBUG - Using selector: EpollSelector
2025-03-22 09:42:14,309 - INFO - Starting application
2025-03-22 09:42:14,309 - INFO - Clearing screen
2025-03-22 09:42:15,880 - INFO - Selected: Save files
2025-03-22 09:42:15,881 - INFO - Clearing screen
2025-03-22 09:42:20,141 - INFO - Initiating save operation for emr
2025-03-22 09:42:21,056 - INFO - Using cached data for Price
2025-03-22 09:42:27,016 - INFO - Using cached data for Transfer
2025-03-22 09:42:27,020 - INFO - Using cached data for Price
2025-03-22 09:42:27,020 - INFO - Using cached data for Price
2025-03-22 09:42:28,308 - INFO - Using cached data for Transfer
2025-03-22 09:42:28,310 - INFO - Using cached data for Price
2025-03-22 09:42:28,310 - INFO - Using cached data for Price
2025-03-22 09:42:28,312 - INFO - Using cached data for Price
2025-03-22 09:42:28,313 - INFO - Using cached data for Price
2025-03-22 09:44:11,909 - DEBUG - Using selector: EpollSelector
2025-03-22 09:44:11,909 - INFO - Starting application
2025-03-22 09:44:11,909 - INFO - Clearing screen
2025-03-22 09:44:13,241 - INFO - Selected: Save files
2025-03-22 09:44:13,241 - INFO - Clearing screen
2025-03-22 09:44:17,215 - INFO - Initiating save operation for all
2025-03-22 09:44:17,896 - INFO - Using cached data for Price
2025-03-22 09:44:21,669 - INFO - Using cached data for Transfer
2025-03-22 09:44:21,674 - INFO - Using cached data for Price
2025-03-22 09:44:21,674 - INFO - Using cached data for Price
2025-03-22 09:44:22,874 - INFO - Using cached data for Transfer
2025-03-22 09:44:22,876 - INFO - Using cached data for Price
2025-03-22 09:44:22,876 - INFO - Using cached data for Price
2025-03-22 09:44:22,878 - INFO - Using cached data for Price
2025-03-22 09:44:22,878 - INFO - Using cached data for Price
2025-03-22 09:44:24,401 - INFO - Using cached data for Price
2025-03-22 09:44:24,401 - INFO - Using cached data for Price
2025-03-22 09:45:34,004 - DEBUG - Using selector: EpollSelector
2025-03-22 09:45:34,004 - INFO - Starting application
2025-03-22 09:45:34,004 - INFO - Clearing screen
2025-03-22 09:45:35,530 - INFO - Selected: Save files
2025-03-22 09:45:35,530 - INFO - Clearing screen
2025-03-22 09:45:38,651 - INFO - Initiating save operation for all
2025-03-22 09:45:39,306 - INFO - Using cached data for Price
2025-03-22 09:45:42,933 - INFO - Using cached data for Transfer
2025-03-22 09:45:42,938 - INFO - Using cached data for Price
2025-03-22 09:45:42,938 - INFO - Using cached data for Price
2025-03-22 09:45:44,108 - INFO - Using cached data for Transfer
2025-03-22 09:45:44,112 - INFO - Using cached data for Price
2025-03-22 09:45:44,112 - INFO - Using cached data for Price
2025-03-22 09:45:44,114 - INFO - Using cached data for Price
2025-03-22 09:45:44,114 - INFO - Using cached data for Price
2025-03-22 09:45:45,503 - INFO - Using cached data for Price
2025-03-22 09:45:45,503 - INFO - Using cached data for Price
2025-03-22 09:46:57,743 - DEBUG - Using selector: EpollSelector
2025-03-22 09:46:57,744 - INFO - Starting application
2025-03-22 09:46:57,744 - INFO - Clearing screen
2025-03-22 09:46:59,066 - INFO - Selected: Save files
2025-03-22 09:46:59,067 - INFO - Clearing screen
2025-03-22 09:47:01,587 - INFO - Initiating save operation for all
2025-03-22 09:47:02,249 - INFO - Using cached data for Price
2025-03-22 09:47:05,693 - INFO - Using cached data for Transfer
2025-03-22 09:47:05,697 - INFO - Using cached data for Price
2025-03-22 09:47:05,697 - INFO - Using cached data for Price
2025-03-22 09:47:06,888 - INFO - Using cached data for Transfer
2025-03-22 09:47:06,891 - INFO - Using cached data for Price
2025-03-22 09:47:06,891 - INFO - Using cached data for Price
2025-03-22 09:47:06,893 - INFO - Using cached data for Price
2025-03-22 09:47:06,893 - INFO - Using cached data for Price
2025-03-22 09:47:09,787 - INFO - Using cached data for Price
2025-03-22 09:47:09,787 - INFO - Using cached data for Price
2025-03-22 09:48:43,721 - DEBUG - Using selector: EpollSelector
2025-03-22 09:48:43,722 - INFO - Starting application
2025-03-22 09:48:43,722 - INFO - Clearing screen
2025-03-22 09:48:45,178 - INFO - Selected: Save files
2025-03-22 09:48:45,179 - INFO - Clearing screen
2025-03-22 09:48:48,956 - INFO - Initiating save operation for all
2025-03-22 09:48:49,872 - INFO - Using cached data for Price
2025-03-22 09:48:53,417 - INFO - Using cached data for Transfer
2025-03-22 09:48:53,421 - INFO - Using cached data for Price
2025-03-22 09:48:53,421 - INFO - Using cached data for Price
2025-03-22 09:48:54,529 - INFO - Using cached data for Transfer
2025-03-22 09:48:54,532 - INFO - Using cached data for Price
2025-03-22 09:48:54,532 - INFO - Using cached data for Price
2025-03-22 09:48:54,535 - INFO - Using cached data for Price
2025-03-22 09:48:54,535 - INFO - Using cached data for Price
2025-03-22 09:48:57,015 - INFO - Using cached data for Price
2025-03-22 09:48:57,015 - INFO - Using cached data for Price
2025-03-22 09:50:08,086 - DEBUG - Using selector: EpollSelector
2025-03-22 09:50:08,086 - INFO - Starting application
2025-03-22 09:50:08,086 - INFO - Clearing screen
2025-03-22 09:50:09,492 - INFO - Selected: Save files
2025-03-22 09:50:09,492 - INFO - Clearing screen
2025-03-22 09:50:12,086 - INFO - Initiating save operation for all
2025-03-22 09:50:12,831 - INFO - Using cached data for Price
2025-03-22 09:50:17,550 - INFO - Using cached data for Transfer
2025-03-22 09:50:17,554 - INFO - Using cached data for Price
2025-03-22 09:50:17,555 - INFO - Using cached data for Price
2025-03-22 09:50:18,544 - INFO - Using cached data for Transfer
2025-03-22 09:50:18,546 - INFO - Using cached data for Price
2025-03-22 09:50:18,546 - INFO - Using cached data for Price
2025-03-22 09:50:18,549 - INFO - Using cached data for Price
2025-03-22 09:50:18,549 - INFO - Using cached data for Price
2025-03-22 09:50:21,287 - INFO - Using cached data for Price
2025-03-22 09:50:21,287 - INFO - Using cached data for Price
2025-03-22 09:50:21,304 - INFO - Using cached data for ScowTransfer
2025-03-22 09:50:21,305 - INFO - Using cached data for Price
2025-03-22 09:50:21,305 - INFO - Using cached data for Price
2025-03-22 13:22:17,684 - DEBUG - Using selector: EpollSelector
2025-03-22 13:22:17,685 - INFO - Starting application
2025-03-22 13:22:17,685 - INFO - Clearing screen
2025-03-22 13:22:19,394 - INFO - Selected: Save files
2025-03-22 13:22:19,394 - INFO - Clearing screen
2025-03-22 13:22:22,755 - INFO - Initiating save operation for emr
2025-03-22 13:22:23,607 - INFO - Using cached data for Price
2025-03-22 13:22:30,348 - INFO - Using cached data for Transfer
2025-03-22 13:22:30,352 - INFO - Using cached data for Price
2025-03-22 13:22:30,352 - INFO - Using cached data for Price
2025-03-22 13:22:31,388 - INFO - Using cached data for Transfer
2025-03-22 13:22:31,391 - INFO - Using cached data for Price
2025-03-22 13:22:31,391 - INFO - Using cached data for Price
2025-03-22 13:22:31,393 - INFO - Using cached data for Price
2025-03-22 13:22:31,393 - INFO - Using cached data for Price
2025-03-22 13:22:34,492 - INFO - Using cached data for Price
2025-03-22 13:22:34,492 - INFO - Using cached data for Price
2025-03-22 13:22:34,493 - INFO - Using cached data for ScowTransfer
2025-03-22 13:22:34,493 - INFO - Using cached data for Price
2025-03-22 13:22:34,493 - INFO - Using cached data for Price
2025-03-22 13:26:37,789 - DEBUG - Using selector: EpollSelector
2025-03-22 13:26:37,790 - INFO - Starting application
2025-03-22 13:26:37,790 - INFO - Clearing screen
2025-03-22 13:26:39,031 - INFO - Selected: Save files
2025-03-22 13:26:39,032 - INFO - Clearing screen
2025-03-22 13:26:42,152 - INFO - Initiating save operation for all
2025-03-22 13:26:42,783 - INFO - Using cached data for Price
2025-03-22 13:26:46,436 - INFO - Using cached data for Transfer
2025-03-22 13:26:46,440 - INFO - Using cached data for Price
2025-03-22 13:26:46,440 - INFO - Using cached data for Price
2025-03-22 13:26:47,612 - INFO - Using cached data for Transfer
2025-03-22 13:26:47,614 - INFO - Using cached data for Price
2025-03-22 13:26:47,614 - INFO - Using cached data for Price
2025-03-22 13:26:47,616 - INFO - Using cached data for Price
2025-03-22 13:26:47,616 - INFO - Using cached data for Price
2025-03-22 13:26:50,264 - INFO - Using cached data for Price
2025-03-22 13:26:50,264 - INFO - Using cached data for Price
2025-03-22 13:26:50,265 - INFO - Using cached data for ScowTransfer
2025-03-22 13:26:50,266 - INFO - Using cached data for Price
2025-03-22 13:26:50,266 - INFO - Using cached data for Price
2025-03-22 13:26:50,267 - INFO - Using cached data for CCCSReport
2025-03-22 13:26:50,267 - INFO - Using cached data for Price
2025-03-22 13:26:50,267 - INFO - Using cached data for Price
2025-03-22 15:33:16,210 - DEBUG - Using selector: EpollSelector
2025-03-22 15:33:16,211 - INFO - Starting application
2025-03-22 15:33:16,211 - INFO - Clearing screen
2025-03-22 15:33:17,804 - INFO - Selected: Save files
2025-03-22 15:33:17,804 - INFO - Clearing screen
2025-03-22 15:33:20,970 - INFO - Initiating save operation for all
2025-03-22 15:33:21,840 - INFO - Using cached data for Price
2025-03-22 15:33:28,238 - INFO - Using cached data for Transfer
2025-03-22 15:33:28,243 - INFO - Using cached data for Price
2025-03-22 15:33:28,243 - INFO - Using cached data for Price
2025-03-22 15:33:29,851 - INFO - Using cached data for Transfer
2025-03-22 15:33:29,854 - INFO - Using cached data for Price
2025-03-22 15:33:29,854 - INFO - Using cached data for Price
2025-03-22 15:33:29,857 - INFO - Using cached data for Price
2025-03-22 15:33:29,857 - INFO - Using cached data for Price
2025-03-22 15:33:33,017 - INFO - Using cached data for Price
2025-03-22 15:33:33,017 - INFO - Using cached data for Price
2025-03-22 15:33:33,018 - INFO - Using cached data for ScowTransfer
2025-03-22 15:33:33,018 - INFO - Using cached data for Price
2025-03-22 15:33:33,018 - INFO - Using cached data for Price
2025-03-22 15:33:33,019 - INFO - Using cached data for CCCSReport
2025-03-22 15:34:48,765 - DEBUG - Using selector: EpollSelector
2025-03-22 15:34:48,766 - INFO - Starting application
2025-03-22 15:34:48,766 - INFO - Clearing screen
2025-03-22 15:34:50,594 - INFO - Selected: Save files
2025-03-22 15:34:50,594 - INFO - Clearing screen
2025-03-22 15:34:53,699 - INFO - Initiating save operation for all
2025-03-22 15:34:54,512 - INFO - Using cached data for Price
2025-03-22 15:34:57,501 - INFO - Using cached data for Transfer
2025-03-22 15:34:57,505 - INFO - Using cached data for Price
2025-03-22 15:34:57,506 - INFO - Using cached data for Price
2025-03-22 15:34:58,683 - INFO - Using cached data for Transfer
2025-03-22 15:34:58,686 - INFO - Using cached data for Price
2025-03-22 15:34:58,686 - INFO - Using cached data for Price
2025-03-22 15:34:58,688 - INFO - Using cached data for Price
2025-03-22 15:34:58,688 - INFO - Using cached data for Price
2025-03-22 15:35:01,273 - INFO - Using cached data for Price
2025-03-22 15:35:01,273 - INFO - Using cached data for Price
2025-03-22 15:35:01,274 - INFO - Using cached data for ScowTransfer
2025-03-22 15:35:01,274 - INFO - Using cached data for Price
2025-03-22 15:35:01,274 - INFO - Using cached data for Price
2025-03-22 15:35:01,275 - INFO - Using cached data for CCCSReport
2025-03-22 15:39:09,508 - DEBUG - Using selector: EpollSelector
2025-03-22 15:39:09,508 - INFO - Starting application
2025-03-22 15:39:09,508 - INFO - Clearing screen
2025-03-22 15:39:11,147 - INFO - Selected: Save files
2025-03-22 15:39:11,147 - INFO - Clearing screen
2025-03-22 15:39:14,236 - INFO - Initiating save operation for all
2025-03-22 15:39:15,429 - INFO - Using cached data for Price
2025-03-22 15:39:18,744 - INFO - Using cached data for Transfer
2025-03-22 15:39:18,748 - INFO - Using cached data for Price
2025-03-22 15:39:18,748 - INFO - Using cached data for Price
2025-03-22 15:39:20,012 - INFO - Using cached data for Transfer
2025-03-22 15:39:20,014 - INFO - Using cached data for Price
2025-03-22 15:39:20,014 - INFO - Using cached data for Price
2025-03-22 15:39:20,016 - INFO - Using cached data for Price
2025-03-22 15:39:20,016 - INFO - Using cached data for Price
2025-03-22 15:39:22,396 - INFO - Using cached data for Price
2025-03-22 15:39:22,396 - INFO - Using cached data for Price
2025-03-22 15:39:22,397 - INFO - Using cached data for ScowTransfer
2025-03-22 15:39:22,398 - INFO - Using cached data for Price
2025-03-22 15:39:22,398 - INFO - Using cached data for Price
2025-03-22 15:39:22,399 - INFO - Using cached data for CCCSReport
2025-03-22 15:39:22,399 - INFO - Using cached data for Price
2025-03-22 15:39:22,399 - INFO - Using cached data for Price
2025-03-22 18:09:58,075 - DEBUG - Using selector: EpollSelector
2025-03-22 18:09:58,075 - INFO - Starting application
2025-03-22 18:09:58,075 - INFO - Clearing screen
2025-03-22 18:09:59,836 - INFO - Selected: Save files
2025-03-22 18:09:59,837 - INFO - Clearing screen
2025-03-22 18:10:03,226 - INFO - Initiating save operation for all
2025-03-22 18:10:04,485 - INFO - Using cached data for Price
2025-03-22 18:10:10,726 - INFO - Using cached data for Transfer
2025-03-22 18:10:10,729 - INFO - Using cached data for Price
2025-03-22 18:10:10,729 - INFO - Using cached data for Price
2025-03-22 18:10:11,804 - INFO - Using cached data for Transfer
2025-03-22 18:10:11,807 - INFO - Using cached data for Price
2025-03-22 18:10:11,807 - INFO - Using cached data for Price
2025-03-22 18:10:11,809 - INFO - Using cached data for Price
2025-03-22 18:10:11,809 - INFO - Using cached data for Price
2025-03-22 18:10:14,561 - INFO - Using cached data for Price
2025-03-22 18:10:14,561 - INFO - Using cached data for Price
2025-03-22 18:10:14,562 - INFO - Using cached data for ScowTransfer
2025-03-22 18:10:14,562 - INFO - Using cached data for Price
2025-03-22 18:10:14,562 - INFO - Using cached data for Price
2025-03-22 18:10:14,563 - INFO - Using cached data for CCCSReport
2025-03-22 18:10:14,563 - INFO - Using cached data for Price
2025-03-22 18:10:14,563 - INFO - Using cached data for Price
2025-03-22 18:13:19,650 - DEBUG - Using selector: EpollSelector
2025-03-22 18:13:19,650 - INFO - Starting application
2025-03-22 18:13:19,650 - INFO - Clearing screen
2025-03-22 18:13:21,875 - INFO - Selected: Save files
2025-03-22 18:13:21,875 - INFO - Clearing screen
2025-03-22 18:13:25,475 - INFO - Initiating save operation for all
2025-03-22 18:13:26,941 - INFO - Using cached data for Price
2025-03-22 18:13:29,958 - INFO - Using cached data for Transfer
2025-03-22 18:13:29,962 - INFO - Using cached data for Price
2025-03-22 18:13:29,962 - INFO - Using cached data for Price
2025-03-22 18:13:31,124 - INFO - Using cached data for Transfer
2025-03-22 18:13:31,127 - INFO - Using cached data for Price
2025-03-22 18:13:31,127 - INFO - Using cached data for Price
2025-03-22 18:13:31,130 - INFO - Using cached data for Price
2025-03-22 18:13:31,130 - INFO - Using cached data for Price
2025-03-22 18:13:33,380 - INFO - Using cached data for Price
2025-03-22 18:13:33,380 - INFO - Using cached data for Price
2025-03-22 18:13:33,381 - INFO - Using cached data for ScowTransfer
2025-03-22 18:13:33,382 - INFO - Using cached data for Price
2025-03-22 18:13:33,382 - INFO - Using cached data for Price
2025-03-22 18:13:33,382 - INFO - Using cached data for CCCSReport
2025-03-22 18:13:33,383 - INFO - Using cached data for Price
2025-03-22 18:13:33,383 - INFO - Using cached data for Price
2025-03-22 18:21:23,219 - DEBUG - Using selector: EpollSelector
2025-03-22 18:21:23,219 - INFO - Starting application
2025-03-22 18:21:23,219 - INFO - Clearing screen
2025-03-22 18:21:25,406 - INFO - Selected: Save files
2025-03-22 18:21:25,407 - INFO - Clearing screen
2025-03-22 18:21:28,571 - INFO - Initiating save operation for all
2025-03-22 18:21:30,017 - INFO - Using cached data for Price
2025-03-22 18:21:35,563 - INFO - Using cached data for Transfer
2025-03-22 18:21:35,568 - INFO - Using cached data for Price
2025-03-22 18:21:35,568 - INFO - Using cached data for Price
2025-03-22 18:21:36,636 - INFO - Using cached data for Transfer
2025-03-22 18:21:36,639 - INFO - Using cached data for Price
2025-03-22 18:21:36,639 - INFO - Using cached data for Price
2025-03-22 18:21:36,642 - INFO - Using cached data for Price
2025-03-22 18:21:36,642 - INFO - Using cached data for Price
2025-03-22 18:21:39,276 - INFO - Using cached data for Price
2025-03-22 18:21:39,276 - INFO - Using cached data for Price
2025-03-22 18:21:39,278 - INFO - Using cached data for ScowTransfer
2025-03-22 18:21:39,278 - INFO - Using cached data for Price
2025-03-22 18:21:39,278 - INFO - Using cached data for Price
2025-03-22 18:21:39,279 - INFO - Using cached data for CCCSReport
2025-03-22 18:21:39,279 - INFO - Using cached data for Price
2025-03-22 18:21:39,279 - INFO - Using cached data for Price
2025-03-22 18:22:54,069 - DEBUG - Using selector: EpollSelector
2025-03-22 18:22:54,069 - INFO - Starting application
2025-03-22 18:22:54,069 - INFO - Clearing screen
2025-03-22 18:22:55,481 - INFO - Selected: Save files
2025-03-22 18:22:55,482 - INFO - Clearing screen
2025-03-22 18:22:58,378 - INFO - Initiating save operation for all
2025-03-22 18:22:59,157 - INFO - Using cached data for Price
2025-03-22 18:23:02,491 - INFO - Using cached data for Transfer
2025-03-22 18:23:02,495 - INFO - Using cached data for Price
2025-03-22 18:23:02,495 - INFO - Using cached data for Price
2025-03-22 18:23:03,568 - INFO - Using cached data for Transfer
2025-03-22 18:23:03,570 - INFO - Using cached data for Price
2025-03-22 18:23:03,571 - INFO - Using cached data for Price
2025-03-22 18:23:03,573 - INFO - Using cached data for Price
2025-03-22 18:23:03,573 - INFO - Using cached data for Price
2025-03-22 18:23:05,879 - INFO - Using cached data for Price
2025-03-22 18:23:05,879 - INFO - Using cached data for Price
2025-03-22 18:23:05,880 - INFO - Using cached data for ScowTransfer
2025-03-22 18:23:05,880 - INFO - Using cached data for Price
2025-03-22 18:23:05,880 - INFO - Using cached data for Price
2025-03-22 18:23:05,881 - INFO - Using cached data for CCCSReport
2025-03-22 18:23:05,882 - INFO - Using cached data for Price
2025-03-22 18:23:05,882 - INFO - Using cached data for Price
2025-03-22 18:24:07,267 - DEBUG - Using selector: EpollSelector
2025-03-22 18:24:07,267 - INFO - Starting application
2025-03-22 18:24:07,267 - INFO - Clearing screen
2025-03-22 18:24:09,103 - INFO - Selected: Save files
2025-03-22 18:24:09,104 - INFO - Clearing screen
2025-03-22 18:24:12,105 - INFO - Initiating save operation for all
2025-03-22 18:24:12,885 - INFO - Using cached data for Price
2025-03-22 18:24:16,028 - INFO - Using cached data for Transfer
2025-03-22 18:24:16,032 - INFO - Using cached data for Price
2025-03-22 18:24:16,032 - INFO - Using cached data for Price
2025-03-22 18:24:17,109 - INFO - Using cached data for Transfer
2025-03-22 18:24:17,112 - INFO - Using cached data for Price
2025-03-22 18:24:17,112 - INFO - Using cached data for Price
2025-03-22 18:24:17,114 - INFO - Using cached data for Price
2025-03-22 18:24:17,114 - INFO - Using cached data for Price
2025-03-22 18:24:19,274 - INFO - Using cached data for Price
2025-03-22 18:24:19,274 - INFO - Using cached data for Price
2025-03-22 18:24:19,276 - INFO - Using cached data for ScowTransfer
2025-03-22 18:24:19,276 - INFO - Using cached data for Price
2025-03-22 18:24:19,276 - INFO - Using cached data for Price
2025-03-22 18:24:19,277 - INFO - Using cached data for CCCSReport
2025-03-22 18:24:19,277 - INFO - Using cached data for Price
2025-03-22 18:24:19,277 - INFO - Using cached data for Price
2025-03-22 18:24:19,278 - INFO - Using cached data for CCCSReport
2025-03-22 18:24:19,278 - INFO - Using cached data for Price
2025-03-22 18:24:19,278 - INFO - Using cached data for Price
2025-03-22 18:24:19,280 - INFO - Using cached data for CCCSReport
2025-03-22 18:24:19,280 - INFO - Using cached data for Price
2025-03-22 18:24:19,280 - INFO - Using cached data for Price
2025-03-22 18:24:20,091 - INFO - Using cached data for Price
2025-03-22 18:24:20,091 - INFO - Using cached data for Price
2025-03-22 18:27:04,063 - DEBUG - Using selector: EpollSelector
2025-03-22 18:27:04,064 - INFO - Starting application
2025-03-22 18:27:04,064 - INFO - Clearing screen
2025-03-22 18:27:05,641 - INFO - Selected: Save files
2025-03-22 18:27:05,642 - INFO - Clearing screen
2025-03-22 18:27:08,792 - INFO - Initiating save operation for all
2025-03-22 18:27:09,733 - INFO - Using cached data for Price
2025-03-22 18:27:12,939 - INFO - Using cached data for Transfer
2025-03-22 18:27:12,943 - INFO - Using cached data for Price
2025-03-22 18:27:12,943 - INFO - Using cached data for Price
2025-03-22 18:27:14,062 - INFO - Using cached data for Transfer
2025-03-22 18:27:14,064 - INFO - Using cached data for Price
2025-03-22 18:27:14,065 - INFO - Using cached data for Price
2025-03-22 18:27:14,067 - INFO - Using cached data for Price
2025-03-22 18:27:14,067 - INFO - Using cached data for Price
2025-03-22 18:27:16,296 - INFO - Using cached data for Price
2025-03-22 18:27:16,296 - INFO - Using cached data for Price
2025-03-22 18:27:16,297 - INFO - Using cached data for ScowTransfer
2025-03-22 18:27:16,298 - INFO - Using cached data for Price
2025-03-22 18:27:16,298 - INFO - Using cached data for Price
2025-03-22 18:27:16,298 - INFO - Using cached data for CCCSReport
2025-03-22 18:27:16,299 - INFO - Using cached data for Price
2025-03-22 18:27:16,299 - INFO - Using cached data for Price
2025-03-22 18:27:16,300 - INFO - Using cached data for CCCSReport
2025-03-22 18:27:16,300 - INFO - Using cached data for Price
2025-03-22 18:27:16,300 - INFO - Using cached data for Price
2025-03-22 18:27:16,301 - INFO - Using cached data for CCCSReport
2025-03-22 18:27:16,301 - INFO - Using cached data for Price
2025-03-22 18:27:16,301 - INFO - Using cached data for Price
2025-03-22 18:27:17,028 - INFO - Using cached data for Price
2025-03-22 18:27:17,028 - INFO - Using cached data for Price
2025-03-22 18:27:17,855 - INFO - Using cached data for Transfer
2025-03-22 18:27:17,857 - INFO - Using cached data for Price
2025-03-22 18:27:17,857 - INFO - Using cached data for Price
2025-03-22 18:27:17,858 - INFO - Using cached data for CCCSReport
2025-03-22 18:28:31,279 - DEBUG - Using selector: EpollSelector
2025-03-22 18:28:31,279 - INFO - Starting application
2025-03-22 18:28:31,279 - INFO - Clearing screen
2025-03-22 18:28:32,688 - INFO - Selected: Save files
2025-03-22 18:28:32,689 - INFO - Clearing screen
2025-03-22 18:28:35,614 - INFO - Initiating save operation for all
2025-03-22 18:28:36,364 - INFO - Using cached data for Price
2025-03-22 18:28:39,409 - INFO - Using cached data for Transfer
2025-03-22 18:28:39,412 - INFO - Using cached data for Price
2025-03-22 18:28:39,413 - INFO - Using cached data for Price
2025-03-22 18:28:40,376 - INFO - Using cached data for Transfer
2025-03-22 18:28:40,378 - INFO - Using cached data for Price
2025-03-22 18:28:40,378 - INFO - Using cached data for Price
2025-03-22 18:28:40,381 - INFO - Using cached data for Price
2025-03-22 18:28:40,381 - INFO - Using cached data for Price
2025-03-22 18:28:42,643 - INFO - Using cached data for Price
2025-03-22 18:28:42,643 - INFO - Using cached data for Price
2025-03-22 18:28:42,644 - INFO - Using cached data for ScowTransfer
2025-03-22 18:28:42,644 - INFO - Using cached data for Price
2025-03-22 18:28:42,644 - INFO - Using cached data for Price
2025-03-22 18:28:42,645 - INFO - Using cached data for CCCSReport
2025-03-22 18:28:42,645 - INFO - Using cached data for Price
2025-03-22 18:28:42,646 - INFO - Using cached data for Price
2025-03-22 18:28:42,647 - INFO - Using cached data for CCCSReport
2025-03-22 18:28:42,647 - INFO - Using cached data for Price
2025-03-22 18:28:42,647 - INFO - Using cached data for Price
2025-03-22 18:28:42,648 - INFO - Using cached data for CCCSReport
2025-03-22 18:28:42,648 - INFO - Using cached data for Price
2025-03-22 18:28:42,648 - INFO - Using cached data for Price
2025-03-22 18:28:43,450 - INFO - Using cached data for Price
2025-03-22 18:28:43,450 - INFO - Using cached data for Price
2025-03-22 18:28:44,287 - INFO - Using cached data for Transfer
2025-03-22 18:28:44,290 - INFO - Using cached data for Price
2025-03-22 18:28:44,290 - INFO - Using cached data for Price
2025-03-22 18:28:44,291 - INFO - Using cached data for CCCSReport
2025-03-22 18:34:12,384 - DEBUG - Using selector: EpollSelector
2025-03-22 18:34:12,385 - INFO - Starting application
2025-03-22 18:34:12,385 - INFO - Clearing screen
2025-03-22 18:34:14,729 - INFO - Selected: Save files
2025-03-22 18:34:14,729 - INFO - Clearing screen
2025-03-22 18:34:18,253 - INFO - Initiating save operation for all
2025-03-22 18:34:19,111 - INFO - Using cached data for Price
2025-03-22 18:34:24,080 - INFO - Using cached data for Transfer
2025-03-22 18:34:24,083 - INFO - Using cached data for Price
2025-03-22 18:34:24,083 - INFO - Using cached data for Price
2025-03-22 18:34:25,061 - INFO - Using cached data for Transfer
2025-03-22 18:34:25,063 - INFO - Using cached data for Price
2025-03-22 18:34:25,063 - INFO - Using cached data for Price
2025-03-22 18:34:25,066 - INFO - Using cached data for Price
2025-03-22 18:34:25,066 - INFO - Using cached data for Price
2025-03-22 18:34:27,724 - INFO - Using cached data for Price
2025-03-22 18:34:27,724 - INFO - Using cached data for Price
2025-03-22 18:34:27,726 - INFO - Using cached data for ScowTransfer
2025-03-22 18:34:27,726 - INFO - Using cached data for Price
2025-03-22 18:34:27,726 - INFO - Using cached data for Price
2025-03-22 18:34:27,727 - INFO - Using cached data for CCCSReport
2025-03-22 18:34:27,727 - INFO - Using cached data for Price
2025-03-22 18:34:27,727 - INFO - Using cached data for Price
2025-03-22 18:34:27,728 - INFO - Using cached data for CCCSReport
2025-03-22 18:34:27,728 - INFO - Using cached data for Price
2025-03-22 18:34:27,728 - INFO - Using cached data for Price
2025-03-22 18:34:27,730 - INFO - Using cached data for CCCSReport
2025-03-22 18:34:27,730 - INFO - Using cached data for Price
2025-03-22 18:34:27,730 - INFO - Using cached data for Price
2025-03-22 18:34:28,429 - INFO - Using cached data for Price
2025-03-22 18:34:28,429 - INFO - Using cached data for Price
2025-03-22 18:34:29,265 - INFO - Using cached data for Transfer
2025-03-22 18:34:29,267 - INFO - Using cached data for Price
2025-03-22 18:34:29,267 - INFO - Using cached data for Price
2025-03-22 18:34:29,268 - INFO - Using cached data for CCCSReport
2025-03-22 19:14:59,809 - DEBUG - Using selector: EpollSelector
2025-03-22 19:14:59,810 - INFO - Starting application
2025-03-22 19:14:59,810 - INFO - Clearing screen
2025-03-22 19:15:01,432 - INFO - Selected: Save files
2025-03-22 19:15:01,432 - INFO - Clearing screen
2025-03-22 19:15:04,538 - INFO - Initiating save operation for all
2025-03-22 19:15:05,997 - INFO - Using cached data for Price
2025-03-22 19:15:11,041 - INFO - Using cached data for Transfer
2025-03-22 19:15:11,044 - INFO - Using cached data for Price
2025-03-22 19:15:11,044 - INFO - Using cached data for Price
2025-03-22 19:15:12,032 - INFO - Using cached data for Transfer
2025-03-22 19:15:12,035 - INFO - Using cached data for Price
2025-03-22 19:15:12,035 - INFO - Using cached data for Price
2025-03-22 19:15:12,037 - INFO - Using cached data for Price
2025-03-22 19:15:12,037 - INFO - Using cached data for Price
2025-03-22 19:15:14,634 - INFO - Using cached data for Price
2025-03-22 19:15:14,634 - INFO - Using cached data for Price
2025-03-22 19:15:14,635 - INFO - Using cached data for ScowTransfer
2025-03-22 19:15:14,635 - INFO - Using cached data for Price
2025-03-22 19:15:14,635 - INFO - Using cached data for Price
2025-03-22 19:15:14,636 - INFO - Using cached data for CCCSReport
2025-03-22 19:15:14,636 - INFO - Using cached data for Price
2025-03-22 19:15:14,636 - INFO - Using cached data for Price
2025-03-22 19:15:14,637 - INFO - Using cached data for CCCSReport
2025-03-22 19:15:14,638 - INFO - Using cached data for Price
2025-03-22 19:15:14,638 - INFO - Using cached data for Price
2025-03-22 19:15:14,639 - INFO - Using cached data for CCCSReport
2025-03-22 19:15:14,639 - INFO - Using cached data for Price
2025-03-22 19:15:14,639 - INFO - Using cached data for Price
2025-03-22 19:15:15,564 - INFO - Using cached data for Price
2025-03-22 19:15:15,564 - INFO - Using cached data for Price
2025-03-22 19:15:16,487 - INFO - Using cached data for Transfer
2025-03-22 19:15:16,493 - INFO - Using cached data for Price
2025-03-22 19:15:16,494 - INFO - Using cached data for Price
2025-03-22 19:15:16,496 - INFO - Using cached data for CCCSReport
2025-03-22 19:15:47,441 - DEBUG - Using selector: EpollSelector
2025-03-22 19:15:47,441 - INFO - Starting application
2025-03-22 19:15:47,441 - INFO - Clearing screen
2025-03-22 19:15:49,104 - INFO - Selected: Save files
2025-03-22 19:15:49,105 - INFO - Clearing screen
2025-03-22 19:15:51,939 - INFO - Initiating save operation for all
2025-03-22 19:15:53,222 - INFO - Using cached data for Price
2025-03-22 19:15:56,079 - INFO - Using cached data for Transfer
2025-03-22 19:15:56,085 - INFO - Using cached data for Price
2025-03-22 19:15:56,085 - INFO - Using cached data for Price
2025-03-22 19:15:57,076 - INFO - Using cached data for Transfer
2025-03-22 19:15:57,078 - INFO - Using cached data for Price
2025-03-22 19:15:57,079 - INFO - Using cached data for Price
2025-03-22 19:15:57,081 - INFO - Using cached data for Price
2025-03-22 19:15:57,081 - INFO - Using cached data for Price
2025-03-22 19:15:58,951 - INFO - Using cached data for Price
2025-03-22 19:15:58,951 - INFO - Using cached data for Price
2025-03-22 19:15:58,953 - INFO - Using cached data for ScowTransfer
2025-03-22 19:15:58,953 - INFO - Using cached data for Price
2025-03-22 19:15:58,954 - INFO - Using cached data for Price
2025-03-22 19:15:58,954 - INFO - Using cached data for CCCSReport
2025-03-22 19:15:58,955 - INFO - Using cached data for Price
2025-03-22 19:15:58,955 - INFO - Using cached data for Price
2025-03-22 19:15:58,956 - INFO - Using cached data for CCCSReport
2025-03-22 19:15:58,956 - INFO - Using cached data for Price
2025-03-22 19:15:58,956 - INFO - Using cached data for Price
2025-03-22 19:15:58,958 - INFO - Using cached data for CCCSReport
2025-03-22 19:15:58,958 - INFO - Using cached data for Price
2025-03-22 19:15:58,958 - INFO - Using cached data for Price
2025-03-22 19:15:59,701 - INFO - Using cached data for Price
2025-03-22 19:15:59,701 - INFO - Using cached data for Price
2025-03-22 19:16:00,516 - INFO - Using cached data for Transfer
2025-03-22 19:16:00,518 - INFO - Using cached data for Price
2025-03-22 19:16:00,518 - INFO - Using cached data for Price
2025-03-22 19:16:00,519 - INFO - Using cached data for CCCSReport
2025-03-22 19:16:01,703 - INFO - Using cached data for Client
2025-03-22 19:16:01,704 - INFO - Using cached data for Client
2025-03-22 19:16:01,704 - INFO - Using cached data for Client
2025-03-22 19:16:01,704 - INFO - Using cached data for Client
2025-03-22 19:16:01,704 - INFO - Using cached data for Client
2025-03-22 19:16:01,704 - INFO - Using cached data for Client
2025-03-22 19:16:01,704 - INFO - Using cached data for Client
2025-03-22 19:16:01,704 - INFO - Using cached data for Client
2025-03-22 19:16:01,704 - INFO - Using cached data for Client
2025-03-22 19:16:01,704 - INFO - Using cached data for Client
2025-03-22 19:16:01,704 - INFO - Using cached data for Client
2025-03-22 19:16:01,704 - INFO - Using cached data for Client
2025-03-22 19:16:01,704 - INFO - Using cached data for Client
2025-03-22 19:16:01,704 - INFO - Using cached data for Client
2025-03-22 19:16:01,704 - INFO - Using cached data for Client
2025-03-22 19:16:01,705 - INFO - Using cached data for Client
2025-03-22 19:16:01,705 - INFO - Using cached data for Client
2025-03-22 19:16:01,705 - INFO - Using cached data for Client
2025-03-22 19:16:01,705 - INFO - Using cached data for Client
2025-03-22 19:16:01,705 - INFO - Using cached data for Client
2025-03-22 19:16:01,705 - INFO - Using cached data for Client
2025-03-22 19:16:01,705 - INFO - Using cached data for Client
2025-03-22 19:16:01,705 - INFO - Using cached data for Client
2025-03-22 19:16:01,705 - INFO - Using cached data for Client
2025-03-22 19:16:01,705 - INFO - Using cached data for Client
2025-03-22 19:16:01,705 - INFO - Using cached data for Client
2025-03-22 19:16:01,705 - INFO - Using cached data for Client
2025-03-22 19:16:01,705 - INFO - Using cached data for Client
2025-03-22 19:16:01,706 - INFO - Using cached data for Client
2025-03-22 19:16:01,706 - INFO - Using cached data for Client
2025-03-22 19:16:01,706 - INFO - Using cached data for Client
2025-03-22 19:16:01,706 - INFO - Using cached data for Client
2025-03-22 19:16:01,706 - INFO - Using cached data for Client
2025-03-22 19:16:01,706 - INFO - Using cached data for Client
2025-03-22 19:16:01,706 - INFO - Using cached data for Client
2025-03-22 19:16:01,706 - INFO - Using cached data for Client
2025-03-22 19:16:01,706 - INFO - Using cached data for Client
2025-03-22 19:16:01,706 - INFO - Using cached data for Client
2025-03-22 19:16:01,706 - INFO - Using cached data for Client
2025-03-22 19:16:01,706 - INFO - Using cached data for Client
2025-03-22 19:16:01,706 - INFO - Using cached data for Client
2025-03-22 19:16:01,706 - INFO - Using cached data for Client
2025-03-22 19:16:01,707 - INFO - Using cached data for Client
2025-03-22 19:16:01,707 - INFO - Using cached data for Client
2025-03-22 19:16:01,707 - INFO - Using cached data for Client
2025-03-22 19:16:01,707 - INFO - Using cached data for Client
2025-03-22 19:16:01,707 - INFO - Using cached data for Client
2025-03-22 19:16:01,707 - INFO - Using cached data for Client
2025-03-22 19:16:01,707 - INFO - Using cached data for Client
2025-03-22 19:16:01,707 - INFO - Using cached data for Client
2025-03-22 19:16:01,707 - INFO - Using cached data for Client
2025-03-22 19:16:01,707 - INFO - Using cached data for Client
2025-03-22 19:16:01,707 - INFO - Using cached data for Client
2025-03-22 19:16:01,707 - INFO - Using cached data for Client
2025-03-22 19:16:01,707 - INFO - Using cached data for Client
2025-03-22 19:16:01,707 - INFO - Using cached data for Client
2025-03-22 19:16:01,708 - INFO - Using cached data for Client
2025-03-22 19:16:01,708 - INFO - Using cached data for Client
2025-03-22 19:16:01,708 - INFO - Using cached data for Client
2025-03-22 19:16:01,708 - INFO - Using cached data for Client
2025-03-22 19:16:01,708 - INFO - Using cached data for Client
2025-03-22 19:16:01,708 - INFO - Using cached data for Client
2025-03-22 19:16:01,708 - INFO - Using cached data for Client
2025-03-22 19:16:01,708 - INFO - Using cached data for Client
2025-03-22 19:16:01,708 - INFO - Using cached data for Client
2025-03-22 19:16:01,708 - INFO - Using cached data for Client
2025-03-22 19:16:01,708 - INFO - Using cached data for Client
2025-03-22 19:16:01,708 - INFO - Using cached data for Client
2025-03-22 19:16:01,708 - INFO - Using cached data for Client
2025-03-22 19:16:01,708 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,709 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,710 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,711 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,712 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,713 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,714 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,715 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,716 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,717 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,718 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,719 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,720 - INFO - Using cached data for Client
2025-03-22 19:16:01,721 - INFO - Using cached data for Client
2025-03-22 19:16:01,721 - INFO - Using cached data for Client
2025-03-22 19:16:01,721 - INFO - Using cached data for Client
2025-03-22 19:16:01,721 - INFO - Using cached data for Client
2025-03-22 19:16:01,721 - INFO - Using cached data for Client
2025-03-22 19:16:01,721 - INFO - Using cached data for Client
2025-03-22 19:16:01,721 - INFO - Using cached data for Client
2025-03-22 19:16:01,721 - INFO - Using cached data for Client
2025-03-22 19:16:01,721 - INFO - Using cached data for Client
2025-03-22 19:16:01,721 - INFO - Using cached data for Client
2025-03-22 19:16:01,721 - INFO - Using cached data for Client
2025-03-22 19:16:01,721 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,723 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,724 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,725 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,726 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,727 - INFO - Using cached data for Client
2025-03-22 19:16:01,728 - INFO - Using cached data for Client
2025-03-22 19:16:01,728 - INFO - Using cached data for Client
2025-03-22 19:16:01,728 - INFO - Using cached data for Client
2025-03-22 19:16:01,728 - INFO - Using cached data for Client
2025-03-22 19:16:01,728 - INFO - Using cached data for Client
2025-03-22 19:16:01,728 - INFO - Using cached data for Client
2025-03-22 19:16:01,728 - INFO - Using cached data for Client
2025-03-22 19:16:01,728 - INFO - Using cached data for Client
2025-03-22 19:16:01,728 - INFO - Using cached data for Client
2025-03-22 19:16:01,728 - INFO - Using cached data for Client
2025-03-22 19:16:01,728 - INFO - Using cached data for Client
2025-03-22 19:16:01,728 - INFO - Using cached data for Client
2025-03-22 19:16:01,728 - INFO - Using cached data for Client
2025-03-22 19:16:01,728 - INFO - Using cached data for Client
2025-03-22 19:16:01,729 - INFO - Using cached data for Client
2025-03-22 19:16:01,729 - INFO - Using cached data for Client
2025-03-22 19:16:01,729 - INFO - Using cached data for Client
2025-03-22 19:16:01,729 - INFO - Using cached data for Client
2025-03-22 19:16:01,729 - INFO - Using cached data for Client
2025-03-22 19:16:01,729 - INFO - Using cached data for Client
2025-03-22 19:16:01,729 - INFO - Using cached data for Client
2025-03-22 19:16:01,729 - INFO - Using cached data for Client
2025-03-22 19:16:01,729 - INFO - Using cached data for Client
2025-03-22 19:16:01,729 - INFO - Using cached data for Client
2025-03-22 19:16:01,729 - INFO - Using cached data for Client
2025-03-22 19:16:01,729 - INFO - Using cached data for Client
2025-03-22 19:16:01,729 - INFO - Using cached data for Client
2025-03-22 19:16:01,730 - INFO - Using cached data for Client
2025-03-22 19:16:01,730 - INFO - Using cached data for Client
2025-03-22 19:16:01,730 - INFO - Using cached data for Client
2025-03-22 19:16:01,730 - INFO - Using cached data for Client
2025-03-22 19:16:01,730 - INFO - Using cached data for Client
2025-03-22 19:16:01,730 - INFO - Using cached data for Client
2025-03-22 19:16:01,730 - INFO - Using cached data for Client
2025-03-22 19:16:01,730 - INFO - Using cached data for Client
2025-03-22 19:16:01,730 - INFO - Using cached data for Client
2025-03-22 19:16:01,730 - INFO - Using cached data for Client
2025-03-22 19:16:01,730 - INFO - Using cached data for Client
2025-03-22 19:16:01,730 - INFO - Using cached data for Client
2025-03-22 19:16:01,730 - INFO - Using cached data for Client
2025-03-22 19:16:01,731 - INFO - Using cached data for Client
2025-03-22 19:16:01,731 - INFO - Using cached data for Client
2025-03-22 19:16:01,731 - INFO - Using cached data for Client
2025-03-22 19:16:01,731 - INFO - Using cached data for Client
2025-03-22 19:16:01,731 - INFO - Using cached data for Client
2025-03-22 19:16:01,731 - INFO - Using cached data for Client
2025-03-22 19:16:01,731 - INFO - Using cached data for Client
2025-03-22 19:16:01,731 - INFO - Using cached data for Client
2025-03-22 19:16:01,731 - INFO - Using cached data for Client
2025-03-22 19:16:01,731 - INFO - Using cached data for Client
2025-03-22 19:16:01,731 - INFO - Using cached data for Client
2025-03-22 19:16:01,731 - INFO - Using cached data for Client
2025-03-22 19:16:01,731 - INFO - Using cached data for Client
2025-03-22 19:16:01,732 - INFO - Using cached data for Client
2025-03-22 19:16:01,732 - INFO - Using cached data for Client
2025-03-22 19:16:01,732 - INFO - Using cached data for Client
2025-03-22 19:16:01,732 - INFO - Using cached data for Client
2025-03-22 19:16:01,732 - INFO - Using cached data for Client
2025-03-22 19:16:01,732 - INFO - Using cached data for Client
2025-03-22 19:16:01,732 - INFO - Using cached data for Client
2025-03-22 19:16:01,732 - INFO - Using cached data for Client
2025-03-22 19:16:01,732 - INFO - Using cached data for Client
2025-03-22 19:16:01,732 - INFO - Using cached data for Client
2025-03-22 19:16:01,732 - INFO - Using cached data for Client
2025-03-22 19:16:01,732 - INFO - Using cached data for Client
2025-03-22 19:16:01,733 - INFO - Using cached data for Client
2025-03-22 19:16:01,733 - INFO - Using cached data for Client
2025-03-22 19:16:01,733 - INFO - Using cached data for Client
2025-03-22 19:16:01,733 - INFO - Using cached data for Client
2025-03-22 19:16:01,733 - INFO - Using cached data for Client
2025-03-22 19:16:01,733 - INFO - Using cached data for Client
2025-03-22 19:16:01,733 - INFO - Using cached data for Client
2025-03-22 19:16:01,733 - INFO - Using cached data for Client
2025-03-22 19:16:01,733 - INFO - Using cached data for Client
2025-03-22 19:16:01,733 - INFO - Using cached data for Client
2025-03-22 19:16:01,733 - INFO - Using cached data for Client
2025-03-22 19:16:01,733 - INFO - Using cached data for Client
2025-03-22 19:16:01,733 - INFO - Using cached data for Client
2025-03-22 19:16:01,734 - INFO - Using cached data for Client
2025-03-22 19:16:01,734 - INFO - Using cached data for Client
2025-03-22 19:16:01,734 - INFO - Using cached data for Client
2025-03-22 19:16:01,734 - INFO - Using cached data for Client
2025-03-22 19:16:01,734 - INFO - Using cached data for Client
2025-03-22 19:16:01,734 - INFO - Using cached data for Client
2025-03-22 19:16:01,734 - INFO - Using cached data for Client
2025-03-22 19:16:01,734 - INFO - Using cached data for Client
2025-03-22 19:16:01,734 - INFO - Using cached data for Client
2025-03-22 19:16:01,734 - INFO - Using cached data for Client
2025-03-22 19:16:01,734 - INFO - Using cached data for Client
2025-03-22 19:16:01,734 - INFO - Using cached data for Client
2025-03-22 19:16:01,734 - INFO - Using cached data for Client
2025-03-22 19:16:01,734 - INFO - Using cached data for Client
2025-03-22 19:16:01,735 - INFO - Using cached data for Client
2025-03-22 19:16:01,735 - INFO - Using cached data for Client
2025-03-22 19:16:01,735 - INFO - Using cached data for Client
2025-03-22 19:16:01,735 - INFO - Using cached data for Client
2025-03-22 19:16:01,735 - INFO - Using cached data for Client
2025-03-22 19:16:01,735 - INFO - Using cached data for Client
2025-03-22 19:16:01,735 - INFO - Using cached data for Client
2025-03-22 19:16:01,735 - INFO - Using cached data for Client
2025-03-22 19:16:01,735 - INFO - Using cached data for Client
2025-03-22 19:16:01,735 - INFO - Using cached data for Client
2025-03-22 19:16:01,735 - INFO - Using cached data for Client
2025-03-22 19:16:01,735 - INFO - Using cached data for Client
2025-03-22 19:16:01,735 - INFO - Using cached data for Client
2025-03-22 19:16:01,735 - INFO - Using cached data for Client
2025-03-22 19:16:01,736 - INFO - Using cached data for Client
2025-03-22 19:16:01,736 - INFO - Using cached data for Client
2025-03-22 19:16:01,736 - INFO - Using cached data for Client
2025-03-22 19:16:01,736 - INFO - Using cached data for Client
2025-03-22 19:16:01,736 - INFO - Using cached data for Client
2025-03-22 19:16:01,736 - INFO - Using cached data for Client
2025-03-22 19:16:01,736 - INFO - Using cached data for Client
2025-03-22 19:16:01,736 - INFO - Using cached data for Client
2025-03-22 19:16:01,736 - INFO - Using cached data for Client
2025-03-22 19:16:01,736 - INFO - Using cached data for Client
2025-03-22 19:16:01,736 - INFO - Using cached data for Client
2025-03-22 19:16:01,736 - INFO - Using cached data for Client
2025-03-22 19:16:01,736 - INFO - Using cached data for Client
2025-03-22 19:16:01,736 - INFO - Using cached data for Client
2025-03-22 19:16:01,737 - INFO - Using cached data for Client
2025-03-22 19:16:01,737 - INFO - Using cached data for Client
2025-03-22 19:16:01,737 - INFO - Using cached data for Client
2025-03-22 19:16:01,737 - INFO - Using cached data for Client
2025-03-22 19:24:11,911 - DEBUG - Using selector: EpollSelector
2025-03-22 19:24:11,912 - INFO - Starting application
2025-03-22 19:24:11,912 - INFO - Clearing screen
2025-03-22 19:24:13,874 - INFO - Selected: Save files
2025-03-22 19:24:13,875 - INFO - Clearing screen
2025-03-22 19:24:19,139 - INFO - Initiating save operation for all
2025-03-22 19:24:20,619 - INFO - Using cached data for Price
2025-03-22 19:24:25,493 - INFO - Using cached data for Transfer
2025-03-22 19:24:25,496 - INFO - Using cached data for Price
2025-03-22 19:24:25,496 - INFO - Using cached data for Price
2025-03-22 19:24:26,551 - INFO - Using cached data for Transfer
2025-03-22 19:24:26,554 - INFO - Using cached data for Price
2025-03-22 19:24:26,555 - INFO - Using cached data for Price
2025-03-22 19:24:26,558 - INFO - Using cached data for Price
2025-03-22 19:24:26,559 - INFO - Using cached data for Price
2025-03-22 19:24:29,285 - INFO - Using cached data for Price
2025-03-22 19:24:29,285 - INFO - Using cached data for Price
2025-03-22 19:24:29,287 - INFO - Using cached data for ScowTransfer
2025-03-22 19:24:29,287 - INFO - Using cached data for Price
2025-03-22 19:24:29,287 - INFO - Using cached data for Price
2025-03-22 19:24:29,288 - INFO - Using cached data for CCCSReport
2025-03-22 19:24:29,288 - INFO - Using cached data for Price
2025-03-22 19:24:29,288 - INFO - Using cached data for Price
2025-03-22 19:24:29,289 - INFO - Using cached data for CCCSReport
2025-03-22 19:24:29,289 - INFO - Using cached data for Price
2025-03-22 19:24:29,289 - INFO - Using cached data for Price
2025-03-22 19:24:29,291 - INFO - Using cached data for CCCSReport
2025-03-22 19:24:29,291 - INFO - Using cached data for Price
2025-03-22 19:24:29,291 - INFO - Using cached data for Price
2025-03-22 19:24:29,951 - INFO - Using cached data for Price
2025-03-22 19:24:29,951 - INFO - Using cached data for Price
2025-03-22 19:24:30,801 - INFO - Using cached data for Transfer
2025-03-22 19:24:30,807 - INFO - Using cached data for Price
2025-03-22 19:24:30,807 - INFO - Using cached data for Price
2025-03-22 19:24:30,809 - INFO - Using cached data for CCCSReport
2025-03-22 19:24:32,088 - INFO - Using cached data for Client
2025-03-22 19:24:32,089 - INFO - Using cached data for Client
2025-03-22 19:24:32,090 - INFO - Using cached data for Client
2025-03-22 19:24:32,091 - INFO - Using cached data for Client
2025-03-22 19:24:32,092 - INFO - Using cached data for Client
2025-03-22 19:24:32,093 - INFO - Using cached data for Client
2025-03-22 19:24:32,094 - INFO - Using cached data for Client
2025-03-22 19:24:32,095 - INFO - Using cached data for Client
2025-03-22 19:24:32,096 - INFO - Using cached data for Client
2025-03-22 19:24:32,097 - INFO - Using cached data for Client
2025-03-22 19:24:32,098 - INFO - Using cached data for Client
2025-03-22 19:24:32,099 - INFO - Using cached data for Client
2025-03-22 19:24:32,100 - INFO - Using cached data for CCCSReport
2025-03-22 19:24:32,719 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 19:24:32,720 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 19:24:32,720 - INFO - Using cached data for CCCSReport
2025-03-22 19:24:32,720 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 19:24:32,721 - INFO - Using cached data for Price
2025-03-22 19:24:32,721 - INFO - Using cached data for Price
2025-03-22 20:17:50,101 - DEBUG - Using selector: EpollSelector
2025-03-22 20:17:50,102 - INFO - Starting application
2025-03-22 20:17:50,102 - INFO - Clearing screen
2025-03-22 20:17:52,304 - INFO - Selected: Save files
2025-03-22 20:17:52,304 - INFO - Clearing screen
2025-03-22 20:17:55,498 - INFO - Initiating save operation for all
2025-03-22 20:17:56,397 - INFO - Using cached data for Price
2025-03-22 20:18:01,481 - INFO - Using cached data for Transfer
2025-03-22 20:18:01,484 - INFO - Using cached data for Price
2025-03-22 20:18:01,484 - INFO - Using cached data for Price
2025-03-22 20:18:02,545 - INFO - Using cached data for Transfer
2025-03-22 20:18:02,548 - INFO - Using cached data for Price
2025-03-22 20:18:02,548 - INFO - Using cached data for Price
2025-03-22 20:18:02,550 - INFO - Using cached data for Price
2025-03-22 20:18:02,550 - INFO - Using cached data for Price
2025-03-22 20:18:05,236 - INFO - Using cached data for Price
2025-03-22 20:18:05,236 - INFO - Using cached data for Price
2025-03-22 20:18:05,237 - INFO - Using cached data for ScowTransfer
2025-03-22 20:18:05,237 - INFO - Using cached data for Price
2025-03-22 20:18:05,237 - INFO - Using cached data for Price
2025-03-22 20:18:05,238 - INFO - Using cached data for CCCSReport
2025-03-22 20:18:05,238 - INFO - Using cached data for Price
2025-03-22 20:18:05,238 - INFO - Using cached data for Price
2025-03-22 20:18:05,240 - INFO - Using cached data for CCCSReport
2025-03-22 20:18:05,240 - INFO - Using cached data for Price
2025-03-22 20:18:05,240 - INFO - Using cached data for Price
2025-03-22 20:18:05,241 - INFO - Using cached data for CCCSReport
2025-03-22 20:18:05,241 - INFO - Using cached data for Price
2025-03-22 20:18:05,241 - INFO - Using cached data for Price
2025-03-22 20:18:06,038 - INFO - Using cached data for Price
2025-03-22 20:18:06,038 - INFO - Using cached data for Price
2025-03-22 20:18:06,890 - INFO - Using cached data for Transfer
2025-03-22 20:18:06,897 - INFO - Using cached data for Price
2025-03-22 20:18:06,897 - INFO - Using cached data for Price
2025-03-22 20:18:06,900 - INFO - Using cached data for CCCSReport
2025-03-22 20:18:07,547 - INFO - Using cached data for Client
2025-03-22 20:18:07,547 - INFO - Using cached data for Client
2025-03-22 20:18:07,548 - INFO - Using cached data for Client
2025-03-22 20:18:07,549 - INFO - Using cached data for Client
2025-03-22 20:18:07,549 - INFO - Using cached data for Client
2025-03-22 20:18:07,550 - INFO - Using cached data for Client
2025-03-22 20:18:07,550 - INFO - Using cached data for Client
2025-03-22 20:18:07,551 - INFO - Using cached data for Client
2025-03-22 20:18:07,551 - INFO - Using cached data for Client
2025-03-22 20:18:07,552 - INFO - Using cached data for Client
2025-03-22 20:18:07,552 - INFO - Using cached data for Client
2025-03-22 20:18:07,552 - INFO - Using cached data for Client
2025-03-22 20:18:07,553 - INFO - Using cached data for CCCSReport
2025-03-22 20:18:08,210 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:18:08,211 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:18:08,212 - INFO - Using cached data for CCCSReport
2025-03-22 20:18:08,212 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:18:08,213 - INFO - Using cached data for Price
2025-03-22 20:18:08,213 - INFO - Using cached data for Price
2025-03-22 20:18:12,594 - INFO - Using cached data for CCCSReport
2025-03-22 20:18:12,595 - INFO - Using cached data for Price
2025-03-22 20:18:12,595 - INFO - Using cached data for Price
2025-03-22 20:18:13,975 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:18:13,976 - INFO - Using cached data for Client
2025-03-22 20:18:14,005 - INFO - Using cached data for Transfer
2025-03-22 20:18:14,015 - INFO - Using cached data for Price
2025-03-22 20:18:14,015 - INFO - Using cached data for Price
2025-03-22 20:18:52,013 - DEBUG - Using selector: EpollSelector
2025-03-22 20:18:52,014 - INFO - Starting application
2025-03-22 20:18:52,014 - INFO - Clearing screen
2025-03-22 20:18:53,805 - INFO - Selected: Save files
2025-03-22 20:18:53,805 - INFO - Clearing screen
2025-03-22 20:18:57,750 - INFO - Initiating save operation for all
2025-03-22 20:18:58,575 - INFO - Using cached data for Price
2025-03-22 20:19:01,869 - INFO - Using cached data for Transfer
2025-03-22 20:19:01,873 - INFO - Using cached data for Price
2025-03-22 20:19:01,873 - INFO - Using cached data for Price
2025-03-22 20:19:03,023 - INFO - Using cached data for Transfer
2025-03-22 20:19:03,026 - INFO - Using cached data for Price
2025-03-22 20:19:03,026 - INFO - Using cached data for Price
2025-03-22 20:19:03,029 - INFO - Using cached data for Price
2025-03-22 20:19:03,029 - INFO - Using cached data for Price
2025-03-22 20:19:05,164 - INFO - Using cached data for Price
2025-03-22 20:19:05,165 - INFO - Using cached data for Price
2025-03-22 20:19:05,166 - INFO - Using cached data for ScowTransfer
2025-03-22 20:19:05,166 - INFO - Using cached data for Price
2025-03-22 20:19:05,166 - INFO - Using cached data for Price
2025-03-22 20:19:05,167 - INFO - Using cached data for CCCSReport
2025-03-22 20:19:05,167 - INFO - Using cached data for Price
2025-03-22 20:19:05,168 - INFO - Using cached data for Price
2025-03-22 20:19:05,169 - INFO - Using cached data for CCCSReport
2025-03-22 20:19:05,169 - INFO - Using cached data for Price
2025-03-22 20:19:05,169 - INFO - Using cached data for Price
2025-03-22 20:19:05,170 - INFO - Using cached data for CCCSReport
2025-03-22 20:19:05,171 - INFO - Using cached data for Price
2025-03-22 20:19:05,171 - INFO - Using cached data for Price
2025-03-22 20:19:05,859 - INFO - Using cached data for Price
2025-03-22 20:19:05,859 - INFO - Using cached data for Price
2025-03-22 20:19:06,592 - INFO - Using cached data for Transfer
2025-03-22 20:19:06,597 - INFO - Using cached data for Price
2025-03-22 20:19:06,597 - INFO - Using cached data for Price
2025-03-22 20:19:06,598 - INFO - Using cached data for CCCSReport
2025-03-22 20:19:07,256 - INFO - Using cached data for Client
2025-03-22 20:19:07,257 - INFO - Using cached data for Client
2025-03-22 20:19:07,257 - INFO - Using cached data for Client
2025-03-22 20:19:07,258 - INFO - Using cached data for Client
2025-03-22 20:19:07,258 - INFO - Using cached data for Client
2025-03-22 20:19:07,258 - INFO - Using cached data for Client
2025-03-22 20:19:07,259 - INFO - Using cached data for Client
2025-03-22 20:19:07,259 - INFO - Using cached data for Client
2025-03-22 20:19:07,260 - INFO - Using cached data for Client
2025-03-22 20:19:07,260 - INFO - Using cached data for Client
2025-03-22 20:19:07,260 - INFO - Using cached data for Client
2025-03-22 20:19:07,261 - INFO - Using cached data for Client
2025-03-22 20:19:07,261 - INFO - Using cached data for CCCSReport
2025-03-22 20:19:08,002 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:19:08,003 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:19:08,004 - INFO - Using cached data for CCCSReport
2025-03-22 20:19:08,004 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:19:08,005 - INFO - Using cached data for Price
2025-03-22 20:19:08,005 - INFO - Using cached data for Price
2025-03-22 20:19:11,346 - INFO - Using cached data for CCCSReport
2025-03-22 20:19:11,347 - INFO - Using cached data for Price
2025-03-22 20:19:11,348 - INFO - Using cached data for Price
2025-03-22 20:19:12,325 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:19:12,326 - INFO - Using cached data for Client
2025-03-22 20:19:12,327 - INFO - Using cached data for Transfer
2025-03-22 20:19:12,329 - INFO - Using cached data for Price
2025-03-22 20:19:12,329 - INFO - Using cached data for Price
2025-03-22 20:19:12,333 - INFO - Using cached data for Transfer
2025-03-22 20:20:35,163 - DEBUG - Using selector: EpollSelector
2025-03-22 20:20:35,163 - INFO - Starting application
2025-03-22 20:20:35,163 - INFO - Clearing screen
2025-03-22 20:20:36,737 - INFO - Selected: Save files
2025-03-22 20:20:36,737 - INFO - Clearing screen
2025-03-22 20:20:39,408 - INFO - Initiating save operation for all
2025-03-22 20:20:40,156 - INFO - Using cached data for Price
2025-03-22 20:20:43,083 - INFO - Using cached data for Transfer
2025-03-22 20:20:43,086 - INFO - Using cached data for Price
2025-03-22 20:20:43,086 - INFO - Using cached data for Price
2025-03-22 20:20:44,164 - INFO - Using cached data for Transfer
2025-03-22 20:20:44,167 - INFO - Using cached data for Price
2025-03-22 20:20:44,167 - INFO - Using cached data for Price
2025-03-22 20:20:44,169 - INFO - Using cached data for Price
2025-03-22 20:20:44,169 - INFO - Using cached data for Price
2025-03-22 20:20:46,303 - INFO - Using cached data for Price
2025-03-22 20:20:46,303 - INFO - Using cached data for Price
2025-03-22 20:20:46,304 - INFO - Using cached data for ScowTransfer
2025-03-22 20:20:46,304 - INFO - Using cached data for Price
2025-03-22 20:20:46,304 - INFO - Using cached data for Price
2025-03-22 20:20:46,305 - INFO - Using cached data for CCCSReport
2025-03-22 20:20:46,306 - INFO - Using cached data for Price
2025-03-22 20:20:46,306 - INFO - Using cached data for Price
2025-03-22 20:20:46,307 - INFO - Using cached data for CCCSReport
2025-03-22 20:20:46,307 - INFO - Using cached data for Price
2025-03-22 20:20:46,307 - INFO - Using cached data for Price
2025-03-22 20:20:46,308 - INFO - Using cached data for CCCSReport
2025-03-22 20:20:46,309 - INFO - Using cached data for Price
2025-03-22 20:20:46,309 - INFO - Using cached data for Price
2025-03-22 20:20:46,965 - INFO - Using cached data for Price
2025-03-22 20:20:46,965 - INFO - Using cached data for Price
2025-03-22 20:20:47,716 - INFO - Using cached data for Transfer
2025-03-22 20:20:47,722 - INFO - Using cached data for Price
2025-03-22 20:20:47,722 - INFO - Using cached data for Price
2025-03-22 20:20:47,725 - INFO - Using cached data for CCCSReport
2025-03-22 20:20:48,418 - INFO - Using cached data for Client
2025-03-22 20:20:48,419 - INFO - Using cached data for Client
2025-03-22 20:20:48,419 - INFO - Using cached data for Client
2025-03-22 20:20:48,420 - INFO - Using cached data for Client
2025-03-22 20:20:48,420 - INFO - Using cached data for Client
2025-03-22 20:20:48,420 - INFO - Using cached data for Client
2025-03-22 20:20:48,421 - INFO - Using cached data for Client
2025-03-22 20:20:48,421 - INFO - Using cached data for Client
2025-03-22 20:20:48,421 - INFO - Using cached data for Client
2025-03-22 20:20:48,422 - INFO - Using cached data for Client
2025-03-22 20:20:48,422 - INFO - Using cached data for Client
2025-03-22 20:20:48,422 - INFO - Using cached data for Client
2025-03-22 20:20:48,423 - INFO - Using cached data for CCCSReport
2025-03-22 20:20:49,082 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:20:49,082 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:20:49,082 - INFO - Using cached data for CCCSReport
2025-03-22 20:20:49,083 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:20:49,083 - INFO - Using cached data for Price
2025-03-22 20:20:49,084 - INFO - Using cached data for Price
2025-03-22 20:20:52,425 - INFO - Using cached data for CCCSReport
2025-03-22 20:20:52,426 - INFO - Using cached data for Price
2025-03-22 20:20:52,426 - INFO - Using cached data for Price
2025-03-22 20:20:53,577 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:20:53,577 - INFO - Using cached data for Client
2025-03-22 20:20:53,578 - INFO - Using cached data for Transfer
2025-03-22 20:20:53,581 - INFO - Using cached data for Price
2025-03-22 20:20:53,582 - INFO - Using cached data for Price
2025-03-22 20:20:53,586 - INFO - Using cached data for Transfer
2025-03-22 20:20:53,587 - INFO - Using cached data for UnloadingSummary
2025-03-22 20:20:54,597 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:20:54,597 - INFO - Using cached data for Client
2025-03-22 20:20:54,598 - INFO - Using cached data for Transfer
2025-03-22 20:20:54,600 - INFO - Using cached data for Price
2025-03-22 20:20:54,600 - INFO - Using cached data for Price
2025-03-22 20:20:54,604 - INFO - Using cached data for Transfer
2025-03-22 20:20:54,605 - INFO - Using cached data for Price
2025-03-22 20:20:54,605 - INFO - Using cached data for Price
2025-03-22 20:20:54,606 - INFO - Using cached data for UnloadingSummary
2025-03-22 20:20:54,606 - INFO - Using cached data for RawData
2025-03-22 20:20:54,606 - INFO - Using cached data for CCCSReport
2025-03-22 20:20:54,607 - INFO - Using cached data for Price
2025-03-22 20:20:54,607 - INFO - Using cached data for Price
2025-03-22 20:20:55,675 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:20:55,675 - INFO - Using cached data for Client
2025-03-22 20:20:55,676 - INFO - Using cached data for Transfer
2025-03-22 20:20:55,679 - INFO - Using cached data for Price
2025-03-22 20:20:55,679 - INFO - Using cached data for Price
2025-03-22 20:20:55,683 - INFO - Using cached data for Transfer
2025-03-22 20:20:55,684 - INFO - Using cached data for Price
2025-03-22 20:20:55,685 - INFO - Using cached data for Price
2025-03-22 20:20:55,685 - INFO - Using cached data for RawData
2025-03-22 20:20:56,416 - INFO - Using cached data for Price
2025-03-22 20:20:56,416 - INFO - Using cached data for Price
2025-03-22 20:24:56,190 - DEBUG - Using selector: EpollSelector
2025-03-22 20:24:56,191 - INFO - Starting application
2025-03-22 20:24:56,191 - INFO - Clearing screen
2025-03-22 20:25:01,656 - INFO - Selected: Save files
2025-03-22 20:25:01,657 - INFO - Clearing screen
2025-03-22 20:25:04,806 - INFO - Initiating save operation for all
2025-03-22 20:25:05,569 - INFO - Using cached data for Price
2025-03-22 20:25:08,893 - INFO - Using cached data for Transfer
2025-03-22 20:25:08,897 - INFO - Using cached data for Price
2025-03-22 20:25:08,898 - INFO - Using cached data for Price
2025-03-22 20:25:09,867 - INFO - Using cached data for Transfer
2025-03-22 20:25:09,870 - INFO - Using cached data for Price
2025-03-22 20:25:09,870 - INFO - Using cached data for Price
2025-03-22 20:25:09,872 - INFO - Using cached data for Price
2025-03-22 20:25:09,873 - INFO - Using cached data for Price
2025-03-22 20:25:12,088 - INFO - Using cached data for Price
2025-03-22 20:25:12,088 - INFO - Using cached data for Price
2025-03-22 20:25:12,089 - INFO - Using cached data for ScowTransfer
2025-03-22 20:25:12,090 - INFO - Using cached data for Price
2025-03-22 20:25:12,090 - INFO - Using cached data for Price
2025-03-22 20:25:12,090 - INFO - Using cached data for CCCSReport
2025-03-22 20:25:12,091 - INFO - Using cached data for Price
2025-03-22 20:25:12,091 - INFO - Using cached data for Price
2025-03-22 20:25:12,092 - INFO - Using cached data for CCCSReport
2025-03-22 20:25:12,092 - INFO - Using cached data for Price
2025-03-22 20:25:12,092 - INFO - Using cached data for Price
2025-03-22 20:25:12,094 - INFO - Using cached data for CCCSReport
2025-03-22 20:25:12,094 - INFO - Using cached data for Price
2025-03-22 20:25:12,094 - INFO - Using cached data for Price
2025-03-22 20:25:12,851 - INFO - Using cached data for Price
2025-03-22 20:25:12,851 - INFO - Using cached data for Price
2025-03-22 20:25:13,684 - INFO - Using cached data for Transfer
2025-03-22 20:25:13,689 - INFO - Using cached data for Price
2025-03-22 20:25:13,689 - INFO - Using cached data for Price
2025-03-22 20:25:13,691 - INFO - Using cached data for CCCSReport
2025-03-22 20:25:14,370 - INFO - Using cached data for Client
2025-03-22 20:25:14,371 - INFO - Using cached data for Client
2025-03-22 20:25:14,371 - INFO - Using cached data for Client
2025-03-22 20:25:14,371 - INFO - Using cached data for Client
2025-03-22 20:25:14,372 - INFO - Using cached data for Client
2025-03-22 20:25:14,372 - INFO - Using cached data for Client
2025-03-22 20:25:14,372 - INFO - Using cached data for Client
2025-03-22 20:25:14,373 - INFO - Using cached data for Client
2025-03-22 20:25:14,373 - INFO - Using cached data for Client
2025-03-22 20:25:14,373 - INFO - Using cached data for Client
2025-03-22 20:25:14,373 - INFO - Using cached data for Client
2025-03-22 20:25:14,374 - INFO - Using cached data for Client
2025-03-22 20:25:14,374 - INFO - Using cached data for CCCSReport
2025-03-22 20:25:15,028 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:25:15,028 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:25:15,028 - INFO - Using cached data for CCCSReport
2025-03-22 20:25:15,029 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:25:15,029 - INFO - Using cached data for Price
2025-03-22 20:25:15,029 - INFO - Using cached data for Price
2025-03-22 20:25:18,598 - INFO - Using cached data for CCCSReport
2025-03-22 20:25:18,599 - INFO - Using cached data for Price
2025-03-22 20:25:18,599 - INFO - Using cached data for Price
2025-03-22 20:25:19,840 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:25:19,840 - INFO - Using cached data for Client
2025-03-22 20:25:19,841 - INFO - Using cached data for Transfer
2025-03-22 20:25:19,844 - INFO - Using cached data for Price
2025-03-22 20:25:19,844 - INFO - Using cached data for Price
2025-03-22 20:25:19,847 - INFO - Using cached data for Transfer
2025-03-22 20:25:19,850 - INFO - Using cached data for UnloadingSummary
2025-03-22 20:25:21,018 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:25:21,018 - INFO - Using cached data for Client
2025-03-22 20:25:21,019 - INFO - Using cached data for Transfer
2025-03-22 20:25:21,021 - INFO - Using cached data for Price
2025-03-22 20:25:21,021 - INFO - Using cached data for Price
2025-03-22 20:25:21,025 - INFO - Using cached data for Transfer
2025-03-22 20:25:21,027 - INFO - Using cached data for Price
2025-03-22 20:25:21,027 - INFO - Using cached data for Price
2025-03-22 20:25:21,028 - INFO - Using cached data for UnloadingSummary
2025-03-22 20:25:21,028 - INFO - Using cached data for RawData
2025-03-22 20:25:21,028 - INFO - Using cached data for CCCSReport
2025-03-22 20:25:21,029 - INFO - Using cached data for Price
2025-03-22 20:25:21,029 - INFO - Using cached data for Price
2025-03-22 20:25:22,386 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:25:22,386 - INFO - Using cached data for Client
2025-03-22 20:25:22,387 - INFO - Using cached data for Transfer
2025-03-22 20:25:22,389 - INFO - Using cached data for Price
2025-03-22 20:25:22,389 - INFO - Using cached data for Price
2025-03-22 20:25:22,393 - INFO - Using cached data for Transfer
2025-03-22 20:25:22,395 - INFO - Using cached data for Price
2025-03-22 20:25:22,395 - INFO - Using cached data for Price
2025-03-22 20:25:22,396 - INFO - Using cached data for RawData
2025-03-22 20:25:23,078 - INFO - Using cached data for Price
2025-03-22 20:25:23,079 - INFO - Using cached data for Price
2025-03-22 20:25:24,422 - INFO - Using cached data for Price
2025-03-22 20:25:24,422 - INFO - Using cached data for Price
2025-03-22 20:26:03,829 - DEBUG - Using selector: EpollSelector
2025-03-22 20:26:03,829 - INFO - Starting application
2025-03-22 20:26:03,829 - INFO - Clearing screen
2025-03-22 20:26:05,616 - INFO - Selected: Save files
2025-03-22 20:26:05,616 - INFO - Clearing screen
2025-03-22 20:26:08,887 - INFO - Initiating save operation for all
2025-03-22 20:26:09,567 - INFO - Using cached data for Price
2025-03-22 20:26:12,474 - INFO - Using cached data for Transfer
2025-03-22 20:26:12,479 - INFO - Using cached data for Price
2025-03-22 20:26:12,479 - INFO - Using cached data for Price
2025-03-22 20:26:13,490 - INFO - Using cached data for Transfer
2025-03-22 20:26:13,493 - INFO - Using cached data for Price
2025-03-22 20:26:13,493 - INFO - Using cached data for Price
2025-03-22 20:26:13,496 - INFO - Using cached data for Price
2025-03-22 20:26:13,496 - INFO - Using cached data for Price
2025-03-22 20:26:15,408 - INFO - Using cached data for Price
2025-03-22 20:26:15,409 - INFO - Using cached data for Price
2025-03-22 20:26:15,410 - INFO - Using cached data for ScowTransfer
2025-03-22 20:26:15,410 - INFO - Using cached data for Price
2025-03-22 20:26:15,410 - INFO - Using cached data for Price
2025-03-22 20:26:15,411 - INFO - Using cached data for CCCSReport
2025-03-22 20:26:15,411 - INFO - Using cached data for Price
2025-03-22 20:26:15,411 - INFO - Using cached data for Price
2025-03-22 20:26:15,412 - INFO - Using cached data for CCCSReport
2025-03-22 20:26:15,413 - INFO - Using cached data for Price
2025-03-22 20:26:15,413 - INFO - Using cached data for Price
2025-03-22 20:26:15,414 - INFO - Using cached data for CCCSReport
2025-03-22 20:26:15,414 - INFO - Using cached data for Price
2025-03-22 20:26:15,414 - INFO - Using cached data for Price
2025-03-22 20:26:16,241 - INFO - Using cached data for Price
2025-03-22 20:26:16,241 - INFO - Using cached data for Price
2025-03-22 20:26:16,974 - INFO - Using cached data for Transfer
2025-03-22 20:26:16,976 - INFO - Using cached data for Price
2025-03-22 20:26:16,976 - INFO - Using cached data for Price
2025-03-22 20:26:16,977 - INFO - Using cached data for CCCSReport
2025-03-22 20:26:17,653 - INFO - Using cached data for Client
2025-03-22 20:26:17,653 - INFO - Using cached data for Client
2025-03-22 20:26:17,653 - INFO - Using cached data for Client
2025-03-22 20:26:17,654 - INFO - Using cached data for Client
2025-03-22 20:26:17,654 - INFO - Using cached data for Client
2025-03-22 20:26:17,654 - INFO - Using cached data for Client
2025-03-22 20:26:17,654 - INFO - Using cached data for Client
2025-03-22 20:26:17,655 - INFO - Using cached data for Client
2025-03-22 20:26:17,655 - INFO - Using cached data for Client
2025-03-22 20:26:17,655 - INFO - Using cached data for Client
2025-03-22 20:26:17,655 - INFO - Using cached data for Client
2025-03-22 20:26:17,655 - INFO - Using cached data for Client
2025-03-22 20:26:17,656 - INFO - Using cached data for CCCSReport
2025-03-22 20:26:18,336 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:26:18,337 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:26:18,337 - INFO - Using cached data for CCCSReport
2025-03-22 20:26:18,338 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:26:18,338 - INFO - Using cached data for Price
2025-03-22 20:26:18,338 - INFO - Using cached data for Price
2025-03-22 20:26:22,197 - INFO - Using cached data for CCCSReport
2025-03-22 20:26:22,198 - INFO - Using cached data for Price
2025-03-22 20:26:22,198 - INFO - Using cached data for Price
2025-03-22 20:26:23,536 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:26:23,536 - INFO - Using cached data for Client
2025-03-22 20:26:23,537 - INFO - Using cached data for Transfer
2025-03-22 20:26:23,540 - INFO - Using cached data for Price
2025-03-22 20:26:23,540 - INFO - Using cached data for Price
2025-03-22 20:26:23,544 - INFO - Using cached data for Transfer
2025-03-22 20:26:23,546 - INFO - Using cached data for UnloadingSummary
2025-03-22 20:26:24,749 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:26:24,749 - INFO - Using cached data for Client
2025-03-22 20:26:24,750 - INFO - Using cached data for Transfer
2025-03-22 20:26:24,751 - INFO - Using cached data for Price
2025-03-22 20:26:24,752 - INFO - Using cached data for Price
2025-03-22 20:26:24,754 - INFO - Using cached data for Transfer
2025-03-22 20:26:24,755 - INFO - Using cached data for Price
2025-03-22 20:26:24,755 - INFO - Using cached data for Price
2025-03-22 20:26:24,756 - INFO - Using cached data for UnloadingSummary
2025-03-22 20:26:24,756 - INFO - Using cached data for RawData
2025-03-22 20:26:24,756 - INFO - Using cached data for CCCSReport
2025-03-22 20:26:24,757 - INFO - Using cached data for Price
2025-03-22 20:26:24,757 - INFO - Using cached data for Price
2025-03-22 20:26:25,938 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:26:25,939 - INFO - Using cached data for Client
2025-03-22 20:26:25,939 - INFO - Using cached data for Transfer
2025-03-22 20:26:25,942 - INFO - Using cached data for Price
2025-03-22 20:26:25,942 - INFO - Using cached data for Price
2025-03-22 20:26:25,946 - INFO - Using cached data for Transfer
2025-03-22 20:26:25,948 - INFO - Using cached data for Price
2025-03-22 20:26:25,948 - INFO - Using cached data for Price
2025-03-22 20:26:25,948 - INFO - Using cached data for RawData
2025-03-22 20:26:26,602 - INFO - Using cached data for Price
2025-03-22 20:26:26,602 - INFO - Using cached data for Price
2025-03-22 20:26:27,280 - INFO - Using cached data for Price
2025-03-22 20:26:27,280 - INFO - Using cached data for Price
2025-03-22 20:26:27,281 - INFO - Using cached data for Client
2025-03-22 20:26:28,114 - INFO - Using cached data for Price
2025-03-22 20:26:28,114 - INFO - Using cached data for Price
2025-03-22 20:26:28,847 - INFO - Using cached data for Transfer
2025-03-22 20:26:28,850 - INFO - Using cached data for Price
2025-03-22 20:26:28,850 - INFO - Using cached data for Price
2025-03-22 20:26:30,046 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:26:30,046 - INFO - Using cached data for Client
2025-03-22 20:26:30,047 - INFO - Using cached data for Transfer
2025-03-22 20:26:30,050 - INFO - Using cached data for Price
2025-03-22 20:26:30,050 - INFO - Using cached data for Price
2025-03-22 20:26:30,768 - INFO - Using cached data for Transfer
2025-03-22 20:26:30,768 - INFO - Using cached data for Price
2025-03-22 20:26:30,768 - INFO - Using cached data for Price
2025-03-22 20:26:30,769 - INFO - Using cached data for Transfer
2025-03-22 20:28:44,972 - DEBUG - Using selector: EpollSelector
2025-03-22 20:28:44,972 - INFO - Starting application
2025-03-22 20:28:44,972 - INFO - Clearing screen
2025-03-22 20:28:47,532 - INFO - Selected: Save files
2025-03-22 20:28:47,532 - INFO - Clearing screen
2025-03-22 20:28:50,754 - INFO - Initiating save operation for all
2025-03-22 20:28:51,526 - INFO - Using cached data for Price
2025-03-22 20:28:54,606 - INFO - Using cached data for Transfer
2025-03-22 20:28:54,610 - INFO - Using cached data for Price
2025-03-22 20:28:54,610 - INFO - Using cached data for Price
2025-03-22 20:28:55,643 - INFO - Using cached data for Transfer
2025-03-22 20:28:55,645 - INFO - Using cached data for Price
2025-03-22 20:28:55,645 - INFO - Using cached data for Price
2025-03-22 20:28:55,648 - INFO - Using cached data for Price
2025-03-22 20:28:55,648 - INFO - Using cached data for Price
2025-03-22 20:28:57,761 - INFO - Using cached data for Price
2025-03-22 20:28:57,761 - INFO - Using cached data for Price
2025-03-22 20:28:57,762 - INFO - Using cached data for ScowTransfer
2025-03-22 20:28:57,762 - INFO - Using cached data for Price
2025-03-22 20:28:57,763 - INFO - Using cached data for Price
2025-03-22 20:28:57,763 - INFO - Using cached data for CCCSReport
2025-03-22 20:28:57,764 - INFO - Using cached data for Price
2025-03-22 20:28:57,764 - INFO - Using cached data for Price
2025-03-22 20:28:57,765 - INFO - Using cached data for CCCSReport
2025-03-22 20:28:57,765 - INFO - Using cached data for Price
2025-03-22 20:28:57,765 - INFO - Using cached data for Price
2025-03-22 20:28:57,766 - INFO - Using cached data for CCCSReport
2025-03-22 20:28:57,766 - INFO - Using cached data for Price
2025-03-22 20:28:57,766 - INFO - Using cached data for Price
2025-03-22 20:28:58,444 - INFO - Using cached data for Price
2025-03-22 20:28:58,444 - INFO - Using cached data for Price
2025-03-22 20:28:59,282 - INFO - Using cached data for Transfer
2025-03-22 20:28:59,284 - INFO - Using cached data for Price
2025-03-22 20:28:59,284 - INFO - Using cached data for Price
2025-03-22 20:28:59,285 - INFO - Using cached data for CCCSReport
2025-03-22 20:28:59,962 - INFO - Using cached data for Client
2025-03-22 20:28:59,962 - INFO - Using cached data for Client
2025-03-22 20:28:59,963 - INFO - Using cached data for Client
2025-03-22 20:28:59,963 - INFO - Using cached data for Client
2025-03-22 20:28:59,963 - INFO - Using cached data for Client
2025-03-22 20:28:59,963 - INFO - Using cached data for Client
2025-03-22 20:28:59,964 - INFO - Using cached data for Client
2025-03-22 20:28:59,964 - INFO - Using cached data for Client
2025-03-22 20:28:59,964 - INFO - Using cached data for Client
2025-03-22 20:28:59,964 - INFO - Using cached data for Client
2025-03-22 20:28:59,965 - INFO - Using cached data for Client
2025-03-22 20:28:59,965 - INFO - Using cached data for Client
2025-03-22 20:28:59,966 - INFO - Using cached data for CCCSReport
2025-03-22 20:29:00,694 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:29:00,695 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:29:00,696 - INFO - Using cached data for CCCSReport
2025-03-22 20:29:00,697 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:29:00,697 - INFO - Using cached data for Price
2025-03-22 20:29:00,697 - INFO - Using cached data for Price
2025-03-22 20:29:04,181 - INFO - Using cached data for CCCSReport
2025-03-22 20:29:04,182 - INFO - Using cached data for Price
2025-03-22 20:29:04,182 - INFO - Using cached data for Price
2025-03-22 20:29:05,472 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:29:05,473 - INFO - Using cached data for Client
2025-03-22 20:29:05,474 - INFO - Using cached data for Transfer
2025-03-22 20:29:05,476 - INFO - Using cached data for Price
2025-03-22 20:29:05,477 - INFO - Using cached data for Price
2025-03-22 20:29:05,481 - INFO - Using cached data for Transfer
2025-03-22 20:29:05,483 - INFO - Using cached data for UnloadingSummary
2025-03-22 20:29:06,481 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:29:06,481 - INFO - Using cached data for Client
2025-03-22 20:29:06,482 - INFO - Using cached data for Transfer
2025-03-22 20:29:06,485 - INFO - Using cached data for Price
2025-03-22 20:29:06,485 - INFO - Using cached data for Price
2025-03-22 20:29:06,489 - INFO - Using cached data for Transfer
2025-03-22 20:29:06,490 - INFO - Using cached data for Price
2025-03-22 20:29:06,490 - INFO - Using cached data for Price
2025-03-22 20:29:06,491 - INFO - Using cached data for UnloadingSummary
2025-03-22 20:29:06,491 - INFO - Using cached data for RawData
2025-03-22 20:29:06,492 - INFO - Using cached data for CCCSReport
2025-03-22 20:29:06,492 - INFO - Using cached data for Price
2025-03-22 20:29:06,492 - INFO - Using cached data for Price
2025-03-22 20:29:07,683 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:29:07,683 - INFO - Using cached data for Client
2025-03-22 20:29:07,684 - INFO - Using cached data for Transfer
2025-03-22 20:29:07,686 - INFO - Using cached data for Price
2025-03-22 20:29:07,686 - INFO - Using cached data for Price
2025-03-22 20:29:07,690 - INFO - Using cached data for Transfer
2025-03-22 20:29:07,692 - INFO - Using cached data for Price
2025-03-22 20:29:07,692 - INFO - Using cached data for Price
2025-03-22 20:29:07,693 - INFO - Using cached data for RawData
2025-03-22 20:29:08,474 - INFO - Using cached data for Price
2025-03-22 20:29:08,475 - INFO - Using cached data for Price
2025-03-22 20:29:09,284 - INFO - Using cached data for Price
2025-03-22 20:29:09,284 - INFO - Using cached data for Price
2025-03-22 20:29:09,285 - INFO - Using cached data for Client
2025-03-22 20:29:10,108 - INFO - Using cached data for Price
2025-03-22 20:29:10,108 - INFO - Using cached data for Price
2025-03-22 20:29:10,972 - INFO - Using cached data for Transfer
2025-03-22 20:29:10,974 - INFO - Using cached data for Price
2025-03-22 20:29:10,974 - INFO - Using cached data for Price
2025-03-22 20:29:12,147 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:29:12,148 - INFO - Using cached data for Client
2025-03-22 20:29:12,149 - INFO - Using cached data for Transfer
2025-03-22 20:29:12,151 - INFO - Using cached data for Price
2025-03-22 20:29:12,151 - INFO - Using cached data for Price
2025-03-22 20:29:12,782 - INFO - Using cached data for Transfer
2025-03-22 20:29:12,782 - INFO - Using cached data for Price
2025-03-22 20:29:12,782 - INFO - Using cached data for Price
2025-03-22 20:29:12,783 - INFO - Using cached data for Transfer
2025-03-22 20:30:11,601 - DEBUG - Using selector: EpollSelector
2025-03-22 20:30:11,602 - INFO - Starting application
2025-03-22 20:30:11,602 - INFO - Clearing screen
2025-03-22 20:30:13,240 - INFO - Selected: Save files
2025-03-22 20:30:13,241 - INFO - Clearing screen
2025-03-22 20:30:16,300 - INFO - Initiating save operation for all
2025-03-22 20:30:17,015 - INFO - Using cached data for Price
2025-03-22 20:30:20,145 - INFO - Using cached data for Transfer
2025-03-22 20:30:20,147 - INFO - Using cached data for Price
2025-03-22 20:30:20,147 - INFO - Using cached data for Price
2025-03-22 20:30:21,128 - INFO - Using cached data for Transfer
2025-03-22 20:30:21,131 - INFO - Using cached data for Price
2025-03-22 20:30:21,131 - INFO - Using cached data for Price
2025-03-22 20:30:21,133 - INFO - Using cached data for Price
2025-03-22 20:30:21,133 - INFO - Using cached data for Price
2025-03-22 20:30:23,353 - INFO - Using cached data for Price
2025-03-22 20:30:23,353 - INFO - Using cached data for Price
2025-03-22 20:30:23,354 - INFO - Using cached data for ScowTransfer
2025-03-22 20:30:23,355 - INFO - Using cached data for Price
2025-03-22 20:30:23,355 - INFO - Using cached data for Price
2025-03-22 20:30:23,356 - INFO - Using cached data for CCCSReport
2025-03-22 20:30:23,356 - INFO - Using cached data for Price
2025-03-22 20:30:23,356 - INFO - Using cached data for Price
2025-03-22 20:30:23,357 - INFO - Using cached data for CCCSReport
2025-03-22 20:30:23,358 - INFO - Using cached data for Price
2025-03-22 20:30:23,358 - INFO - Using cached data for Price
2025-03-22 20:30:23,360 - INFO - Using cached data for CCCSReport
2025-03-22 20:30:23,360 - INFO - Using cached data for Price
2025-03-22 20:30:23,360 - INFO - Using cached data for Price
2025-03-22 20:30:23,972 - INFO - Using cached data for Price
2025-03-22 20:30:23,972 - INFO - Using cached data for Price
2025-03-22 20:30:24,794 - INFO - Using cached data for Transfer
2025-03-22 20:30:24,797 - INFO - Using cached data for Price
2025-03-22 20:30:24,797 - INFO - Using cached data for Price
2025-03-22 20:30:24,799 - INFO - Using cached data for CCCSReport
2025-03-22 20:30:25,463 - INFO - Using cached data for Client
2025-03-22 20:30:25,463 - INFO - Using cached data for Client
2025-03-22 20:30:25,464 - INFO - Using cached data for Client
2025-03-22 20:30:25,464 - INFO - Using cached data for Client
2025-03-22 20:30:25,464 - INFO - Using cached data for Client
2025-03-22 20:30:25,465 - INFO - Using cached data for Client
2025-03-22 20:30:25,465 - INFO - Using cached data for Client
2025-03-22 20:30:25,465 - INFO - Using cached data for Client
2025-03-22 20:30:25,465 - INFO - Using cached data for Client
2025-03-22 20:30:25,466 - INFO - Using cached data for Client
2025-03-22 20:30:25,467 - INFO - Using cached data for Client
2025-03-22 20:30:25,467 - INFO - Using cached data for Client
2025-03-22 20:30:25,468 - INFO - Using cached data for CCCSReport
2025-03-22 20:30:26,101 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:30:26,102 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:30:26,102 - INFO - Using cached data for CCCSReport
2025-03-22 20:30:26,103 - INFO - Using cached data for IPHSBycatchTransfer
2025-03-22 20:30:26,103 - INFO - Using cached data for Price
2025-03-22 20:30:26,103 - INFO - Using cached data for Price
2025-03-22 20:30:29,581 - INFO - Using cached data for CCCSReport
2025-03-22 20:30:29,582 - INFO - Using cached data for Price
2025-03-22 20:30:29,582 - INFO - Using cached data for Price
2025-03-22 20:30:30,854 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:30:30,854 - INFO - Using cached data for Client
2025-03-22 20:30:30,855 - INFO - Using cached data for Transfer
2025-03-22 20:30:30,858 - INFO - Using cached data for Price
2025-03-22 20:30:30,858 - INFO - Using cached data for Price
2025-03-22 20:30:30,862 - INFO - Using cached data for Transfer
2025-03-22 20:30:30,863 - INFO - Using cached data for UnloadingSummary
2025-03-22 20:30:31,892 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:30:31,892 - INFO - Using cached data for Client
2025-03-22 20:30:31,893 - INFO - Using cached data for Transfer
2025-03-22 20:30:31,896 - INFO - Using cached data for Price
2025-03-22 20:30:31,896 - INFO - Using cached data for Price
2025-03-22 20:30:31,900 - INFO - Using cached data for Transfer
2025-03-22 20:30:31,902 - INFO - Using cached data for Price
2025-03-22 20:30:31,902 - INFO - Using cached data for Price
2025-03-22 20:30:31,903 - INFO - Using cached data for UnloadingSummary
2025-03-22 20:30:31,903 - INFO - Using cached data for RawData
2025-03-22 20:30:31,903 - INFO - Using cached data for CCCSReport
2025-03-22 20:30:31,904 - INFO - Using cached data for Price
2025-03-22 20:30:31,904 - INFO - Using cached data for Price
2025-03-22 20:30:33,056 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:30:33,056 - INFO - Using cached data for Client
2025-03-22 20:30:33,057 - INFO - Using cached data for Transfer
2025-03-22 20:30:33,059 - INFO - Using cached data for Price
2025-03-22 20:30:33,059 - INFO - Using cached data for Price
2025-03-22 20:30:33,062 - INFO - Using cached data for Transfer
2025-03-22 20:30:33,064 - INFO - Using cached data for Price
2025-03-22 20:30:33,064 - INFO - Using cached data for Price
2025-03-22 20:30:33,064 - INFO - Using cached data for RawData
2025-03-22 20:30:33,860 - INFO - Using cached data for Price
2025-03-22 20:30:33,860 - INFO - Using cached data for Price
2025-03-22 20:30:34,589 - INFO - Using cached data for Price
2025-03-22 20:30:34,590 - INFO - Using cached data for Price
2025-03-22 20:30:34,591 - INFO - Using cached data for Client
2025-03-22 20:30:35,307 - INFO - Using cached data for Price
2025-03-22 20:30:35,307 - INFO - Using cached data for Price
2025-03-22 20:30:36,062 - INFO - Using cached data for Transfer
2025-03-22 20:30:36,068 - INFO - Using cached data for Price
2025-03-22 20:30:36,068 - INFO - Using cached data for Price
2025-03-22 20:30:37,086 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 2 out of 53 values: ["", ""]
2025-03-22 20:30:37,086 - INFO - Using cached data for Client
2025-03-22 20:30:37,087 - INFO - Using cached data for Transfer
2025-03-22 20:30:37,089 - INFO - Using cached data for Price
2025-03-22 20:30:37,089 - INFO - Using cached data for Price
2025-03-22 20:30:37,792 - INFO - Using cached data for Transfer
2025-03-22 20:30:37,792 - INFO - Using cached data for Price
2025-03-22 20:30:37,792 - INFO - Using cached data for Price
2025-03-22 20:30:37,793 - INFO - Using cached data for Transfer
2025-03-22 20:30:37,796 - INFO - Using cached data for ScowTransfer
2025-03-22 20:30:39,374 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'end_time' for 1 out of 32 values: ["11:15"]
2025-03-22 20:30:39,375 - INFO - Processing all dataframe categories concurrently
2025-03-22 20:30:39,375 - INFO - Queueing category: emr
2025-03-22 20:30:39,376 - INFO - Queueing category: operations
2025-03-22 20:30:39,376 - INFO - Queueing category: netlist
2025-03-22 20:30:39,376 - INFO - Queueing category: bin_dispatch
2025-03-22 20:30:39,376 - INFO - Queueing category: shore_handling
2025-03-22 20:30:39,376 - INFO - Queueing category: stuffing
2025-03-22 20:30:39,376 - INFO - Queueing category: transport
2025-03-22 20:30:39,376 - INFO - Queueing category: miscellaneous
2025-03-22 20:30:39,376 - INFO - Processing dataframe shifting of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:39,377 - INFO - Collecting LazyFrame for shifting
2025-03-22 20:30:39,420 - INFO - Successfully processed dataframe shifting
2025-03-22 20:30:39,420 - INFO - Writing to output/csv/shifting.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-03-22 20:30:39,421 - INFO - Processing dataframe washing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:39,421 - INFO - Collecting LazyFrame for washing
2025-03-22 20:30:39,453 - INFO - Successfully processed dataframe washing
2025-03-22 20:30:39,454 - INFO - Writing to output/csv/washing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-03-22 20:30:39,454 - INFO - Processing dataframe pti of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:39,457 - INFO - Collecting LazyFrame for pti
2025-03-22 20:30:39,822 - INFO - Successfully processed dataframe pti
2025-03-22 20:30:39,822 - INFO - Writing to output/csv/pti.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-03-22 20:30:39,823 - INFO - Processing dataframe ops of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:39,824 - INFO - Collecting LazyFrame for ops
2025-03-22 20:30:39,852 - ERROR - Error processing dataframe ops: invalid series dtype: expected `String`, got `time` for series with name `Time`
2025-03-22 20:30:39,853 - INFO - Processing dataframe hatch_to_hatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:39,854 - INFO - Collecting LazyFrame for hatch_to_hatch
2025-03-22 20:30:39,942 - INFO - Successfully processed dataframe hatch_to_hatch
2025-03-22 20:30:39,942 - INFO - Writing to output/csv/hatch_to_hatch.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-03-22 20:30:39,942 - INFO - Processing dataframe net_list of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:39,942 - INFO - Collecting LazyFrame for net_list
2025-03-22 20:30:39,943 - ERROR - Error processing dataframe net_list: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:39,943 - INFO - Processing dataframe iot_container_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:39,943 - INFO - Collecting LazyFrame for iot_container_stuffing
2025-03-22 20:30:39,943 - ERROR - Error processing dataframe iot_container_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:39,943 - INFO - Processing dataframe oss_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:39,943 - INFO - Collecting LazyFrame for oss_stuffing
2025-03-22 20:30:39,943 - ERROR - Error processing dataframe oss_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:39,944 - INFO - Processing dataframe full_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:39,944 - INFO - Collecting LazyFrame for full_scows_transfer
2025-03-22 20:30:40,134 - INFO - Successfully processed dataframe full_scows_transfer
2025-03-22 20:30:40,135 - INFO - Writing to output/csv/full_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-03-22 20:30:40,136 - INFO - Processing dataframe empty_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,136 - INFO - Collecting LazyFrame for empty_scows_transfer
2025-03-22 20:30:40,155 - INFO - Successfully processed dataframe empty_scows_transfer
2025-03-22 20:30:40,156 - INFO - Processing dataframe salt of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,156 - INFO - Writing to output/csv/empty_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-03-22 20:30:40,157 - INFO - Collecting LazyFrame for salt
2025-03-22 20:30:40,199 - INFO - Successfully processed dataframe salt
2025-03-22 20:30:40,199 - INFO - Writing to output/csv/salt.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-03-22 20:30:40,200 - INFO - Processing dataframe bin_tipping of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,200 - INFO - Collecting LazyFrame for bin_tipping
2025-03-22 20:30:40,228 - INFO - Successfully processed dataframe bin_tipping
2025-03-22 20:30:40,230 - INFO - Writing to output/csv/bin_tipping.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-03-22 20:30:40,230 - INFO - Processing dataframe pallet_liner of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,232 - INFO - Collecting LazyFrame for pallet_liner
2025-03-22 20:30:40,257 - INFO - Successfully processed dataframe pallet_liner
2025-03-22 20:30:40,258 - INFO - Writing to output/csv/pallet_liner.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-03-22 20:30:40,259 - INFO - Processing dataframe container_plugin of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,259 - INFO - Collecting LazyFrame for container_plugin
2025-03-22 20:30:40,259 - ERROR - Error processing dataframe container_plugin: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:40,260 - INFO - Processing dataframe shore_crane of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,260 - INFO - Collecting LazyFrame for shore_crane
2025-03-22 20:30:40,295 - INFO - Successfully processed dataframe shore_crane
2025-03-22 20:30:40,296 - INFO - Writing to output/csv/shore_crane.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-03-22 20:30:40,296 - INFO - Successfully wrote shifting to file
2025-03-22 20:30:40,296 - INFO - Successfully wrote washing to file
2025-03-22 20:30:40,297 - INFO - Successfully wrote pti to file
2025-03-22 20:30:40,297 - INFO - Successfully wrote hatch_to_hatch to file
2025-03-22 20:30:40,297 - INFO - Successfully wrote full_scows_transfer to file
2025-03-22 20:30:40,297 - INFO - Successfully wrote empty_scows_transfer to file
2025-03-22 20:30:40,297 - INFO - Successfully wrote salt to file
2025-03-22 20:30:40,298 - INFO - Successfully wrote bin_tipping to file
2025-03-22 20:30:40,298 - INFO - Successfully wrote pallet_liner to file
2025-03-22 20:30:40,298 - INFO - Processing dataframe transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,298 - INFO - Collecting LazyFrame for transfer
2025-03-22 20:30:40,377 - INFO - Successfully processed dataframe transfer
2025-03-22 20:30:40,378 - INFO - Writing to output/csv/transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-03-22 20:30:40,378 - INFO - Processing dataframe scow_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,379 - INFO - Collecting LazyFrame for scow_transfer
2025-03-22 20:30:40,391 - INFO - Successfully processed dataframe scow_transfer
2025-03-22 20:30:40,392 - INFO - Writing to output/csv/scow_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-03-22 20:30:40,392 - INFO - Processing dataframe forklift of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,393 - INFO - Collecting LazyFrame for forklift
2025-03-22 20:30:40,397 - ERROR - Error processing dataframe forklift: unable to find column "service_type"; valid columns: []

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:40,398 - INFO - Processing dataframe static_loader of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,398 - INFO - Collecting LazyFrame for static_loader
2025-03-22 20:30:40,399 - ERROR - Error processing dataframe static_loader: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("operation_type"), col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
   SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
    DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-03-22 20:30:40,399 - INFO - Processing dataframe dispatch_to_cargo of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,399 - INFO - Collecting LazyFrame for dispatch_to_cargo
2025-03-22 20:30:40,401 - ERROR - Error processing dataframe dispatch_to_cargo: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type"), col("total_tonnage").abs(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("operation_type").is_in([Series]) FROM
     SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
      DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-03-22 20:30:40,406 - INFO - Processing dataframe truck_to_cccs of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,406 - INFO - Collecting LazyFrame for truck_to_cccs
2025-03-22 20:30:40,407 - ERROR - Error processing dataframe truck_to_cccs: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("vessel"), col("total_tonnage"), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("customer").is_in([Series]) FROM
    FILTER col("operation_type").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-03-22 20:30:40,407 - INFO - Processing dataframe cross_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,407 - INFO - Collecting LazyFrame for cross_stuffing
2025-03-22 20:30:40,408 - ERROR - Error processing dataframe cross_stuffing: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("vessel_client"), col("date"), col("origin"), col("destination"), col("start_time"), col("end_time"), col("total_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("is_origin_empty"), col("service").alias("Service"), col("invoiced")] FROM
  FILTER [(col("day").str.replace([String(), String(x)])) != (String(x))] FROM
    DF ["day", "vessel_client", "date", "origin", ...]; PROJECT */25 COLUMNS
2025-03-22 20:30:40,409 - INFO - Processing dataframe cccs_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,409 - INFO - Collecting LazyFrame for cccs_stuffing
2025-03-22 20:30:40,431 - INFO - Successfully processed dataframe cccs_stuffing
2025-03-22 20:30:40,432 - INFO - Writing to output/csv/cccs_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-03-22 20:30:40,432 - INFO - Processing dataframe bycatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-03-22 20:30:40,434 - INFO - Collecting LazyFrame for bycatch
2025-03-22 20:30:40,435 - ERROR - Error processing dataframe bycatch: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type").str.replace([String(Sorting from Unloading), String(CCCS (By-Catch))]).str.replace([String(Unsorted from Unloading), String(CCCS (By-Catch))]), col("total_tonnage").strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).round()] FROM
  FILTER col("operation_type").is_in([Series]) FROM
    FILTER col("customer").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-03-22 20:30:40,436 - INFO - Successfully wrote shore_crane to file
2025-03-22 20:30:40,436 - INFO - Successfully wrote scow_transfer to file
2025-03-22 20:30:40,437 - INFO - Successfully wrote transfer to file
2025-03-22 20:30:40,437 - INFO - Successfully wrote cccs_stuffing to file
2025-03-22 20:30:40,437 - INFO - Successfully saved shifting
2025-03-22 20:30:40,438 - INFO - Successfully saved washing
2025-03-22 20:30:40,438 - INFO - Successfully saved pti
2025-03-22 20:30:40,438 - ERROR - Error saving ops: invalid series dtype: expected `String`, got `time` for series with name `Time`
2025-03-22 20:30:40,438 - INFO - Successfully saved hatch_to_hatch
2025-03-22 20:30:40,438 - ERROR - Error saving net_list: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:40,438 - ERROR - Error saving iot_container_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:40,439 - ERROR - Error saving oss_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:40,439 - INFO - Successfully saved full_scows_transfer
2025-03-22 20:30:40,439 - INFO - Successfully saved empty_scows_transfer
2025-03-22 20:30:40,439 - INFO - Successfully saved salt
2025-03-22 20:30:40,439 - INFO - Successfully saved bin_tipping
2025-03-22 20:30:40,439 - INFO - Successfully saved pallet_liner
2025-03-22 20:30:40,440 - ERROR - Error saving container_plugin: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:40,440 - INFO - Successfully saved shore_crane
2025-03-22 20:30:40,440 - INFO - Successfully saved transfer
2025-03-22 20:30:40,440 - INFO - Successfully saved scow_transfer
2025-03-22 20:30:40,440 - ERROR - Error saving forklift: unable to find column "service_type"; valid columns: []

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:40,440 - ERROR - Error saving static_loader: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("operation_type"), col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
   SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
    DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-03-22 20:30:40,440 - ERROR - Error saving dispatch_to_cargo: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type"), col("total_tonnage").abs(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("operation_type").is_in([Series]) FROM
     SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
      DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-03-22 20:30:40,441 - ERROR - Error saving truck_to_cccs: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("vessel"), col("total_tonnage"), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("customer").is_in([Series]) FROM
    FILTER col("operation_type").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-03-22 20:30:40,441 - ERROR - Error saving cross_stuffing: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("vessel_client"), col("date"), col("origin"), col("destination"), col("start_time"), col("end_time"), col("total_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("is_origin_empty"), col("service").alias("Service"), col("invoiced")] FROM
  FILTER [(col("day").str.replace([String(), String(x)])) != (String(x))] FROM
    DF ["day", "vessel_client", "date", "origin", ...]; PROJECT */25 COLUMNS
2025-03-22 20:30:40,441 - INFO - Successfully saved cccs_stuffing
2025-03-22 20:30:40,441 - ERROR - Error saving bycatch: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type").str.replace([String(Sorting from Unloading), String(CCCS (By-Catch))]).str.replace([String(Unsorted from Unloading), String(CCCS (By-Catch))]), col("total_tonnage").strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).round()] FROM
  FILTER col("operation_type").is_in([Series]) FROM
    FILTER col("customer").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-03-22 20:30:40,441 - INFO - Save completed
2025-03-22 20:30:40,441 - INFO - Successfully saved: 13 files
2025-03-22 20:30:40,442 - ERROR - Failed to save: 11 files
2025-03-22 20:30:40,442 - ERROR -   - ops: invalid series dtype: expected `String`, got `time` for series with name `Time`
2025-03-22 20:30:40,442 - ERROR -   - net_list: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:40,442 - ERROR -   - iot_container_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:40,442 - ERROR -   - oss_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:40,442 - ERROR -   - container_plugin: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:40,443 - ERROR -   - forklift: unable to find column "service_type"; valid columns: []

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-03-22 20:30:40,443 - ERROR -   - static_loader: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("operation_type"), col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
   SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
    DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-03-22 20:30:40,443 - ERROR -   - dispatch_to_cargo: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type"), col("total_tonnage").abs(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("operation_type").is_in([Series]) FROM
     SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
      DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-03-22 20:30:40,443 - ERROR -   - truck_to_cccs: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("vessel"), col("total_tonnage"), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("customer").is_in([Series]) FROM
    FILTER col("operation_type").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-03-22 20:30:40,444 - ERROR -   - cross_stuffing: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("vessel_client"), col("date"), col("origin"), col("destination"), col("start_time"), col("end_time"), col("total_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("is_origin_empty"), col("service").alias("Service"), col("invoiced")] FROM
  FILTER [(col("day").str.replace([String(), String(x)])) != (String(x))] FROM
    DF ["day", "vessel_client", "date", "origin", ...]; PROJECT */25 COLUMNS
2025-03-22 20:30:40,444 - ERROR -   - bycatch: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type").str.replace([String(Sorting from Unloading), String(CCCS (By-Catch))]).str.replace([String(Unsorted from Unloading), String(CCCS (By-Catch))]), col("total_tonnage").strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).round()] FROM
  FILTER col("operation_type").is_in([Series]) FROM
    FILTER col("customer").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-03-22 20:40:56,926 - INFO - Starting application
2025-03-22 20:40:57,014 - INFO - Clearing screen
2025-03-22 20:41:00,076 - INFO - Selected: Check logistics records
2025-03-22 20:41:00,076 - INFO - Clearing screen
2025-03-22 20:41:00,077 - INFO - Clearing screen
2025-03-22 20:41:02,791 - INFO - Exiting application
2025-04-02 19:10:03,475 - DEBUG - Using selector: EpollSelector
2025-04-02 19:10:03,510 - INFO - Starting application
2025-04-02 19:10:03,511 - INFO - Clearing screen
2025-04-02 19:10:07,061 - INFO - Selected: Save files
2025-04-02 19:10:07,062 - INFO - Clearing screen
2025-04-02 19:10:10,826 - INFO - Initiating save operation for all
2025-04-02 19:10:12,354 - INFO - Using cached data for Price
2025-04-02 19:10:17,685 - INFO - Using cached data for Transfer
2025-04-02 19:10:17,689 - INFO - Using cached data for Price
2025-04-02 19:10:17,689 - INFO - Using cached data for Price
2025-04-02 19:10:18,924 - INFO - Using cached data for Price
2025-04-02 19:10:18,924 - INFO - Using cached data for Price
2025-04-02 19:10:18,926 - INFO - Using cached data for PTI
2025-04-02 19:10:18,926 - INFO - Using cached data for Price
2025-04-02 19:10:18,926 - INFO - Using cached data for Price
2025-04-02 19:10:18,928 - INFO - Using cached data for Price
2025-04-02 19:10:18,928 - INFO - Using cached data for Price
2025-04-02 19:10:18,930 - INFO - Using cached data for Transfer
2025-04-02 19:10:21,364 - INFO - Using cached data for Price
2025-04-02 19:10:21,364 - INFO - Using cached data for Price
2025-04-02 19:10:21,375 - INFO - Using cached data for ScowTransfer
2025-04-02 19:10:21,376 - INFO - Using cached data for Price
2025-04-02 19:10:21,376 - INFO - Using cached data for Price
2025-04-02 19:10:21,378 - INFO - Using cached data for CCCSReport
2025-04-02 19:10:21,380 - INFO - Using cached data for Price
2025-04-02 19:10:21,380 - INFO - Using cached data for Price
2025-04-02 19:10:21,382 - INFO - Using cached data for CCCSReport
2025-04-02 19:10:21,383 - INFO - Using cached data for Price
2025-04-02 19:10:21,383 - INFO - Using cached data for Price
2025-04-02 19:10:21,384 - INFO - Using cached data for CCCSReport
2025-04-02 19:10:21,385 - INFO - Using cached data for Price
2025-04-02 19:10:21,385 - INFO - Using cached data for Price
2025-04-02 19:10:22,082 - INFO - Using cached data for Price
2025-04-02 19:10:22,082 - INFO - Using cached data for Price
2025-04-02 19:10:22,833 - INFO - Using cached data for Transfer
2025-04-02 19:10:22,835 - INFO - Using cached data for Price
2025-04-02 19:10:22,835 - INFO - Using cached data for Price
2025-04-02 19:10:22,836 - INFO - Using cached data for CCCSReport
2025-04-02 19:10:23,623 - INFO - Using cached data for Client
2025-04-02 19:10:23,624 - INFO - Using cached data for Client
2025-04-02 19:10:23,624 - INFO - Using cached data for Client
2025-04-02 19:10:23,624 - INFO - Using cached data for Client
2025-04-02 19:10:23,625 - INFO - Using cached data for Client
2025-04-02 19:10:23,625 - INFO - Using cached data for Client
2025-04-02 19:10:23,625 - INFO - Using cached data for Client
2025-04-02 19:10:23,625 - INFO - Using cached data for Client
2025-04-02 19:10:23,626 - INFO - Using cached data for Client
2025-04-02 19:10:23,626 - INFO - Using cached data for Client
2025-04-02 19:10:23,626 - INFO - Using cached data for Client
2025-04-02 19:10:23,626 - INFO - Using cached data for Client
2025-04-02 19:10:23,627 - INFO - Using cached data for CCCSReport
2025-04-02 19:10:24,372 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-02 19:10:24,373 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-02 19:10:24,374 - INFO - Using cached data for CCCSReport
2025-04-02 19:10:24,375 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-02 19:10:24,376 - INFO - Using cached data for Price
2025-04-02 19:10:24,376 - INFO - Using cached data for Price
2025-04-02 19:10:28,307 - INFO - Using cached data for CCCSReport
2025-04-02 19:10:28,308 - INFO - Using cached data for Price
2025-04-02 19:10:28,309 - INFO - Using cached data for Price
2025-04-02 19:10:29,408 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 1 out of 54 values: [""]
2025-04-02 19:10:29,409 - INFO - Using cached data for Transfer
2025-04-02 19:10:29,416 - INFO - Using cached data for Price
2025-04-02 19:10:29,417 - INFO - Using cached data for Price
2025-04-02 19:10:29,430 - INFO - Using cached data for Transfer
2025-04-02 19:10:29,440 - INFO - Using cached data for UnloadingSummary
2025-04-02 19:10:30,430 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 1 out of 54 values: [""]
2025-04-02 19:10:30,430 - INFO - Using cached data for Transfer
2025-04-02 19:10:30,433 - INFO - Using cached data for Price
2025-04-02 19:10:30,433 - INFO - Using cached data for Price
2025-04-02 19:10:30,437 - INFO - Using cached data for Transfer
2025-04-02 19:10:30,439 - INFO - Using cached data for Price
2025-04-02 19:10:30,439 - INFO - Using cached data for Price
2025-04-02 19:10:30,440 - INFO - Using cached data for UnloadingSummary
2025-04-02 19:10:30,440 - INFO - Using cached data for RawData
2025-04-02 19:10:30,440 - INFO - Using cached data for CCCSReport
2025-04-02 19:10:30,441 - INFO - Using cached data for Price
2025-04-02 19:10:30,441 - INFO - Using cached data for Price
2025-04-02 19:10:31,369 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 1 out of 54 values: [""]
2025-04-02 19:10:31,369 - INFO - Using cached data for Transfer
2025-04-02 19:10:31,372 - INFO - Using cached data for Price
2025-04-02 19:10:31,372 - INFO - Using cached data for Price
2025-04-02 19:10:31,376 - INFO - Using cached data for Transfer
2025-04-02 19:10:31,378 - INFO - Using cached data for Price
2025-04-02 19:10:31,379 - INFO - Using cached data for Price
2025-04-02 19:10:31,379 - INFO - Using cached data for RawData
2025-04-02 19:10:31,990 - INFO - Using cached data for Price
2025-04-02 19:10:31,991 - INFO - Using cached data for Price
2025-04-02 19:10:33,243 - INFO - Using cached data for Price
2025-04-02 19:10:33,243 - INFO - Using cached data for Price
2025-04-02 19:10:33,246 - INFO - Using cached data for Client
2025-04-02 19:10:33,945 - INFO - Using cached data for Price
2025-04-02 19:10:33,945 - INFO - Using cached data for Price
2025-04-02 19:10:34,622 - INFO - Using cached data for Transfer
2025-04-02 19:10:34,624 - INFO - Using cached data for Price
2025-04-02 19:10:34,624 - INFO - Using cached data for Price
2025-04-02 19:10:35,546 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 1 out of 54 values: [""]
2025-04-02 19:10:35,546 - INFO - Using cached data for Transfer
2025-04-02 19:10:35,549 - INFO - Using cached data for Price
2025-04-02 19:10:35,549 - INFO - Using cached data for Price
2025-04-02 19:10:36,310 - INFO - Using cached data for Transfer
2025-04-02 19:10:36,310 - INFO - Using cached data for Price
2025-04-02 19:10:36,310 - INFO - Using cached data for Price
2025-04-02 19:10:36,311 - INFO - Using cached data for Transfer
2025-04-02 19:10:36,399 - INFO - Using cached data for ScowTransfer
2025-04-02 19:10:37,613 - INFO - Processing all dataframe categories concurrently
2025-04-02 19:10:37,613 - INFO - Queueing category: emr
2025-04-02 19:10:37,613 - INFO - Queueing category: operations
2025-04-02 19:10:37,613 - INFO - Queueing category: netlist
2025-04-02 19:10:37,613 - INFO - Queueing category: bin_dispatch
2025-04-02 19:10:37,614 - INFO - Queueing category: shore_handling
2025-04-02 19:10:37,614 - INFO - Queueing category: stuffing
2025-04-02 19:10:37,614 - INFO - Queueing category: transport
2025-04-02 19:10:37,614 - INFO - Queueing category: miscellaneous
2025-04-02 19:10:37,614 - INFO - Processing dataframe shifting of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:37,614 - INFO - Collecting LazyFrame for shifting
2025-04-02 19:10:37,980 - INFO - Successfully processed dataframe shifting
2025-04-02 19:10:37,981 - INFO - Writing to output/csv/shifting.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:10:37,981 - INFO - Processing dataframe washing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:37,982 - INFO - Collecting LazyFrame for washing
2025-04-02 19:10:38,047 - INFO - Successfully processed dataframe washing
2025-04-02 19:10:38,048 - INFO - Writing to output/csv/washing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:10:38,048 - INFO - Processing dataframe pti of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,048 - INFO - Collecting LazyFrame for pti
2025-04-02 19:10:38,532 - INFO - Successfully processed dataframe pti
2025-04-02 19:10:38,533 - INFO - Processing dataframe ops of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,533 - INFO - Collecting LazyFrame for ops
2025-04-02 19:10:38,533 - INFO - Writing to output/csv/pti.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:10:38,579 - ERROR - Error processing dataframe ops: invalid series dtype: expected `String`, got `time` for series with name `Time`
2025-04-02 19:10:38,579 - INFO - Processing dataframe hatch_to_hatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,579 - INFO - Collecting LazyFrame for hatch_to_hatch
2025-04-02 19:10:38,620 - INFO - Successfully processed dataframe hatch_to_hatch
2025-04-02 19:10:38,620 - INFO - Processing dataframe net_list of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,620 - INFO - Writing to output/csv/hatch_to_hatch.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:10:38,620 - INFO - Collecting LazyFrame for net_list
2025-04-02 19:10:38,621 - ERROR - Error processing dataframe net_list: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-02 19:10:38,621 - INFO - Processing dataframe iot_container_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,621 - INFO - Collecting LazyFrame for iot_container_stuffing
2025-04-02 19:10:38,622 - ERROR - Error processing dataframe iot_container_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-02 19:10:38,622 - INFO - Processing dataframe oss_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,622 - INFO - Collecting LazyFrame for oss_stuffing
2025-04-02 19:10:38,622 - ERROR - Error processing dataframe oss_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-02 19:10:38,622 - INFO - Processing dataframe full_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,622 - INFO - Collecting LazyFrame for full_scows_transfer
2025-04-02 19:10:38,720 - INFO - Successfully processed dataframe full_scows_transfer
2025-04-02 19:10:38,720 - INFO - Writing to output/csv/full_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:10:38,720 - INFO - Processing dataframe empty_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,721 - INFO - Collecting LazyFrame for empty_scows_transfer
2025-04-02 19:10:38,776 - INFO - Successfully processed dataframe empty_scows_transfer
2025-04-02 19:10:38,777 - INFO - Writing to output/csv/empty_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:10:38,777 - INFO - Processing dataframe salt of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,777 - INFO - Collecting LazyFrame for salt
2025-04-02 19:10:38,830 - INFO - Successfully processed dataframe salt
2025-04-02 19:10:38,830 - INFO - Processing dataframe bin_tipping of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,831 - INFO - Writing to output/csv/salt.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:10:38,831 - INFO - Collecting LazyFrame for bin_tipping
2025-04-02 19:10:38,853 - INFO - Successfully processed dataframe bin_tipping
2025-04-02 19:10:38,854 - INFO - Processing dataframe pallet_liner of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,855 - INFO - Collecting LazyFrame for pallet_liner
2025-04-02 19:10:38,854 - INFO - Writing to output/csv/bin_tipping.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:10:38,922 - INFO - Successfully processed dataframe pallet_liner
2025-04-02 19:10:38,922 - INFO - Writing to output/csv/pallet_liner.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:10:38,922 - INFO - Processing dataframe container_plugin of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,923 - INFO - Collecting LazyFrame for container_plugin
2025-04-02 19:10:38,923 - ERROR - Error processing dataframe container_plugin: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-02 19:10:38,923 - INFO - Processing dataframe shore_crane of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,923 - INFO - Collecting LazyFrame for shore_crane
2025-04-02 19:10:38,925 - INFO - Successfully processed dataframe shore_crane
2025-04-02 19:10:38,926 - INFO - Writing to output/csv/shore_crane.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:10:38,926 - INFO - Successfully wrote shifting to file
2025-04-02 19:10:38,927 - INFO - Successfully wrote washing to file
2025-04-02 19:10:38,927 - INFO - Successfully wrote pti to file
2025-04-02 19:10:38,927 - INFO - Successfully wrote hatch_to_hatch to file
2025-04-02 19:10:38,927 - INFO - Successfully wrote full_scows_transfer to file
2025-04-02 19:10:38,928 - INFO - Successfully wrote empty_scows_transfer to file
2025-04-02 19:10:38,928 - INFO - Successfully wrote salt to file
2025-04-02 19:10:38,928 - INFO - Successfully wrote bin_tipping to file
2025-04-02 19:10:38,928 - INFO - Successfully wrote pallet_liner to file
2025-04-02 19:10:38,929 - INFO - Processing dataframe transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,929 - INFO - Collecting LazyFrame for transfer
2025-04-02 19:10:38,996 - INFO - Successfully processed dataframe transfer
2025-04-02 19:10:38,996 - INFO - Writing to output/csv/transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:10:38,996 - INFO - Processing dataframe scow_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:38,996 - INFO - Collecting LazyFrame for scow_transfer
2025-04-02 19:10:39,000 - INFO - Successfully processed dataframe scow_transfer
2025-04-02 19:10:39,000 - INFO - Writing to output/csv/scow_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:10:39,000 - INFO - Processing dataframe forklift of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:39,000 - INFO - Collecting LazyFrame for forklift
2025-04-02 19:10:39,010 - INFO - Successfully processed dataframe forklift
2025-04-02 19:10:39,010 - INFO - Writing to output/csv/forklift.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:10:39,011 - INFO - Processing dataframe static_loader of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:39,011 - INFO - Collecting LazyFrame for static_loader
2025-04-02 19:10:39,011 - ERROR - Error processing dataframe static_loader: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("operation_type"), col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
   SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
    DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:10:39,011 - INFO - Processing dataframe dispatch_to_cargo of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:39,011 - INFO - Collecting LazyFrame for dispatch_to_cargo
2025-04-02 19:10:39,011 - ERROR - Error processing dataframe dispatch_to_cargo: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type"), col("total_tonnage").abs(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("operation_type").is_in([Series]) FROM
     SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
      DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:10:39,011 - INFO - Processing dataframe truck_to_cccs of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:39,011 - INFO - Collecting LazyFrame for truck_to_cccs
2025-04-02 19:10:39,012 - ERROR - Error processing dataframe truck_to_cccs: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("vessel"), col("total_tonnage"), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("customer").is_in([Series]) FROM
    FILTER col("operation_type").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:10:39,012 - INFO - Processing dataframe cross_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:39,012 - INFO - Collecting LazyFrame for cross_stuffing
2025-04-02 19:10:39,012 - ERROR - Error processing dataframe cross_stuffing: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("vessel_client"), col("date"), col("origin"), col("destination"), col("start_time"), col("end_time"), col("total_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("is_origin_empty"), col("service").alias("Service"), col("invoiced")] FROM
  FILTER [(col("day").str.replace([String(), String(x)])) != (String(x))] FROM
    DF ["day", "vessel_client", "date", "origin", ...]; PROJECT */26 COLUMNS
2025-04-02 19:10:39,012 - INFO - Processing dataframe cccs_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:39,012 - INFO - Collecting LazyFrame for cccs_stuffing
2025-04-02 19:10:39,020 - INFO - Successfully processed dataframe cccs_stuffing
2025-04-02 19:10:39,021 - INFO - Processing dataframe bycatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:10:39,022 - INFO - Collecting LazyFrame for bycatch
2025-04-02 19:10:39,022 - ERROR - Error processing dataframe bycatch: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type").str.replace([String(Sorting from Unloading), String(CCCS (By-Catch))]).str.replace([String(Unsorted from Unloading), String(CCCS (By-Catch))]), col("total_tonnage").strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).round()] FROM
  FILTER col("operation_type").is_in([Series]) FROM
    FILTER col("customer").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:10:39,022 - INFO - Successfully wrote shore_crane to file
2025-04-02 19:10:39,022 - INFO - Writing to output/csv/cccs_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:10:39,022 - INFO - Successfully wrote scow_transfer to file
2025-04-02 19:10:39,023 - INFO - Successfully wrote transfer to file
2025-04-02 19:10:39,023 - INFO - Successfully wrote forklift to file
2025-04-02 19:10:39,024 - INFO - Successfully wrote cccs_stuffing to file
2025-04-02 19:10:39,025 - INFO - Successfully saved shifting
2025-04-02 19:10:39,025 - INFO - Successfully saved washing
2025-04-02 19:10:39,025 - INFO - Successfully saved pti
2025-04-02 19:10:39,026 - ERROR - Error saving ops: invalid series dtype: expected `String`, got `time` for series with name `Time`
2025-04-02 19:10:39,026 - INFO - Successfully saved hatch_to_hatch
2025-04-02 19:10:39,026 - ERROR - Error saving net_list: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-02 19:10:39,026 - ERROR - Error saving iot_container_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-02 19:10:39,026 - ERROR - Error saving oss_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-02 19:10:39,026 - INFO - Successfully saved full_scows_transfer
2025-04-02 19:10:39,027 - INFO - Successfully saved empty_scows_transfer
2025-04-02 19:10:39,027 - INFO - Successfully saved salt
2025-04-02 19:10:39,027 - INFO - Successfully saved bin_tipping
2025-04-02 19:10:39,027 - INFO - Successfully saved pallet_liner
2025-04-02 19:10:39,027 - ERROR - Error saving container_plugin: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-02 19:10:39,028 - INFO - Successfully saved shore_crane
2025-04-02 19:10:39,028 - INFO - Successfully saved transfer
2025-04-02 19:10:39,028 - INFO - Successfully saved scow_transfer
2025-04-02 19:10:39,029 - INFO - Successfully saved forklift
2025-04-02 19:10:39,029 - ERROR - Error saving static_loader: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("operation_type"), col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
   SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
    DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:10:39,029 - ERROR - Error saving dispatch_to_cargo: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type"), col("total_tonnage").abs(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("operation_type").is_in([Series]) FROM
     SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
      DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:10:39,030 - ERROR - Error saving truck_to_cccs: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("vessel"), col("total_tonnage"), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("customer").is_in([Series]) FROM
    FILTER col("operation_type").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:10:39,030 - ERROR - Error saving cross_stuffing: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("vessel_client"), col("date"), col("origin"), col("destination"), col("start_time"), col("end_time"), col("total_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("is_origin_empty"), col("service").alias("Service"), col("invoiced")] FROM
  FILTER [(col("day").str.replace([String(), String(x)])) != (String(x))] FROM
    DF ["day", "vessel_client", "date", "origin", ...]; PROJECT */26 COLUMNS
2025-04-02 19:10:39,030 - INFO - Successfully saved cccs_stuffing
2025-04-02 19:10:39,031 - ERROR - Error saving bycatch: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type").str.replace([String(Sorting from Unloading), String(CCCS (By-Catch))]).str.replace([String(Unsorted from Unloading), String(CCCS (By-Catch))]), col("total_tonnage").strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).round()] FROM
  FILTER col("operation_type").is_in([Series]) FROM
    FILTER col("customer").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:10:39,031 - INFO - Save completed
2025-04-02 19:10:39,031 - INFO - Successfully saved: 14 files
2025-04-02 19:10:39,031 - ERROR - Failed to save: 10 files
2025-04-02 19:10:39,031 - ERROR -   - ops: invalid series dtype: expected `String`, got `time` for series with name `Time`
2025-04-02 19:10:39,031 - ERROR -   - net_list: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-02 19:10:39,031 - ERROR -   - iot_container_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-02 19:10:39,031 - ERROR -   - oss_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-02 19:10:39,031 - ERROR -   - container_plugin: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-02 19:10:39,031 - ERROR -   - static_loader: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("operation_type"), col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
   SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
    DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:10:39,032 - ERROR -   - dispatch_to_cargo: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type"), col("total_tonnage").abs(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("operation_type").is_in([Series]) FROM
     SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
      DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:10:39,032 - ERROR -   - truck_to_cccs: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("vessel"), col("total_tonnage"), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("customer").is_in([Series]) FROM
    FILTER col("operation_type").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:10:39,032 - ERROR -   - cross_stuffing: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("vessel_client"), col("date"), col("origin"), col("destination"), col("start_time"), col("end_time"), col("total_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("is_origin_empty"), col("service").alias("Service"), col("invoiced")] FROM
  FILTER [(col("day").str.replace([String(), String(x)])) != (String(x))] FROM
    DF ["day", "vessel_client", "date", "origin", ...]; PROJECT */26 COLUMNS
2025-04-02 19:10:39,032 - ERROR -   - bycatch: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type").str.replace([String(Sorting from Unloading), String(CCCS (By-Catch))]).str.replace([String(Unsorted from Unloading), String(CCCS (By-Catch))]), col("total_tonnage").strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).round()] FROM
  FILTER col("operation_type").is_in([Series]) FROM
    FILTER col("customer").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:47:12,022 - INFO - Starting application
2025-04-02 19:47:12,080 - INFO - Clearing screen
2025-04-02 19:47:14,621 - INFO - Exiting application
2025-04-02 19:47:27,466 - DEBUG - Using selector: EpollSelector
2025-04-02 19:47:27,467 - INFO - Starting application
2025-04-02 19:47:27,467 - INFO - Clearing screen
2025-04-02 19:47:30,746 - INFO - Selected: Save files
2025-04-02 19:47:30,747 - INFO - Clearing screen
2025-04-02 19:47:36,536 - INFO - Initiating save operation for all
2025-04-02 19:47:37,737 - INFO - Using cached data for Price
2025-04-02 19:47:42,147 - INFO - Using cached data for Transfer
2025-04-02 19:47:42,149 - INFO - Using cached data for Price
2025-04-02 19:47:42,149 - INFO - Using cached data for Price
2025-04-02 19:47:43,252 - INFO - Using cached data for Price
2025-04-02 19:47:43,252 - INFO - Using cached data for Price
2025-04-02 19:47:43,255 - INFO - Using cached data for PTI
2025-04-02 19:47:43,255 - INFO - Using cached data for Price
2025-04-02 19:47:43,255 - INFO - Using cached data for Price
2025-04-02 19:47:43,256 - INFO - Using cached data for Price
2025-04-02 19:47:43,257 - INFO - Using cached data for Price
2025-04-02 19:47:43,258 - INFO - Using cached data for Transfer
2025-04-02 19:47:45,098 - INFO - Using cached data for Price
2025-04-02 19:47:45,098 - INFO - Using cached data for Price
2025-04-02 19:47:45,099 - INFO - Using cached data for ScowTransfer
2025-04-02 19:47:45,100 - INFO - Using cached data for Price
2025-04-02 19:47:45,100 - INFO - Using cached data for Price
2025-04-02 19:47:45,100 - INFO - Using cached data for CCCSReport
2025-04-02 19:47:45,101 - INFO - Using cached data for Price
2025-04-02 19:47:45,101 - INFO - Using cached data for Price
2025-04-02 19:47:45,101 - INFO - Using cached data for CCCSReport
2025-04-02 19:47:45,102 - INFO - Using cached data for Price
2025-04-02 19:47:45,102 - INFO - Using cached data for Price
2025-04-02 19:47:45,103 - INFO - Using cached data for CCCSReport
2025-04-02 19:47:45,103 - INFO - Using cached data for Price
2025-04-02 19:47:45,103 - INFO - Using cached data for Price
2025-04-02 19:47:45,792 - INFO - Using cached data for Price
2025-04-02 19:47:45,793 - INFO - Using cached data for Price
2025-04-02 19:47:46,526 - INFO - Using cached data for Transfer
2025-04-02 19:47:46,528 - INFO - Using cached data for Price
2025-04-02 19:47:46,528 - INFO - Using cached data for Price
2025-04-02 19:47:46,529 - INFO - Using cached data for CCCSReport
2025-04-02 19:47:47,241 - INFO - Using cached data for Client
2025-04-02 19:47:47,242 - INFO - Using cached data for Client
2025-04-02 19:47:47,242 - INFO - Using cached data for Client
2025-04-02 19:47:47,242 - INFO - Using cached data for Client
2025-04-02 19:47:47,243 - INFO - Using cached data for Client
2025-04-02 19:47:47,243 - INFO - Using cached data for Client
2025-04-02 19:47:47,243 - INFO - Using cached data for Client
2025-04-02 19:47:47,243 - INFO - Using cached data for Client
2025-04-02 19:47:47,244 - INFO - Using cached data for Client
2025-04-02 19:47:47,244 - INFO - Using cached data for Client
2025-04-02 19:47:47,244 - INFO - Using cached data for Client
2025-04-02 19:47:47,244 - INFO - Using cached data for Client
2025-04-02 19:47:47,245 - INFO - Using cached data for CCCSReport
2025-04-02 19:47:47,859 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-02 19:47:47,860 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-02 19:47:47,861 - INFO - Using cached data for CCCSReport
2025-04-02 19:47:47,861 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-02 19:47:47,862 - INFO - Using cached data for Price
2025-04-02 19:47:47,862 - INFO - Using cached data for Price
2025-04-02 19:47:50,526 - INFO - Using cached data for CCCSReport
2025-04-02 19:47:50,527 - INFO - Using cached data for Price
2025-04-02 19:47:50,527 - INFO - Using cached data for Price
2025-04-02 19:47:51,489 - INFO - Using cached data for Transfer
2025-04-02 19:47:51,492 - INFO - Using cached data for Price
2025-04-02 19:47:51,492 - INFO - Using cached data for Price
2025-04-02 19:47:51,496 - INFO - Using cached data for Transfer
2025-04-02 19:47:51,498 - INFO - Using cached data for UnloadingSummary
2025-04-02 19:47:51,498 - INFO - Using cached data for containerOperations
2025-04-02 19:47:51,498 - INFO - Using cached data for Transfer
2025-04-02 19:47:51,500 - INFO - Using cached data for Price
2025-04-02 19:47:51,501 - INFO - Using cached data for Price
2025-04-02 19:47:51,506 - INFO - Using cached data for Transfer
2025-04-02 19:47:51,508 - INFO - Using cached data for Price
2025-04-02 19:47:51,509 - INFO - Using cached data for Price
2025-04-02 19:47:51,510 - INFO - Using cached data for UnloadingSummary
2025-04-02 19:47:51,510 - INFO - Using cached data for RawData
2025-04-02 19:47:51,511 - INFO - Using cached data for CCCSReport
2025-04-02 19:47:51,512 - INFO - Using cached data for Price
2025-04-02 19:47:51,512 - INFO - Using cached data for Price
2025-04-02 19:47:51,512 - INFO - Using cached data for containerOperations
2025-04-02 19:47:51,513 - INFO - Using cached data for Transfer
2025-04-02 19:47:51,516 - INFO - Using cached data for Price
2025-04-02 19:47:51,518 - INFO - Using cached data for Price
2025-04-02 19:47:51,524 - INFO - Using cached data for Transfer
2025-04-02 19:47:51,526 - INFO - Using cached data for Price
2025-04-02 19:47:51,526 - INFO - Using cached data for Price
2025-04-02 19:47:51,527 - INFO - Using cached data for RawData
2025-04-02 19:47:52,324 - INFO - Using cached data for Price
2025-04-02 19:47:52,324 - INFO - Using cached data for Price
2025-04-02 19:47:53,457 - INFO - Using cached data for Price
2025-04-02 19:47:53,458 - INFO - Using cached data for Price
2025-04-02 19:47:53,459 - INFO - Using cached data for Client
2025-04-02 19:47:54,377 - INFO - Using cached data for Price
2025-04-02 19:47:54,377 - INFO - Using cached data for Price
2025-04-02 19:47:55,022 - INFO - Using cached data for Transfer
2025-04-02 19:47:55,024 - INFO - Using cached data for Price
2025-04-02 19:47:55,024 - INFO - Using cached data for Price
2025-04-02 19:47:55,027 - INFO - Using cached data for containerOperations
2025-04-02 19:47:55,027 - INFO - Using cached data for Transfer
2025-04-02 19:47:55,030 - INFO - Using cached data for Price
2025-04-02 19:47:55,030 - INFO - Using cached data for Price
2025-04-02 19:47:55,781 - INFO - Using cached data for Transfer
2025-04-02 19:47:55,781 - INFO - Using cached data for Price
2025-04-02 19:47:55,781 - INFO - Using cached data for Price
2025-04-02 19:47:55,781 - INFO - Using cached data for Transfer
2025-04-02 19:47:55,785 - INFO - Using cached data for ScowTransfer
2025-04-02 19:47:56,989 - INFO - Processing all dataframe categories concurrently
2025-04-02 19:47:56,990 - INFO - Queueing category: emr
2025-04-02 19:47:56,990 - INFO - Queueing category: operations
2025-04-02 19:47:56,990 - INFO - Queueing category: netlist
2025-04-02 19:47:56,990 - INFO - Queueing category: bin_dispatch
2025-04-02 19:47:56,990 - INFO - Queueing category: shore_handling
2025-04-02 19:47:56,990 - INFO - Queueing category: stuffing
2025-04-02 19:47:56,990 - INFO - Queueing category: transport
2025-04-02 19:47:56,990 - INFO - Queueing category: miscellaneous
2025-04-02 19:47:56,990 - INFO - Processing dataframe shifting of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:56,990 - INFO - Collecting LazyFrame for shifting
2025-04-02 19:47:57,162 - INFO - Successfully processed dataframe shifting
2025-04-02 19:47:57,163 - INFO - Writing to output/csv/shifting.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:47:57,164 - INFO - Processing dataframe washing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,165 - INFO - Collecting LazyFrame for washing
2025-04-02 19:47:57,257 - INFO - Successfully processed dataframe washing
2025-04-02 19:47:57,258 - INFO - Writing to output/csv/washing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:47:57,258 - INFO - Processing dataframe pti of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,258 - INFO - Collecting LazyFrame for pti
2025-04-02 19:47:57,381 - INFO - Successfully processed dataframe pti
2025-04-02 19:47:57,382 - INFO - Processing dataframe ops of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,382 - INFO - Writing to output/csv/pti.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:47:57,382 - INFO - Collecting LazyFrame for ops
2025-04-02 19:47:57,387 - ERROR - Error processing dataframe ops: invalid series dtype: expected `String`, got `time` for series with name `Time`
2025-04-02 19:47:57,387 - INFO - Processing dataframe hatch_to_hatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,387 - INFO - Collecting LazyFrame for hatch_to_hatch
2025-04-02 19:47:57,449 - INFO - Successfully processed dataframe hatch_to_hatch
2025-04-02 19:47:57,449 - INFO - Writing to output/csv/hatch_to_hatch.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:47:57,450 - INFO - Processing dataframe net_list of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,450 - INFO - Collecting LazyFrame for net_list
2025-04-02 19:47:57,529 - ERROR - Error processing dataframe net_list: conversion from `str` to `enum` failed in column 'customer' for 54 out of 54 values: ["MAERSKLINE", "MAERSKLINE", … "MAERSKLINE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-02 19:47:57,529 - INFO - Processing dataframe iot_container_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,530 - INFO - Collecting LazyFrame for iot_container_stuffing
2025-04-02 19:47:57,551 - ERROR - Error processing dataframe iot_container_stuffing: conversion from `str` to `enum` failed in column 'customer' for 27 out of 27 values: ["IOT", "IOT", … "MAERSKLINE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-02 19:47:57,551 - INFO - Processing dataframe oss_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,552 - INFO - Collecting LazyFrame for oss_stuffing
2025-04-02 19:47:57,570 - ERROR - Error processing dataframe oss_stuffing: conversion from `str` to `enum` failed in column 'customer' for 56 out of 56 values: ["IOT EXPORT", "IOT EXPORT", … "MAERSKLINE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-02 19:47:57,571 - INFO - Processing dataframe full_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,571 - INFO - Collecting LazyFrame for full_scows_transfer
2025-04-02 19:47:57,595 - INFO - Successfully processed dataframe full_scows_transfer
2025-04-02 19:47:57,596 - INFO - Writing to output/csv/full_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:47:57,596 - INFO - Processing dataframe empty_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,597 - INFO - Collecting LazyFrame for empty_scows_transfer
2025-04-02 19:47:57,608 - INFO - Successfully processed dataframe empty_scows_transfer
2025-04-02 19:47:57,609 - INFO - Writing to output/csv/empty_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:47:57,609 - INFO - Processing dataframe salt of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,609 - INFO - Collecting LazyFrame for salt
2025-04-02 19:47:57,633 - INFO - Successfully processed dataframe salt
2025-04-02 19:47:57,634 - INFO - Writing to output/csv/salt.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:47:57,634 - INFO - Processing dataframe bin_tipping of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,634 - INFO - Collecting LazyFrame for bin_tipping
2025-04-02 19:47:57,636 - INFO - Successfully processed dataframe bin_tipping
2025-04-02 19:47:57,637 - INFO - Processing dataframe pallet_liner of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,637 - INFO - Writing to output/csv/bin_tipping.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:47:57,637 - INFO - Collecting LazyFrame for pallet_liner
2025-04-02 19:47:57,646 - INFO - Successfully processed dataframe pallet_liner
2025-04-02 19:47:57,647 - INFO - Processing dataframe container_plugin of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,647 - INFO - Collecting LazyFrame for container_plugin
2025-04-02 19:47:57,647 - INFO - Writing to output/csv/pallet_liner.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:47:57,649 - ERROR - Error processing dataframe container_plugin: conversion from `str` to `enum` failed in column 'customer' for 54 out of 54 values: ["MAERSKLINE", "MAERSKLINE", … "MAERSKLINE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-02 19:47:57,649 - INFO - Processing dataframe shore_crane of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,649 - INFO - Collecting LazyFrame for shore_crane
2025-04-02 19:47:57,650 - INFO - Successfully processed dataframe shore_crane
2025-04-02 19:47:57,650 - INFO - Writing to output/csv/shore_crane.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:47:57,650 - INFO - Successfully wrote shifting to file
2025-04-02 19:47:57,651 - INFO - Successfully wrote washing to file
2025-04-02 19:47:57,651 - INFO - Successfully wrote pti to file
2025-04-02 19:47:57,651 - INFO - Successfully wrote hatch_to_hatch to file
2025-04-02 19:47:57,651 - INFO - Successfully wrote full_scows_transfer to file
2025-04-02 19:47:57,651 - INFO - Successfully wrote empty_scows_transfer to file
2025-04-02 19:47:57,651 - INFO - Successfully wrote salt to file
2025-04-02 19:47:57,651 - INFO - Successfully wrote bin_tipping to file
2025-04-02 19:47:57,651 - INFO - Successfully wrote pallet_liner to file
2025-04-02 19:47:57,652 - INFO - Processing dataframe transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,652 - INFO - Collecting LazyFrame for transfer
2025-04-02 19:47:57,731 - INFO - Successfully processed dataframe transfer
2025-04-02 19:47:57,731 - INFO - Processing dataframe scow_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,731 - INFO - Collecting LazyFrame for scow_transfer
2025-04-02 19:47:57,732 - INFO - Writing to output/csv/transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:47:57,742 - INFO - Successfully processed dataframe scow_transfer
2025-04-02 19:47:57,742 - INFO - Writing to output/csv/scow_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:47:57,743 - INFO - Processing dataframe forklift of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,743 - INFO - Collecting LazyFrame for forklift
2025-04-02 19:47:57,756 - INFO - Successfully processed dataframe forklift
2025-04-02 19:47:57,756 - INFO - Writing to output/csv/forklift.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:47:57,756 - INFO - Processing dataframe static_loader of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,756 - INFO - Collecting LazyFrame for static_loader
2025-04-02 19:47:57,785 - ERROR - Error processing dataframe static_loader: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("operation_type"), col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
   SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
    DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:47:57,786 - INFO - Processing dataframe dispatch_to_cargo of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,786 - INFO - Collecting LazyFrame for dispatch_to_cargo
2025-04-02 19:47:57,786 - ERROR - Error processing dataframe dispatch_to_cargo: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type"), col("total_tonnage").abs(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("operation_type").is_in([Series]) FROM
     SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
      DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:47:57,787 - INFO - Processing dataframe truck_to_cccs of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,787 - INFO - Collecting LazyFrame for truck_to_cccs
2025-04-02 19:47:57,787 - ERROR - Error processing dataframe truck_to_cccs: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("vessel"), col("total_tonnage"), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("customer").is_in([Series]) FROM
    FILTER col("operation_type").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:47:57,787 - INFO - Processing dataframe cross_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,787 - INFO - Collecting LazyFrame for cross_stuffing
2025-04-02 19:47:57,787 - ERROR - Error processing dataframe cross_stuffing: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("vessel_client"), col("date"), col("origin"), col("destination"), col("start_time"), col("end_time"), col("total_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("is_origin_empty"), col("service").alias("Service"), col("invoiced")] FROM
  FILTER [(col("day").str.replace([String(), String(x)])) != (String(x))] FROM
    DF ["day", "vessel_client", "date", "origin", ...]; PROJECT */26 COLUMNS
2025-04-02 19:47:57,787 - INFO - Processing dataframe cccs_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,787 - INFO - Collecting LazyFrame for cccs_stuffing
2025-04-02 19:47:57,797 - INFO - Successfully processed dataframe cccs_stuffing
2025-04-02 19:47:57,797 - INFO - Processing dataframe bycatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:47:57,797 - INFO - Collecting LazyFrame for bycatch
2025-04-02 19:47:57,797 - INFO - Writing to output/csv/cccs_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:47:57,798 - ERROR - Error processing dataframe bycatch: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type").str.replace([String(Sorting from Unloading), String(CCCS (By-Catch))]).str.replace([String(Unsorted from Unloading), String(CCCS (By-Catch))]), col("total_tonnage").strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).round()] FROM
  FILTER col("operation_type").is_in([Series]) FROM
    FILTER col("customer").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:47:57,798 - INFO - Successfully wrote shore_crane to file
2025-04-02 19:47:57,798 - INFO - Successfully wrote transfer to file
2025-04-02 19:47:57,798 - INFO - Successfully wrote scow_transfer to file
2025-04-02 19:47:57,798 - INFO - Successfully wrote forklift to file
2025-04-02 19:47:57,799 - INFO - Successfully wrote cccs_stuffing to file
2025-04-02 19:47:57,799 - INFO - Successfully saved shifting
2025-04-02 19:47:57,800 - INFO - Successfully saved washing
2025-04-02 19:47:57,800 - INFO - Successfully saved pti
2025-04-02 19:47:57,800 - ERROR - Error saving ops: invalid series dtype: expected `String`, got `time` for series with name `Time`
2025-04-02 19:47:57,800 - INFO - Successfully saved hatch_to_hatch
2025-04-02 19:47:57,800 - ERROR - Error saving net_list: conversion from `str` to `enum` failed in column 'customer' for 54 out of 54 values: ["MAERSKLINE", "MAERSKLINE", … "MAERSKLINE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-02 19:47:57,800 - ERROR - Error saving iot_container_stuffing: conversion from `str` to `enum` failed in column 'customer' for 27 out of 27 values: ["IOT", "IOT", … "MAERSKLINE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-02 19:47:57,800 - ERROR - Error saving oss_stuffing: conversion from `str` to `enum` failed in column 'customer' for 56 out of 56 values: ["IOT EXPORT", "IOT EXPORT", … "MAERSKLINE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-02 19:47:57,800 - INFO - Successfully saved full_scows_transfer
2025-04-02 19:47:57,800 - INFO - Successfully saved empty_scows_transfer
2025-04-02 19:47:57,800 - INFO - Successfully saved salt
2025-04-02 19:47:57,800 - INFO - Successfully saved bin_tipping
2025-04-02 19:47:57,800 - INFO - Successfully saved pallet_liner
2025-04-02 19:47:57,800 - ERROR - Error saving container_plugin: conversion from `str` to `enum` failed in column 'customer' for 54 out of 54 values: ["MAERSKLINE", "MAERSKLINE", … "MAERSKLINE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-02 19:47:57,800 - INFO - Successfully saved shore_crane
2025-04-02 19:47:57,800 - INFO - Successfully saved transfer
2025-04-02 19:47:57,800 - INFO - Successfully saved scow_transfer
2025-04-02 19:47:57,800 - INFO - Successfully saved forklift
2025-04-02 19:47:57,800 - ERROR - Error saving static_loader: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("operation_type"), col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
   SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
    DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:47:57,800 - ERROR - Error saving dispatch_to_cargo: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type"), col("total_tonnage").abs(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("operation_type").is_in([Series]) FROM
     SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
      DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:47:57,800 - ERROR - Error saving truck_to_cccs: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("vessel"), col("total_tonnage"), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("customer").is_in([Series]) FROM
    FILTER col("operation_type").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:47:57,801 - ERROR - Error saving cross_stuffing: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("vessel_client"), col("date"), col("origin"), col("destination"), col("start_time"), col("end_time"), col("total_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("is_origin_empty"), col("service").alias("Service"), col("invoiced")] FROM
  FILTER [(col("day").str.replace([String(), String(x)])) != (String(x))] FROM
    DF ["day", "vessel_client", "date", "origin", ...]; PROJECT */26 COLUMNS
2025-04-02 19:47:57,801 - INFO - Successfully saved cccs_stuffing
2025-04-02 19:47:57,801 - ERROR - Error saving bycatch: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type").str.replace([String(Sorting from Unloading), String(CCCS (By-Catch))]).str.replace([String(Unsorted from Unloading), String(CCCS (By-Catch))]), col("total_tonnage").strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).round()] FROM
  FILTER col("operation_type").is_in([Series]) FROM
    FILTER col("customer").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:47:57,801 - INFO - Save completed
2025-04-02 19:47:57,801 - INFO - Successfully saved: 14 files
2025-04-02 19:47:57,801 - ERROR - Failed to save: 10 files
2025-04-02 19:47:57,801 - ERROR -   - ops: invalid series dtype: expected `String`, got `time` for series with name `Time`
2025-04-02 19:47:57,801 - ERROR -   - net_list: conversion from `str` to `enum` failed in column 'customer' for 54 out of 54 values: ["MAERSKLINE", "MAERSKLINE", … "MAERSKLINE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-02 19:47:57,801 - ERROR -   - iot_container_stuffing: conversion from `str` to `enum` failed in column 'customer' for 27 out of 27 values: ["IOT", "IOT", … "MAERSKLINE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-02 19:47:57,801 - ERROR -   - oss_stuffing: conversion from `str` to `enum` failed in column 'customer' for 56 out of 56 values: ["IOT EXPORT", "IOT EXPORT", … "MAERSKLINE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-02 19:47:57,801 - ERROR -   - container_plugin: conversion from `str` to `enum` failed in column 'customer' for 54 out of 54 values: ["MAERSKLINE", "MAERSKLINE", … "MAERSKLINE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-02 19:47:57,801 - ERROR -   - static_loader: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("operation_type"), col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
   SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
    DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:47:57,801 - ERROR -   - dispatch_to_cargo: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type"), col("total_tonnage").abs(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("operation_type").is_in([Series]) FROM
     SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
      DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:47:57,801 - ERROR -   - truck_to_cccs: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("vessel"), col("total_tonnage"), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("customer").is_in([Series]) FROM
    FILTER col("operation_type").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:47:57,801 - ERROR -   - cross_stuffing: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("vessel_client"), col("date"), col("origin"), col("destination"), col("start_time"), col("end_time"), col("total_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("is_origin_empty"), col("service").alias("Service"), col("invoiced")] FROM
  FILTER [(col("day").str.replace([String(), String(x)])) != (String(x))] FROM
    DF ["day", "vessel_client", "date", "origin", ...]; PROJECT */26 COLUMNS
2025-04-02 19:47:57,801 - ERROR -   - bycatch: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type").str.replace([String(Sorting from Unloading), String(CCCS (By-Catch))]).str.replace([String(Unsorted from Unloading), String(CCCS (By-Catch))]), col("total_tonnage").strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).round()] FROM
  FILTER col("operation_type").is_in([Series]) FROM
    FILTER col("customer").is_in([Series]) FROM
       SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in").str.replace([String(), String(0)]).strict_cast(Int64), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-02 19:48:34,514 - INFO - Exiting application
2025-04-02 19:48:38,004 - DEBUG - Using selector: EpollSelector
2025-04-02 19:48:38,004 - INFO - Starting application
2025-04-02 19:48:38,004 - INFO - Clearing screen
2025-04-02 19:48:42,314 - INFO - Selected: Save files
2025-04-02 19:48:42,314 - INFO - Clearing screen
2025-04-02 19:48:45,822 - INFO - Initiating save operation for emr
2025-04-02 19:48:46,606 - INFO - Using cached data for Price
2025-04-02 19:48:49,810 - INFO - Using cached data for Transfer
2025-04-02 19:48:49,814 - INFO - Using cached data for Price
2025-04-02 19:48:49,814 - INFO - Using cached data for Price
2025-04-02 19:48:50,845 - INFO - Using cached data for Price
2025-04-02 19:48:50,845 - INFO - Using cached data for Price
2025-04-02 19:48:50,848 - INFO - Using cached data for PTI
2025-04-02 19:48:50,848 - INFO - Using cached data for Price
2025-04-02 19:48:50,848 - INFO - Using cached data for Price
2025-04-02 19:48:50,850 - INFO - Using cached data for Price
2025-04-02 19:48:50,850 - INFO - Using cached data for Price
2025-04-02 19:48:50,852 - INFO - Using cached data for Transfer
2025-04-02 19:48:52,838 - INFO - Using cached data for Price
2025-04-02 19:48:52,838 - INFO - Using cached data for Price
2025-04-02 19:48:52,840 - INFO - Using cached data for ScowTransfer
2025-04-02 19:48:52,840 - INFO - Using cached data for Price
2025-04-02 19:48:52,840 - INFO - Using cached data for Price
2025-04-02 19:48:52,841 - INFO - Using cached data for CCCSReport
2025-04-02 19:48:52,841 - INFO - Using cached data for Price
2025-04-02 19:48:52,841 - INFO - Using cached data for Price
2025-04-02 19:48:52,842 - INFO - Using cached data for CCCSReport
2025-04-02 19:48:52,843 - INFO - Using cached data for Price
2025-04-02 19:48:52,843 - INFO - Using cached data for Price
2025-04-02 19:48:52,844 - INFO - Using cached data for CCCSReport
2025-04-02 19:48:52,844 - INFO - Using cached data for Price
2025-04-02 19:48:52,844 - INFO - Using cached data for Price
2025-04-02 19:48:53,484 - INFO - Using cached data for Price
2025-04-02 19:48:53,485 - INFO - Using cached data for Price
2025-04-02 19:48:54,115 - INFO - Using cached data for Transfer
2025-04-02 19:48:54,120 - INFO - Using cached data for Price
2025-04-02 19:48:54,120 - INFO - Using cached data for Price
2025-04-02 19:48:54,121 - INFO - Using cached data for CCCSReport
2025-04-02 19:48:54,815 - INFO - Using cached data for Client
2025-04-02 19:48:54,815 - INFO - Using cached data for Client
2025-04-02 19:48:54,816 - INFO - Using cached data for Client
2025-04-02 19:48:54,816 - INFO - Using cached data for Client
2025-04-02 19:48:54,816 - INFO - Using cached data for Client
2025-04-02 19:48:54,816 - INFO - Using cached data for Client
2025-04-02 19:48:54,817 - INFO - Using cached data for Client
2025-04-02 19:48:54,817 - INFO - Using cached data for Client
2025-04-02 19:48:54,817 - INFO - Using cached data for Client
2025-04-02 19:48:54,817 - INFO - Using cached data for Client
2025-04-02 19:48:54,818 - INFO - Using cached data for Client
2025-04-02 19:48:54,818 - INFO - Using cached data for Client
2025-04-02 19:48:54,818 - INFO - Using cached data for CCCSReport
2025-04-02 19:48:55,540 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-02 19:48:55,541 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-02 19:48:55,542 - INFO - Using cached data for CCCSReport
2025-04-02 19:48:55,542 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-02 19:48:55,543 - INFO - Using cached data for Price
2025-04-02 19:48:55,543 - INFO - Using cached data for Price
2025-04-02 19:48:58,263 - INFO - Using cached data for CCCSReport
2025-04-02 19:48:58,264 - INFO - Using cached data for Price
2025-04-02 19:48:58,264 - INFO - Using cached data for Price
2025-04-02 19:48:59,183 - INFO - Using cached data for Transfer
2025-04-02 19:48:59,186 - INFO - Using cached data for Price
2025-04-02 19:48:59,186 - INFO - Using cached data for Price
2025-04-02 19:48:59,189 - INFO - Using cached data for Transfer
2025-04-02 19:48:59,190 - INFO - Using cached data for UnloadingSummary
2025-04-02 19:48:59,191 - INFO - Using cached data for containerOperations
2025-04-02 19:48:59,191 - INFO - Using cached data for Transfer
2025-04-02 19:48:59,193 - INFO - Using cached data for Price
2025-04-02 19:48:59,193 - INFO - Using cached data for Price
2025-04-02 19:48:59,206 - INFO - Using cached data for Transfer
2025-04-02 19:48:59,209 - INFO - Using cached data for Price
2025-04-02 19:48:59,209 - INFO - Using cached data for Price
2025-04-02 19:48:59,210 - INFO - Using cached data for UnloadingSummary
2025-04-02 19:48:59,210 - INFO - Using cached data for RawData
2025-04-02 19:48:59,210 - INFO - Using cached data for CCCSReport
2025-04-02 19:48:59,212 - INFO - Using cached data for Price
2025-04-02 19:48:59,212 - INFO - Using cached data for Price
2025-04-02 19:48:59,212 - INFO - Using cached data for containerOperations
2025-04-02 19:48:59,212 - INFO - Using cached data for Transfer
2025-04-02 19:48:59,215 - INFO - Using cached data for Price
2025-04-02 19:48:59,215 - INFO - Using cached data for Price
2025-04-02 19:48:59,219 - INFO - Using cached data for Transfer
2025-04-02 19:48:59,221 - INFO - Using cached data for Price
2025-04-02 19:48:59,221 - INFO - Using cached data for Price
2025-04-02 19:48:59,222 - INFO - Using cached data for RawData
2025-04-02 19:48:59,911 - INFO - Using cached data for Price
2025-04-02 19:48:59,911 - INFO - Using cached data for Price
2025-04-02 19:49:00,617 - INFO - Using cached data for Price
2025-04-02 19:49:00,617 - INFO - Using cached data for Price
2025-04-02 19:49:00,618 - INFO - Using cached data for Client
2025-04-02 19:49:01,252 - INFO - Using cached data for Price
2025-04-02 19:49:01,253 - INFO - Using cached data for Price
2025-04-02 19:49:01,994 - INFO - Using cached data for Transfer
2025-04-02 19:49:01,996 - INFO - Using cached data for Price
2025-04-02 19:49:01,996 - INFO - Using cached data for Price
2025-04-02 19:49:01,998 - INFO - Using cached data for containerOperations
2025-04-02 19:49:01,998 - INFO - Using cached data for Transfer
2025-04-02 19:49:02,000 - INFO - Using cached data for Price
2025-04-02 19:49:02,000 - INFO - Using cached data for Price
2025-04-02 19:49:02,626 - INFO - Using cached data for Transfer
2025-04-02 19:49:02,626 - INFO - Using cached data for Price
2025-04-02 19:49:02,626 - INFO - Using cached data for Price
2025-04-02 19:49:02,628 - INFO - Using cached data for Transfer
2025-04-02 19:49:02,634 - INFO - Using cached data for ScowTransfer
2025-04-02 19:49:03,878 - INFO - Processing dataframe category: emr
2025-04-02 19:49:03,878 - INFO - Processing dataframes: ['shifting', 'washing', 'pti']
2025-04-02 19:49:03,878 - INFO - Processing dataframe shifting of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:49:03,878 - INFO - Collecting LazyFrame for shifting
2025-04-02 19:49:03,883 - INFO - Successfully processed dataframe shifting
2025-04-02 19:49:03,883 - INFO - Writing to output/csv/shifting.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:49:03,883 - INFO - Processing dataframe washing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:49:03,884 - INFO - Collecting LazyFrame for washing
2025-04-02 19:49:03,914 - INFO - Successfully processed dataframe washing
2025-04-02 19:49:03,914 - INFO - Writing to output/csv/washing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:49:03,914 - INFO - Processing dataframe pti of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:49:03,915 - INFO - Collecting LazyFrame for pti
2025-04-02 19:49:03,936 - INFO - Successfully processed dataframe pti
2025-04-02 19:49:03,937 - INFO - Writing to output/csv/pti.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:49:03,937 - INFO - Successfully wrote shifting to file
2025-04-02 19:49:03,938 - INFO - Successfully wrote washing to file
2025-04-02 19:49:03,946 - INFO - Successfully wrote pti to file
2025-04-02 19:49:03,946 - INFO - Successfully saved shifting
2025-04-02 19:49:03,946 - INFO - Successfully saved washing
2025-04-02 19:49:03,946 - INFO - Successfully saved pti
2025-04-02 19:49:03,946 - INFO - Save completed
2025-04-02 19:49:03,946 - INFO - Successfully saved: shifting, washing, pti
2025-04-02 19:49:42,989 - INFO - Starting application
2025-04-02 19:49:42,989 - INFO - Clearing screen
2025-04-02 19:49:44,670 - INFO - Selected: Save files
2025-04-02 19:49:44,671 - INFO - Clearing screen
2025-04-02 19:49:50,611 - INFO - Initiating save operation for operations
2025-04-02 19:49:50,611 - INFO - Using cached data for Price
2025-04-02 19:49:50,612 - INFO - Using cached data for Price
2025-04-02 19:49:50,620 - INFO - Using cached data for ContainerShifting
2025-04-02 19:49:50,620 - INFO - Using cached data for Transfer
2025-04-02 19:49:50,629 - INFO - Using cached data for ContainerCleaning
2025-04-02 19:49:50,630 - INFO - Using cached data for Transfer
2025-04-02 19:49:50,639 - INFO - Using cached data for Price
2025-04-02 19:49:50,639 - INFO - Using cached data for Price
2025-04-02 19:49:50,649 - INFO - Using cached data for PTI
2025-04-02 19:49:50,649 - INFO - Using cached data for Price
2025-04-02 19:49:50,649 - INFO - Using cached data for Price
2025-04-02 19:49:50,656 - INFO - Using cached data for PTI
2025-04-02 19:49:50,656 - INFO - Using cached data for Price
2025-04-02 19:49:50,657 - INFO - Using cached data for Price
2025-04-02 19:49:50,662 - INFO - Using cached data for Price
2025-04-02 19:49:50,662 - INFO - Using cached data for Price
2025-04-02 19:49:50,665 - INFO - Using cached data for Transfer
2025-04-02 19:49:50,668 - INFO - Using cached data for ScowTransfer
2025-04-02 19:49:50,668 - INFO - Using cached data for CCCSReport
2025-04-02 19:49:50,669 - INFO - Using cached data for Price
2025-04-02 19:49:50,669 - INFO - Using cached data for Price
2025-04-02 19:49:50,670 - INFO - Using cached data for ScowTransfer
2025-04-02 19:49:50,670 - INFO - Using cached data for Price
2025-04-02 19:49:50,670 - INFO - Using cached data for Price
2025-04-02 19:49:50,671 - INFO - Using cached data for CCCSReport
2025-04-02 19:49:50,671 - INFO - Using cached data for Price
2025-04-02 19:49:50,671 - INFO - Using cached data for Price
2025-04-02 19:49:50,672 - INFO - Using cached data for CCCSReport
2025-04-02 19:49:50,673 - INFO - Using cached data for Price
2025-04-02 19:49:50,673 - INFO - Using cached data for Price
2025-04-02 19:49:50,674 - INFO - Using cached data for CCCSReport
2025-04-02 19:49:50,675 - INFO - Using cached data for Price
2025-04-02 19:49:50,675 - INFO - Using cached data for Price
2025-04-02 19:49:50,676 - INFO - Using cached data for CrossStuffing
2025-04-02 19:49:50,676 - INFO - Using cached data for Price
2025-04-02 19:49:50,676 - INFO - Using cached data for Price
2025-04-02 19:49:50,677 - INFO - Using cached data for CCCSContainerStuffing
2025-04-02 19:49:50,678 - INFO - Using cached data for Transfer
2025-04-02 19:49:50,681 - INFO - Using cached data for Price
2025-04-02 19:49:50,681 - INFO - Using cached data for Price
2025-04-02 19:49:50,683 - INFO - Using cached data for CCCSReport
2025-04-02 19:49:50,683 - INFO - Using cached data for CCCSReport
2025-04-02 19:49:50,684 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-02 19:49:50,685 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-02 19:49:50,685 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-02 19:49:50,686 - INFO - Using cached data for CCCSReport
2025-04-02 19:49:50,686 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-02 19:49:50,687 - INFO - Using cached data for Price
2025-04-02 19:49:50,687 - INFO - Using cached data for Price
2025-04-02 19:49:50,689 - INFO - Using cached data for UnloadingSummary
2025-04-02 19:49:50,689 - INFO - Using cached data for RawData
2025-04-02 19:49:50,689 - INFO - Using cached data for CCCSReport
2025-04-02 19:49:50,690 - INFO - Using cached data for Price
2025-04-02 19:49:50,690 - INFO - Using cached data for Price
2025-04-02 19:49:50,690 - INFO - Using cached data for containerOperations
2025-04-02 19:49:50,691 - INFO - Using cached data for Transfer
2025-04-02 19:49:50,694 - INFO - Using cached data for Price
2025-04-02 19:49:50,694 - INFO - Using cached data for Price
2025-04-02 19:49:50,698 - INFO - Using cached data for Transfer
2025-04-02 19:49:50,700 - INFO - Using cached data for UnloadingSummary
2025-04-02 19:49:50,700 - INFO - Using cached data for containerOperations
2025-04-02 19:49:50,700 - INFO - Using cached data for Transfer
2025-04-02 19:49:50,704 - INFO - Using cached data for Price
2025-04-02 19:49:50,704 - INFO - Using cached data for Price
2025-04-02 19:49:50,714 - INFO - Using cached data for Transfer
2025-04-02 19:49:50,716 - INFO - Using cached data for Price
2025-04-02 19:49:50,716 - INFO - Using cached data for Price
2025-04-02 19:49:50,717 - INFO - Using cached data for UnloadingSummary
2025-04-02 19:49:50,717 - INFO - Using cached data for RawData
2025-04-02 19:49:50,717 - INFO - Using cached data for CCCSReport
2025-04-02 19:49:50,718 - INFO - Using cached data for Price
2025-04-02 19:49:50,718 - INFO - Using cached data for Price
2025-04-02 19:49:50,718 - INFO - Using cached data for containerOperations
2025-04-02 19:49:50,718 - INFO - Using cached data for Transfer
2025-04-02 19:49:50,722 - INFO - Using cached data for Price
2025-04-02 19:49:50,723 - INFO - Using cached data for Price
2025-04-02 19:49:50,726 - INFO - Using cached data for Transfer
2025-04-02 19:49:50,728 - INFO - Using cached data for Price
2025-04-02 19:49:50,728 - INFO - Using cached data for Price
2025-04-02 19:49:50,729 - INFO - Using cached data for RawData
2025-04-02 19:49:50,729 - INFO - Using cached data for WelltoWell
2025-04-02 19:49:50,730 - INFO - Using cached data for Price
2025-04-02 19:49:50,730 - INFO - Using cached data for Price
2025-04-02 19:49:50,730 - INFO - Using cached data for SaltOperation
2025-04-02 19:49:50,730 - INFO - Using cached data for Price
2025-04-02 19:49:50,730 - INFO - Using cached data for Price
2025-04-02 19:49:50,732 - INFO - Using cached data for Client
2025-04-02 19:49:50,737 - INFO - Using cached data for BinTipping
2025-04-02 19:49:50,737 - INFO - Using cached data for Price
2025-04-02 19:49:50,737 - INFO - Using cached data for Price
2025-04-02 19:49:50,740 - INFO - Using cached data for LinerPallet
2025-04-02 19:49:50,740 - INFO - Using cached data for Transfer
2025-04-02 19:49:50,744 - INFO - Using cached data for Price
2025-04-02 19:49:50,744 - INFO - Using cached data for Price
2025-04-02 19:49:50,749 - INFO - Using cached data for containerOperations
2025-04-02 19:49:50,750 - INFO - Using cached data for Transfer
2025-04-02 19:49:50,753 - INFO - Using cached data for Price
2025-04-02 19:49:50,753 - INFO - Using cached data for Price
2025-04-02 19:49:50,756 - INFO - Using cached data for ShoreCrane
2025-04-02 19:49:50,756 - INFO - Using cached data for Transfer
2025-04-02 19:49:50,756 - INFO - Using cached data for Price
2025-04-02 19:49:50,756 - INFO - Using cached data for Price
2025-04-02 19:49:50,757 - INFO - Using cached data for Transfer
2025-04-02 19:49:50,760 - INFO - Using cached data for ScowTransfer
2025-04-02 19:49:50,760 - INFO - Using cached data for ForkliftRecord
2025-04-02 19:49:50,761 - INFO - Processing dataframe category: operations
2025-04-02 19:49:50,761 - INFO - Processing dataframes: ['ops', 'hatch_to_hatch']
2025-04-02 19:49:50,761 - INFO - Processing dataframe ops of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:49:50,761 - INFO - Collecting LazyFrame for ops
2025-04-02 19:49:50,764 - ERROR - Error processing dataframe ops: invalid series dtype: expected `String`, got `time` for series with name `Time`
2025-04-02 19:49:50,764 - INFO - Processing dataframe hatch_to_hatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-02 19:49:50,765 - INFO - Collecting LazyFrame for hatch_to_hatch
2025-04-02 19:49:50,766 - INFO - Successfully processed dataframe hatch_to_hatch
2025-04-02 19:49:50,767 - INFO - Writing to output/csv/hatch_to_hatch.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-02 19:49:50,768 - INFO - Successfully wrote hatch_to_hatch to file
2025-04-02 19:49:50,768 - ERROR - Error saving ops: invalid series dtype: expected `String`, got `time` for series with name `Time`
2025-04-02 19:49:50,768 - INFO - Successfully saved hatch_to_hatch
2025-04-02 19:49:50,768 - INFO - Save completed
2025-04-02 19:49:50,768 - INFO - Successfully saved: hatch_to_hatch
2025-04-02 19:49:50,768 - ERROR - Failed to save: ops: invalid series dtype: expected `String`, got `time` for series with name `Time`
2025-04-08 01:53:31,707 - DEBUG - Using selector: EpollSelector
2025-04-08 01:53:31,757 - INFO - Starting application
2025-04-08 01:53:31,757 - INFO - Clearing screen
2025-04-08 01:53:34,707 - INFO - Selected: Save files
2025-04-08 01:53:34,707 - INFO - Clearing screen
2025-04-08 01:53:38,506 - INFO - Initiating save operation for all
2025-04-08 01:53:39,953 - INFO - Using cached data for Price
2025-04-08 01:53:45,225 - INFO - Using cached data for Transfer
2025-04-08 01:53:45,228 - INFO - Using cached data for Price
2025-04-08 01:53:45,228 - INFO - Using cached data for Price
2025-04-08 01:53:46,390 - INFO - Using cached data for Price
2025-04-08 01:53:46,390 - INFO - Using cached data for Price
2025-04-08 01:53:46,393 - INFO - Using cached data for PTI
2025-04-08 01:53:46,393 - INFO - Using cached data for Price
2025-04-08 01:53:46,393 - INFO - Using cached data for Price
2025-04-08 01:53:46,395 - INFO - Using cached data for Price
2025-04-08 01:53:46,395 - INFO - Using cached data for Price
2025-04-08 01:53:46,398 - INFO - Using cached data for Transfer
2025-04-08 01:53:49,426 - INFO - Using cached data for Price
2025-04-08 01:53:49,426 - INFO - Using cached data for Price
2025-04-08 01:53:49,428 - INFO - Using cached data for ScowTransfer
2025-04-08 01:53:49,428 - INFO - Using cached data for Price
2025-04-08 01:53:49,428 - INFO - Using cached data for Price
2025-04-08 01:53:49,429 - INFO - Using cached data for CCCSReport
2025-04-08 01:53:49,429 - INFO - Using cached data for Price
2025-04-08 01:53:49,429 - INFO - Using cached data for Price
2025-04-08 01:53:49,430 - INFO - Using cached data for CCCSReport
2025-04-08 01:53:49,430 - INFO - Using cached data for Price
2025-04-08 01:53:49,430 - INFO - Using cached data for Price
2025-04-08 01:53:49,432 - INFO - Using cached data for CCCSReport
2025-04-08 01:53:49,432 - INFO - Using cached data for Price
2025-04-08 01:53:49,432 - INFO - Using cached data for Price
2025-04-08 01:53:50,226 - INFO - Using cached data for Price
2025-04-08 01:53:50,226 - INFO - Using cached data for Price
2025-04-08 01:53:51,073 - INFO - Using cached data for Transfer
2025-04-08 01:53:51,079 - INFO - Using cached data for Price
2025-04-08 01:53:51,079 - INFO - Using cached data for Price
2025-04-08 01:53:51,081 - INFO - Using cached data for CCCSReport
2025-04-08 01:53:52,361 - INFO - Using cached data for Client
2025-04-08 01:53:52,361 - INFO - Using cached data for Client
2025-04-08 01:53:52,361 - INFO - Using cached data for Client
2025-04-08 01:53:52,361 - INFO - Using cached data for Client
2025-04-08 01:53:52,362 - INFO - Using cached data for Client
2025-04-08 01:53:52,362 - INFO - Using cached data for Client
2025-04-08 01:53:52,362 - INFO - Using cached data for Client
2025-04-08 01:53:52,362 - INFO - Using cached data for Client
2025-04-08 01:53:52,363 - INFO - Using cached data for Client
2025-04-08 01:53:52,363 - INFO - Using cached data for Client
2025-04-08 01:53:52,363 - INFO - Using cached data for Client
2025-04-08 01:53:52,363 - INFO - Using cached data for Client
2025-04-08 01:53:52,364 - INFO - Using cached data for CCCSReport
2025-04-08 01:53:53,188 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-08 01:53:53,189 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-08 01:53:53,190 - INFO - Using cached data for CCCSReport
2025-04-08 01:53:53,191 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-08 01:53:53,191 - INFO - Using cached data for Price
2025-04-08 01:53:53,191 - INFO - Using cached data for Price
2025-04-08 01:53:57,215 - INFO - Using cached data for CCCSReport
2025-04-08 01:53:57,216 - INFO - Using cached data for Price
2025-04-08 01:53:57,216 - INFO - Using cached data for Price
2025-04-08 01:53:59,013 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 01:53:59,018 - INFO - Using cached data for Transfer
2025-04-08 01:53:59,022 - INFO - Using cached data for Price
2025-04-08 01:53:59,022 - INFO - Using cached data for Price
2025-04-08 01:53:59,027 - INFO - Using cached data for Transfer
2025-04-08 01:53:59,030 - INFO - Using cached data for UnloadingSummary
2025-04-08 01:54:00,626 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 01:54:00,627 - INFO - Using cached data for Transfer
2025-04-08 01:54:00,628 - INFO - Using cached data for Price
2025-04-08 01:54:00,628 - INFO - Using cached data for Price
2025-04-08 01:54:00,630 - INFO - Using cached data for Transfer
2025-04-08 01:54:00,631 - INFO - Using cached data for Price
2025-04-08 01:54:00,631 - INFO - Using cached data for Price
2025-04-08 01:54:00,632 - INFO - Using cached data for UnloadingSummary
2025-04-08 01:54:00,632 - INFO - Using cached data for RawData
2025-04-08 01:54:00,632 - INFO - Using cached data for CCCSReport
2025-04-08 01:54:00,633 - INFO - Using cached data for Price
2025-04-08 01:54:00,633 - INFO - Using cached data for Price
2025-04-08 01:54:01,825 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 01:54:01,825 - INFO - Using cached data for Transfer
2025-04-08 01:54:01,828 - INFO - Using cached data for Price
2025-04-08 01:54:01,828 - INFO - Using cached data for Price
2025-04-08 01:54:01,832 - INFO - Using cached data for Transfer
2025-04-08 01:54:01,834 - INFO - Using cached data for Price
2025-04-08 01:54:01,834 - INFO - Using cached data for Price
2025-04-08 01:54:01,835 - INFO - Using cached data for RawData
2025-04-08 01:54:02,450 - INFO - Using cached data for Price
2025-04-08 01:54:02,450 - INFO - Using cached data for Price
2025-04-08 01:54:04,000 - INFO - Using cached data for Price
2025-04-08 01:54:04,000 - INFO - Using cached data for Price
2025-04-08 01:54:04,093 - INFO - Using cached data for Client
2025-04-08 01:54:05,003 - INFO - Using cached data for Price
2025-04-08 01:54:05,004 - INFO - Using cached data for Price
2025-04-08 01:54:06,303 - INFO - Using cached data for Transfer
2025-04-08 01:54:06,307 - INFO - Using cached data for Price
2025-04-08 01:54:06,307 - INFO - Using cached data for Price
2025-04-08 01:54:08,032 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 01:54:08,033 - INFO - Using cached data for Transfer
2025-04-08 01:54:08,035 - INFO - Using cached data for Price
2025-04-08 01:54:08,035 - INFO - Using cached data for Price
2025-04-08 01:54:08,749 - INFO - Using cached data for Transfer
2025-04-08 01:54:08,750 - INFO - Using cached data for Price
2025-04-08 01:54:08,750 - INFO - Using cached data for Price
2025-04-08 01:54:08,751 - INFO - Using cached data for Transfer
2025-04-08 01:54:08,772 - INFO - Using cached data for ScowTransfer
2025-04-08 01:54:10,177 - INFO - Processing all dataframe categories concurrently
2025-04-08 01:54:10,177 - INFO - Queueing category: emr
2025-04-08 01:54:10,177 - INFO - Queueing category: operations
2025-04-08 01:54:10,177 - INFO - Queueing category: netlist
2025-04-08 01:54:10,177 - INFO - Queueing category: bin_dispatch
2025-04-08 01:54:10,177 - INFO - Queueing category: shore_handling
2025-04-08 01:54:10,177 - INFO - Queueing category: stuffing
2025-04-08 01:54:10,177 - INFO - Queueing category: transport
2025-04-08 01:54:10,177 - INFO - Queueing category: miscellaneous
2025-04-08 01:54:10,178 - INFO - Processing dataframe shifting of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:10,178 - INFO - Collecting LazyFrame for shifting
2025-04-08 01:54:10,283 - INFO - Successfully processed dataframe shifting
2025-04-08 01:54:10,284 - INFO - Writing to output/csv/shifting.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:10,285 - INFO - Processing dataframe washing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:10,286 - INFO - Collecting LazyFrame for washing
2025-04-08 01:54:10,354 - INFO - Successfully processed dataframe washing
2025-04-08 01:54:10,354 - INFO - Writing to output/csv/washing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:10,356 - INFO - Processing dataframe pti of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:10,356 - INFO - Collecting LazyFrame for pti
2025-04-08 01:54:10,676 - INFO - Successfully processed dataframe pti
2025-04-08 01:54:10,676 - INFO - Writing to output/csv/pti.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:10,676 - INFO - Processing dataframe ops of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:10,677 - INFO - Collecting LazyFrame for ops
2025-04-08 01:54:10,794 - INFO - Successfully processed dataframe ops
2025-04-08 01:54:10,795 - INFO - Writing to output/csv/ops.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:10,795 - INFO - Processing dataframe hatch_to_hatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:10,795 - INFO - Collecting LazyFrame for hatch_to_hatch
2025-04-08 01:54:10,881 - INFO - Successfully processed dataframe hatch_to_hatch
2025-04-08 01:54:10,882 - INFO - Processing dataframe net_list of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:10,882 - INFO - Writing to output/csv/hatch_to_hatch.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:10,883 - INFO - Collecting LazyFrame for net_list
2025-04-08 01:54:10,886 - ERROR - Error processing dataframe net_list: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-08 01:54:10,886 - INFO - Processing dataframe iot_container_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:10,886 - INFO - Collecting LazyFrame for iot_container_stuffing
2025-04-08 01:54:10,887 - ERROR - Error processing dataframe iot_container_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-08 01:54:10,887 - INFO - Processing dataframe oss_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:10,888 - INFO - Collecting LazyFrame for oss_stuffing
2025-04-08 01:54:10,889 - ERROR - Error processing dataframe oss_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-08 01:54:10,889 - INFO - Processing dataframe full_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:10,889 - INFO - Collecting LazyFrame for full_scows_transfer
2025-04-08 01:54:11,028 - INFO - Successfully processed dataframe full_scows_transfer
2025-04-08 01:54:11,028 - INFO - Writing to output/csv/full_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:11,029 - INFO - Processing dataframe empty_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,030 - INFO - Collecting LazyFrame for empty_scows_transfer
2025-04-08 01:54:11,048 - INFO - Successfully processed dataframe empty_scows_transfer
2025-04-08 01:54:11,049 - INFO - Writing to output/csv/empty_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:11,049 - INFO - Processing dataframe salt of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,050 - INFO - Collecting LazyFrame for salt
2025-04-08 01:54:11,112 - INFO - Successfully processed dataframe salt
2025-04-08 01:54:11,113 - INFO - Writing to output/csv/salt.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:11,113 - INFO - Processing dataframe bin_tipping of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,113 - INFO - Collecting LazyFrame for bin_tipping
2025-04-08 01:54:11,115 - INFO - Successfully processed dataframe bin_tipping
2025-04-08 01:54:11,116 - INFO - Writing to output/csv/bin_tipping.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:11,116 - INFO - Processing dataframe pallet_liner of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,116 - INFO - Collecting LazyFrame for pallet_liner
2025-04-08 01:54:11,139 - INFO - Successfully processed dataframe pallet_liner
2025-04-08 01:54:11,140 - INFO - Successfully wrote washing to file
2025-04-08 01:54:11,140 - INFO - Successfully wrote shifting to file
2025-04-08 01:54:11,141 - INFO - Successfully wrote pti to file
2025-04-08 01:54:11,141 - INFO - Successfully wrote ops to file
2025-04-08 01:54:11,142 - INFO - Successfully wrote hatch_to_hatch to file
2025-04-08 01:54:11,142 - INFO - Writing to output/csv/pallet_liner.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:11,142 - INFO - Successfully wrote full_scows_transfer to file
2025-04-08 01:54:11,144 - INFO - Successfully wrote empty_scows_transfer to file
2025-04-08 01:54:11,144 - INFO - Successfully wrote salt to file
2025-04-08 01:54:11,144 - INFO - Successfully wrote bin_tipping to file
2025-04-08 01:54:11,145 - INFO - Processing dataframe container_plugin of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,145 - INFO - Collecting LazyFrame for container_plugin
2025-04-08 01:54:11,145 - ERROR - Error processing dataframe container_plugin: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-08 01:54:11,146 - INFO - Processing dataframe shore_crane of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,146 - INFO - Collecting LazyFrame for shore_crane
2025-04-08 01:54:11,148 - INFO - Successfully processed dataframe shore_crane
2025-04-08 01:54:11,148 - INFO - Writing to output/csv/shore_crane.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:11,149 - INFO - Processing dataframe transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,149 - INFO - Collecting LazyFrame for transfer
2025-04-08 01:54:11,212 - INFO - Successfully processed dataframe transfer
2025-04-08 01:54:11,212 - INFO - Writing to output/csv/transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:11,213 - INFO - Processing dataframe scow_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,213 - INFO - Collecting LazyFrame for scow_transfer
2025-04-08 01:54:11,216 - INFO - Successfully processed dataframe scow_transfer
2025-04-08 01:54:11,216 - INFO - Writing to output/csv/scow_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:11,216 - INFO - Processing dataframe forklift of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,216 - INFO - Collecting LazyFrame for forklift
2025-04-08 01:54:11,225 - INFO - Successfully processed dataframe forklift
2025-04-08 01:54:11,225 - INFO - Processing dataframe static_loader of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,225 - INFO - Collecting LazyFrame for static_loader
2025-04-08 01:54:11,225 - INFO - Writing to output/csv/forklift.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:11,225 - ERROR - Error processing dataframe static_loader: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("operation_type"), col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
   SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in"), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
    DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-08 01:54:11,225 - INFO - Processing dataframe dispatch_to_cargo of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,226 - INFO - Collecting LazyFrame for dispatch_to_cargo
2025-04-08 01:54:11,226 - ERROR - Error processing dataframe dispatch_to_cargo: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type"), col("total_tonnage").abs(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("operation_type").is_in([Series]) FROM
     SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in"), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
      DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-08 01:54:11,226 - INFO - Processing dataframe truck_to_cccs of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,226 - INFO - Collecting LazyFrame for truck_to_cccs
2025-04-08 01:54:11,230 - INFO - Successfully processed dataframe truck_to_cccs
2025-04-08 01:54:11,230 - INFO - Processing dataframe cross_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,230 - INFO - Collecting LazyFrame for cross_stuffing
2025-04-08 01:54:11,230 - INFO - Writing to output/csv/truck_to_cccs.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:11,230 - ERROR - Error processing dataframe cross_stuffing: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("vessel_client"), col("date"), col("origin"), col("destination"), col("start_time"), col("end_time"), col("total_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("is_origin_empty"), col("service").alias("Service"), col("invoiced")] FROM
  FILTER [(col("day").str.replace([String(), String(x)])) != (String(x))] FROM
    DF ["day", "vessel_client", "date", "origin", ...]; PROJECT */26 COLUMNS
2025-04-08 01:54:11,230 - INFO - Processing dataframe cccs_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,231 - INFO - Collecting LazyFrame for cccs_stuffing
2025-04-08 01:54:11,243 - INFO - Successfully processed dataframe cccs_stuffing
2025-04-08 01:54:11,244 - INFO - Processing dataframe bycatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 01:54:11,244 - INFO - Writing to output/csv/cccs_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:11,244 - INFO - Collecting LazyFrame for bycatch
2025-04-08 01:54:11,300 - INFO - Successfully processed dataframe bycatch
2025-04-08 01:54:11,300 - INFO - Successfully wrote pallet_liner to file
2025-04-08 01:54:11,301 - INFO - Successfully wrote shore_crane to file
2025-04-08 01:54:11,301 - INFO - Successfully wrote scow_transfer to file
2025-04-08 01:54:11,301 - INFO - Successfully wrote transfer to file
2025-04-08 01:54:11,301 - INFO - Successfully wrote forklift to file
2025-04-08 01:54:11,301 - INFO - Successfully wrote truck_to_cccs to file
2025-04-08 01:54:11,302 - INFO - Successfully wrote cccs_stuffing to file
2025-04-08 01:54:11,302 - INFO - Writing to output/csv/bycatch.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 01:54:11,305 - INFO - Successfully wrote bycatch to file
2025-04-08 01:54:11,305 - INFO - Successfully saved shifting
2025-04-08 01:54:11,305 - INFO - Successfully saved washing
2025-04-08 01:54:11,305 - INFO - Successfully saved pti
2025-04-08 01:54:11,306 - INFO - Successfully saved ops
2025-04-08 01:54:11,306 - INFO - Successfully saved hatch_to_hatch
2025-04-08 01:54:11,306 - ERROR - Error saving net_list: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-08 01:54:11,306 - ERROR - Error saving iot_container_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-08 01:54:11,306 - ERROR - Error saving oss_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-08 01:54:11,306 - INFO - Successfully saved full_scows_transfer
2025-04-08 01:54:11,306 - INFO - Successfully saved empty_scows_transfer
2025-04-08 01:54:11,306 - INFO - Successfully saved salt
2025-04-08 01:54:11,306 - INFO - Successfully saved bin_tipping
2025-04-08 01:54:11,306 - INFO - Successfully saved pallet_liner
2025-04-08 01:54:11,306 - ERROR - Error saving container_plugin: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-08 01:54:11,306 - INFO - Successfully saved shore_crane
2025-04-08 01:54:11,306 - INFO - Successfully saved transfer
2025-04-08 01:54:11,306 - INFO - Successfully saved scow_transfer
2025-04-08 01:54:11,306 - INFO - Successfully saved forklift
2025-04-08 01:54:11,307 - ERROR - Error saving static_loader: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("operation_type"), col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
   SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in"), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
    DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-08 01:54:11,307 - ERROR - Error saving dispatch_to_cargo: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type"), col("total_tonnage").abs(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("operation_type").is_in([Series]) FROM
     SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in"), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
      DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-08 01:54:11,307 - INFO - Successfully saved truck_to_cccs
2025-04-08 01:54:11,307 - ERROR - Error saving cross_stuffing: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("vessel_client"), col("date"), col("origin"), col("destination"), col("start_time"), col("end_time"), col("total_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("is_origin_empty"), col("service").alias("Service"), col("invoiced")] FROM
  FILTER [(col("day").str.replace([String(), String(x)])) != (String(x))] FROM
    DF ["day", "vessel_client", "date", "origin", ...]; PROJECT */26 COLUMNS
2025-04-08 01:54:11,307 - INFO - Successfully saved cccs_stuffing
2025-04-08 01:54:11,307 - INFO - Successfully saved bycatch
2025-04-08 01:54:11,307 - INFO - Save completed
2025-04-08 01:54:11,307 - INFO - Successfully saved: 17 files
2025-04-08 01:54:11,307 - ERROR - Failed to save: 7 files
2025-04-08 01:54:11,308 - ERROR -   - net_list: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-08 01:54:11,308 - ERROR -   - iot_container_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-08 01:54:11,308 - ERROR -   - oss_stuffing: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-08 01:54:11,308 - ERROR -   - container_plugin: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-08 01:54:11,308 - ERROR -   - static_loader: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("customer"), col("operation_type"), col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
   SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in"), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
    DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-08 01:54:11,308 - ERROR -   - dispatch_to_cargo: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day"), col("date"), col("movement_type"), col("customer"), col("vessel"), col("operation_type"), col("total_tonnage").abs(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
  FILTER col("operation_type").is_in([Series]) FROM
     SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in"), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
      DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-08 01:54:11,308 - ERROR -   - cross_stuffing: expected String type, got: f64

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("vessel_client"), col("date"), col("origin"), col("destination"), col("start_time"), col("end_time"), col("total_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64).fill_null([dyn int: 0]), col("is_origin_empty"), col("service").alias("Service"), col("invoiced")] FROM
  FILTER [(col("day").str.replace([String(), String(x)])) != (String(x))] FROM
    DF ["day", "vessel_client", "date", "origin", ...]; PROJECT */26 COLUMNS
2025-04-08 02:42:38,342 - INFO - Starting application
2025-04-08 02:42:38,343 - INFO - Clearing screen
2025-04-08 02:42:40,549 - INFO - Exiting application
2025-04-08 02:42:45,795 - DEBUG - Using selector: EpollSelector
2025-04-08 02:42:45,796 - INFO - Starting application
2025-04-08 02:42:45,796 - INFO - Clearing screen
2025-04-08 02:42:48,222 - INFO - Selected: Save files
2025-04-08 02:42:48,222 - INFO - Clearing screen
2025-04-08 02:42:53,382 - INFO - Initiating save operation for emr
2025-04-08 02:42:54,069 - INFO - Using cached data for Price
2025-04-08 02:42:59,048 - INFO - Using cached data for Transfer
2025-04-08 02:42:59,052 - INFO - Using cached data for Price
2025-04-08 02:42:59,052 - INFO - Using cached data for Price
2025-04-08 02:43:00,776 - INFO - Using cached data for Price
2025-04-08 02:43:00,776 - INFO - Using cached data for Price
2025-04-08 02:43:00,779 - INFO - Using cached data for PTI
2025-04-08 02:43:00,779 - INFO - Using cached data for Price
2025-04-08 02:43:00,780 - INFO - Using cached data for Price
2025-04-08 02:43:00,782 - INFO - Using cached data for Price
2025-04-08 02:43:00,782 - INFO - Using cached data for Price
2025-04-08 02:43:00,784 - INFO - Using cached data for Transfer
2025-04-08 02:43:02,936 - INFO - Using cached data for Price
2025-04-08 02:43:02,936 - INFO - Using cached data for Price
2025-04-08 02:43:02,937 - INFO - Using cached data for ScowTransfer
2025-04-08 02:43:02,938 - INFO - Using cached data for Price
2025-04-08 02:43:02,938 - INFO - Using cached data for Price
2025-04-08 02:43:02,938 - INFO - Using cached data for CCCSReport
2025-04-08 02:43:02,939 - INFO - Using cached data for Price
2025-04-08 02:43:02,939 - INFO - Using cached data for Price
2025-04-08 02:43:02,940 - INFO - Using cached data for CCCSReport
2025-04-08 02:43:02,940 - INFO - Using cached data for Price
2025-04-08 02:43:02,940 - INFO - Using cached data for Price
2025-04-08 02:43:02,941 - INFO - Using cached data for CCCSReport
2025-04-08 02:43:02,942 - INFO - Using cached data for Price
2025-04-08 02:43:02,942 - INFO - Using cached data for Price
2025-04-08 02:43:03,607 - INFO - Using cached data for Price
2025-04-08 02:43:03,607 - INFO - Using cached data for Price
2025-04-08 02:43:04,442 - INFO - Using cached data for Transfer
2025-04-08 02:43:04,444 - INFO - Using cached data for Price
2025-04-08 02:43:04,444 - INFO - Using cached data for Price
2025-04-08 02:43:04,445 - INFO - Using cached data for CCCSReport
2025-04-08 02:43:05,144 - INFO - Using cached data for Client
2025-04-08 02:43:05,144 - INFO - Using cached data for Client
2025-04-08 02:43:05,144 - INFO - Using cached data for Client
2025-04-08 02:43:05,144 - INFO - Using cached data for Client
2025-04-08 02:43:05,145 - INFO - Using cached data for Client
2025-04-08 02:43:05,145 - INFO - Using cached data for Client
2025-04-08 02:43:05,145 - INFO - Using cached data for Client
2025-04-08 02:43:05,145 - INFO - Using cached data for Client
2025-04-08 02:43:05,146 - INFO - Using cached data for Client
2025-04-08 02:43:05,146 - INFO - Using cached data for Client
2025-04-08 02:43:05,146 - INFO - Using cached data for Client
2025-04-08 02:43:05,147 - INFO - Using cached data for Client
2025-04-08 02:43:05,147 - INFO - Using cached data for CCCSReport
2025-04-08 02:43:05,846 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-08 02:43:05,846 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-08 02:43:05,846 - INFO - Using cached data for CCCSReport
2025-04-08 02:43:05,847 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-08 02:43:05,847 - INFO - Using cached data for Price
2025-04-08 02:43:05,847 - INFO - Using cached data for Price
2025-04-08 02:43:10,537 - INFO - Using cached data for CCCSReport
2025-04-08 02:43:10,538 - INFO - Using cached data for Price
2025-04-08 02:43:10,538 - INFO - Using cached data for Price
2025-04-08 02:43:12,378 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 02:43:12,379 - INFO - Using cached data for Transfer
2025-04-08 02:43:12,382 - INFO - Using cached data for Price
2025-04-08 02:43:12,382 - INFO - Using cached data for Price
2025-04-08 02:43:12,385 - INFO - Using cached data for Transfer
2025-04-08 02:43:12,387 - INFO - Using cached data for UnloadingSummary
2025-04-08 02:43:14,177 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 02:43:14,177 - INFO - Using cached data for Transfer
2025-04-08 02:43:14,179 - INFO - Using cached data for Price
2025-04-08 02:43:14,179 - INFO - Using cached data for Price
2025-04-08 02:43:14,181 - INFO - Using cached data for Transfer
2025-04-08 02:43:14,182 - INFO - Using cached data for Price
2025-04-08 02:43:14,182 - INFO - Using cached data for Price
2025-04-08 02:43:14,183 - INFO - Using cached data for UnloadingSummary
2025-04-08 02:43:14,183 - INFO - Using cached data for RawData
2025-04-08 02:43:14,183 - INFO - Using cached data for CCCSReport
2025-04-08 02:43:14,184 - INFO - Using cached data for Price
2025-04-08 02:43:14,184 - INFO - Using cached data for Price
2025-04-08 02:43:15,548 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 02:43:15,549 - INFO - Using cached data for Transfer
2025-04-08 02:43:15,552 - INFO - Using cached data for Price
2025-04-08 02:43:15,552 - INFO - Using cached data for Price
2025-04-08 02:43:15,556 - INFO - Using cached data for Transfer
2025-04-08 02:43:15,558 - INFO - Using cached data for Price
2025-04-08 02:43:15,558 - INFO - Using cached data for Price
2025-04-08 02:43:15,559 - INFO - Using cached data for RawData
2025-04-08 02:43:16,284 - INFO - Using cached data for Price
2025-04-08 02:43:16,284 - INFO - Using cached data for Price
2025-04-08 02:43:18,030 - INFO - Using cached data for Price
2025-04-08 02:43:18,030 - INFO - Using cached data for Price
2025-04-08 02:43:18,031 - INFO - Using cached data for Client
2025-04-08 02:43:18,847 - INFO - Using cached data for Price
2025-04-08 02:43:18,847 - INFO - Using cached data for Price
2025-04-08 02:43:19,705 - INFO - Using cached data for Transfer
2025-04-08 02:43:19,708 - INFO - Using cached data for Price
2025-04-08 02:43:19,708 - INFO - Using cached data for Price
2025-04-08 02:43:21,341 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 02:43:21,341 - INFO - Using cached data for Transfer
2025-04-08 02:43:21,344 - INFO - Using cached data for Price
2025-04-08 02:43:21,344 - INFO - Using cached data for Price
2025-04-08 02:43:22,128 - INFO - Using cached data for Transfer
2025-04-08 02:43:22,129 - INFO - Using cached data for Price
2025-04-08 02:43:22,129 - INFO - Using cached data for Price
2025-04-08 02:43:22,129 - INFO - Using cached data for Transfer
2025-04-08 02:43:22,131 - INFO - Using cached data for ScowTransfer
2025-04-08 02:43:24,039 - INFO - Processing dataframe category: emr
2025-04-08 02:43:24,039 - INFO - Processing dataframes: ['shifting', 'washing', 'pti']
2025-04-08 02:43:24,040 - INFO - Processing dataframe shifting of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 02:43:24,040 - INFO - Collecting LazyFrame for shifting
2025-04-08 02:43:24,045 - INFO - Successfully processed dataframe shifting
2025-04-08 02:43:24,045 - INFO - Writing to output/csv/shifting.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 02:43:24,046 - INFO - Processing dataframe washing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 02:43:24,046 - INFO - Collecting LazyFrame for washing
2025-04-08 02:43:24,080 - INFO - Successfully processed dataframe washing
2025-04-08 02:43:24,080 - INFO - Writing to output/csv/washing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 02:43:24,080 - INFO - Processing dataframe pti of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 02:43:24,080 - INFO - Collecting LazyFrame for pti
2025-04-08 02:43:24,092 - INFO - Successfully processed dataframe pti
2025-04-08 02:43:24,093 - INFO - Writing to output/csv/pti.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 02:43:24,093 - INFO - Successfully wrote shifting to file
2025-04-08 02:43:24,093 - INFO - Successfully wrote washing to file
2025-04-08 02:43:24,097 - INFO - Successfully wrote pti to file
2025-04-08 02:43:24,097 - INFO - Successfully saved shifting
2025-04-08 02:43:24,097 - INFO - Successfully saved washing
2025-04-08 02:43:24,097 - INFO - Successfully saved pti
2025-04-08 02:43:24,097 - INFO - Save completed
2025-04-08 02:43:24,097 - INFO - Successfully saved: shifting, washing, pti
2025-04-08 02:44:18,585 - INFO - Starting application
2025-04-08 02:44:18,585 - INFO - Clearing screen
2025-04-08 02:44:20,480 - INFO - Selected: Save files
2025-04-08 02:44:20,480 - INFO - Clearing screen
2025-04-08 02:44:33,161 - INFO - Initiating save operation for transport
2025-04-08 02:44:33,162 - INFO - Using cached data for Price
2025-04-08 02:44:33,162 - INFO - Using cached data for Price
2025-04-08 02:44:33,171 - INFO - Using cached data for ContainerShifting
2025-04-08 02:44:33,171 - INFO - Using cached data for Transfer
2025-04-08 02:44:33,181 - INFO - Using cached data for ContainerCleaning
2025-04-08 02:44:33,182 - INFO - Using cached data for Transfer
2025-04-08 02:44:33,197 - INFO - Using cached data for Price
2025-04-08 02:44:33,197 - INFO - Using cached data for Price
2025-04-08 02:44:33,208 - INFO - Using cached data for PTI
2025-04-08 02:44:33,209 - INFO - Using cached data for Price
2025-04-08 02:44:33,209 - INFO - Using cached data for Price
2025-04-08 02:44:33,222 - INFO - Using cached data for PTI
2025-04-08 02:44:33,222 - INFO - Using cached data for Price
2025-04-08 02:44:33,223 - INFO - Using cached data for Price
2025-04-08 02:44:33,230 - INFO - Using cached data for Price
2025-04-08 02:44:33,230 - INFO - Using cached data for Price
2025-04-08 02:44:33,235 - INFO - Using cached data for Transfer
2025-04-08 02:44:33,241 - INFO - Using cached data for ScowTransfer
2025-04-08 02:44:33,242 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:33,243 - INFO - Using cached data for Price
2025-04-08 02:44:33,243 - INFO - Using cached data for Price
2025-04-08 02:44:33,245 - INFO - Using cached data for ScowTransfer
2025-04-08 02:44:33,245 - INFO - Using cached data for Price
2025-04-08 02:44:33,245 - INFO - Using cached data for Price
2025-04-08 02:44:33,247 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:33,248 - INFO - Using cached data for Price
2025-04-08 02:44:33,248 - INFO - Using cached data for Price
2025-04-08 02:44:33,254 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:33,255 - INFO - Using cached data for Price
2025-04-08 02:44:33,255 - INFO - Using cached data for Price
2025-04-08 02:44:33,259 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:33,260 - INFO - Using cached data for Price
2025-04-08 02:44:33,260 - INFO - Using cached data for Price
2025-04-08 02:44:33,264 - INFO - Using cached data for CrossStuffing
2025-04-08 02:44:33,265 - INFO - Using cached data for Price
2025-04-08 02:44:33,266 - INFO - Using cached data for Price
2025-04-08 02:44:33,269 - INFO - Using cached data for CCCSContainerStuffing
2025-04-08 02:44:33,270 - INFO - Using cached data for Transfer
2025-04-08 02:44:33,277 - INFO - Using cached data for Price
2025-04-08 02:44:33,278 - INFO - Using cached data for Price
2025-04-08 02:44:33,281 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:33,282 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:33,284 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-08 02:44:33,285 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-08 02:44:33,288 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-08 02:44:33,289 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:33,291 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-08 02:44:33,292 - INFO - Using cached data for Price
2025-04-08 02:44:33,293 - INFO - Using cached data for Price
2025-04-08 02:44:33,295 - INFO - Using cached data for UnloadingSummary
2025-04-08 02:44:33,295 - INFO - Using cached data for RawData
2025-04-08 02:44:33,296 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:33,298 - INFO - Using cached data for Price
2025-04-08 02:44:33,298 - INFO - Using cached data for Price
2025-04-08 02:44:35,095 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 02:44:35,095 - INFO - Using cached data for Transfer
2025-04-08 02:44:35,098 - INFO - Using cached data for Price
2025-04-08 02:44:35,098 - INFO - Using cached data for Price
2025-04-08 02:44:35,101 - INFO - Using cached data for Transfer
2025-04-08 02:44:35,103 - INFO - Using cached data for UnloadingSummary
2025-04-08 02:44:36,757 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 02:44:36,757 - INFO - Using cached data for Transfer
2025-04-08 02:44:36,760 - INFO - Using cached data for Price
2025-04-08 02:44:36,760 - INFO - Using cached data for Price
2025-04-08 02:44:36,764 - INFO - Using cached data for Transfer
2025-04-08 02:44:36,765 - INFO - Using cached data for Price
2025-04-08 02:44:36,765 - INFO - Using cached data for Price
2025-04-08 02:44:36,766 - INFO - Using cached data for UnloadingSummary
2025-04-08 02:44:36,766 - INFO - Using cached data for RawData
2025-04-08 02:44:36,766 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:36,767 - INFO - Using cached data for Price
2025-04-08 02:44:36,767 - INFO - Using cached data for Price
2025-04-08 02:44:38,316 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 02:44:38,316 - INFO - Using cached data for Transfer
2025-04-08 02:44:38,318 - INFO - Using cached data for Price
2025-04-08 02:44:38,318 - INFO - Using cached data for Price
2025-04-08 02:44:38,322 - INFO - Using cached data for Transfer
2025-04-08 02:44:38,324 - INFO - Using cached data for Price
2025-04-08 02:44:38,324 - INFO - Using cached data for Price
2025-04-08 02:44:38,325 - INFO - Using cached data for RawData
2025-04-08 02:44:38,325 - INFO - Using cached data for WelltoWell
2025-04-08 02:44:38,325 - INFO - Using cached data for Price
2025-04-08 02:44:38,326 - INFO - Using cached data for Price
2025-04-08 02:44:38,326 - INFO - Using cached data for SaltOperation
2025-04-08 02:44:38,326 - INFO - Using cached data for Price
2025-04-08 02:44:38,326 - INFO - Using cached data for Price
2025-04-08 02:44:38,327 - INFO - Using cached data for Client
2025-04-08 02:44:38,328 - INFO - Using cached data for BinTipping
2025-04-08 02:44:38,329 - INFO - Using cached data for Price
2025-04-08 02:44:38,329 - INFO - Using cached data for Price
2025-04-08 02:44:38,332 - INFO - Using cached data for LinerPallet
2025-04-08 02:44:38,332 - INFO - Using cached data for Transfer
2025-04-08 02:44:38,335 - INFO - Using cached data for Price
2025-04-08 02:44:38,336 - INFO - Using cached data for Price
2025-04-08 02:44:39,519 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 02:44:39,519 - INFO - Using cached data for Transfer
2025-04-08 02:44:39,521 - INFO - Using cached data for Price
2025-04-08 02:44:39,521 - INFO - Using cached data for Price
2025-04-08 02:44:39,524 - INFO - Using cached data for ShoreCrane
2025-04-08 02:44:39,524 - INFO - Using cached data for Transfer
2025-04-08 02:44:39,524 - INFO - Using cached data for Price
2025-04-08 02:44:39,524 - INFO - Using cached data for Price
2025-04-08 02:44:39,525 - INFO - Using cached data for Transfer
2025-04-08 02:44:39,527 - INFO - Using cached data for ScowTransfer
2025-04-08 02:44:39,528 - INFO - Using cached data for ForkliftRecord
2025-04-08 02:44:39,528 - INFO - Processing dataframe category: transport
2025-04-08 02:44:39,528 - INFO - Processing dataframes: ['shore_crane', 'transfer', 'scow_transfer', 'forklift']
2025-04-08 02:44:39,528 - INFO - Processing dataframe shore_crane of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 02:44:39,528 - INFO - Collecting LazyFrame for shore_crane
2025-04-08 02:44:39,532 - INFO - Successfully processed dataframe shore_crane
2025-04-08 02:44:39,532 - INFO - Processing dataframe transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 02:44:39,532 - INFO - Writing to output/csv/shore_crane.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 02:44:39,532 - INFO - Collecting LazyFrame for transfer
2025-04-08 02:44:39,594 - INFO - Successfully processed dataframe transfer
2025-04-08 02:44:39,595 - INFO - Processing dataframe scow_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 02:44:39,595 - INFO - Writing to output/csv/transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 02:44:39,595 - INFO - Collecting LazyFrame for scow_transfer
2025-04-08 02:44:39,602 - INFO - Successfully processed dataframe scow_transfer
2025-04-08 02:44:39,602 - INFO - Writing to output/csv/scow_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 02:44:39,603 - INFO - Processing dataframe forklift of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 02:44:39,603 - INFO - Collecting LazyFrame for forklift
2025-04-08 02:44:39,612 - INFO - Successfully processed dataframe forklift
2025-04-08 02:44:39,612 - INFO - Successfully wrote shore_crane to file
2025-04-08 02:44:39,612 - INFO - Successfully wrote scow_transfer to file
2025-04-08 02:44:39,612 - INFO - Successfully wrote transfer to file
2025-04-08 02:44:39,613 - INFO - Writing to output/csv/forklift.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 02:44:39,614 - INFO - Successfully wrote forklift to file
2025-04-08 02:44:39,615 - INFO - Successfully saved shore_crane
2025-04-08 02:44:39,615 - INFO - Successfully saved transfer
2025-04-08 02:44:39,615 - INFO - Successfully saved scow_transfer
2025-04-08 02:44:39,615 - INFO - Successfully saved forklift
2025-04-08 02:44:39,615 - INFO - Save completed
2025-04-08 02:44:39,615 - INFO - Successfully saved: shore_crane, transfer, scow_transfer, forklift
2025-04-08 02:44:49,890 - INFO - Starting application
2025-04-08 02:44:49,890 - INFO - Clearing screen
2025-04-08 02:44:51,641 - INFO - Selected: Save files
2025-04-08 02:44:51,642 - INFO - Clearing screen
2025-04-08 02:44:56,938 - INFO - Initiating save operation for stuffing
2025-04-08 02:44:56,939 - INFO - Using cached data for Price
2025-04-08 02:44:56,939 - INFO - Using cached data for Price
2025-04-08 02:44:56,948 - INFO - Using cached data for ContainerShifting
2025-04-08 02:44:56,949 - INFO - Using cached data for Transfer
2025-04-08 02:44:56,962 - INFO - Using cached data for ContainerCleaning
2025-04-08 02:44:56,963 - INFO - Using cached data for Transfer
2025-04-08 02:44:56,977 - INFO - Using cached data for Price
2025-04-08 02:44:56,977 - INFO - Using cached data for Price
2025-04-08 02:44:56,989 - INFO - Using cached data for PTI
2025-04-08 02:44:56,989 - INFO - Using cached data for Price
2025-04-08 02:44:56,989 - INFO - Using cached data for Price
2025-04-08 02:44:57,001 - INFO - Using cached data for PTI
2025-04-08 02:44:57,002 - INFO - Using cached data for Price
2025-04-08 02:44:57,002 - INFO - Using cached data for Price
2025-04-08 02:44:57,013 - INFO - Using cached data for Price
2025-04-08 02:44:57,014 - INFO - Using cached data for Price
2025-04-08 02:44:57,020 - INFO - Using cached data for Transfer
2025-04-08 02:44:57,026 - INFO - Using cached data for ScowTransfer
2025-04-08 02:44:57,027 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:57,027 - INFO - Using cached data for Price
2025-04-08 02:44:57,027 - INFO - Using cached data for Price
2025-04-08 02:44:57,030 - INFO - Using cached data for ScowTransfer
2025-04-08 02:44:57,030 - INFO - Using cached data for Price
2025-04-08 02:44:57,030 - INFO - Using cached data for Price
2025-04-08 02:44:57,033 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:57,033 - INFO - Using cached data for Price
2025-04-08 02:44:57,033 - INFO - Using cached data for Price
2025-04-08 02:44:57,036 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:57,036 - INFO - Using cached data for Price
2025-04-08 02:44:57,037 - INFO - Using cached data for Price
2025-04-08 02:44:57,040 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:57,042 - INFO - Using cached data for Price
2025-04-08 02:44:57,042 - INFO - Using cached data for Price
2025-04-08 02:44:57,046 - INFO - Using cached data for CrossStuffing
2025-04-08 02:44:57,046 - INFO - Using cached data for Price
2025-04-08 02:44:57,047 - INFO - Using cached data for Price
2025-04-08 02:44:57,051 - INFO - Using cached data for CCCSContainerStuffing
2025-04-08 02:44:57,052 - INFO - Using cached data for Transfer
2025-04-08 02:44:57,058 - INFO - Using cached data for Price
2025-04-08 02:44:57,059 - INFO - Using cached data for Price
2025-04-08 02:44:57,061 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:57,063 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:57,064 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-08 02:44:57,065 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-08 02:44:57,067 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-08 02:44:57,068 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:57,069 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-08 02:44:57,070 - INFO - Using cached data for Price
2025-04-08 02:44:57,071 - INFO - Using cached data for Price
2025-04-08 02:44:57,075 - INFO - Using cached data for UnloadingSummary
2025-04-08 02:44:57,075 - INFO - Using cached data for RawData
2025-04-08 02:44:57,075 - INFO - Using cached data for CCCSReport
2025-04-08 02:44:57,077 - INFO - Using cached data for Price
2025-04-08 02:44:57,077 - INFO - Using cached data for Price
2025-04-08 02:44:58,850 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 02:44:58,850 - INFO - Using cached data for Transfer
2025-04-08 02:44:58,853 - INFO - Using cached data for Price
2025-04-08 02:44:58,853 - INFO - Using cached data for Price
2025-04-08 02:44:58,856 - INFO - Using cached data for Transfer
2025-04-08 02:44:58,858 - INFO - Using cached data for UnloadingSummary
2025-04-08 02:45:00,556 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 02:45:00,557 - INFO - Using cached data for Transfer
2025-04-08 02:45:00,559 - INFO - Using cached data for Price
2025-04-08 02:45:00,560 - INFO - Using cached data for Price
2025-04-08 02:45:00,563 - INFO - Using cached data for Transfer
2025-04-08 02:45:00,564 - INFO - Using cached data for Price
2025-04-08 02:45:00,565 - INFO - Using cached data for Price
2025-04-08 02:45:00,565 - INFO - Using cached data for UnloadingSummary
2025-04-08 02:45:00,565 - INFO - Using cached data for RawData
2025-04-08 02:45:00,566 - INFO - Using cached data for CCCSReport
2025-04-08 02:45:00,566 - INFO - Using cached data for Price
2025-04-08 02:45:00,566 - INFO - Using cached data for Price
2025-04-08 02:45:02,252 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 02:45:02,253 - INFO - Using cached data for Transfer
2025-04-08 02:45:02,255 - INFO - Using cached data for Price
2025-04-08 02:45:02,255 - INFO - Using cached data for Price
2025-04-08 02:45:02,257 - INFO - Using cached data for Transfer
2025-04-08 02:45:02,258 - INFO - Using cached data for Price
2025-04-08 02:45:02,258 - INFO - Using cached data for Price
2025-04-08 02:45:02,259 - INFO - Using cached data for RawData
2025-04-08 02:45:02,259 - INFO - Using cached data for WelltoWell
2025-04-08 02:45:02,259 - INFO - Using cached data for Price
2025-04-08 02:45:02,259 - INFO - Using cached data for Price
2025-04-08 02:45:02,260 - INFO - Using cached data for SaltOperation
2025-04-08 02:45:02,260 - INFO - Using cached data for Price
2025-04-08 02:45:02,260 - INFO - Using cached data for Price
2025-04-08 02:45:02,261 - INFO - Using cached data for Client
2025-04-08 02:45:02,261 - INFO - Using cached data for BinTipping
2025-04-08 02:45:02,261 - INFO - Using cached data for Price
2025-04-08 02:45:02,261 - INFO - Using cached data for Price
2025-04-08 02:45:02,262 - INFO - Using cached data for LinerPallet
2025-04-08 02:45:02,262 - INFO - Using cached data for Transfer
2025-04-08 02:45:02,264 - INFO - Using cached data for Price
2025-04-08 02:45:02,264 - INFO - Using cached data for Price
2025-04-08 02:45:04,003 - ERROR - Unexpected error in load_gsheet_data: conversion from `str` to `time` failed in column 'time_plugged' for 6 out of 57 values: ["", "", … ""]
2025-04-08 02:45:04,004 - INFO - Using cached data for Transfer
2025-04-08 02:45:04,006 - INFO - Using cached data for Price
2025-04-08 02:45:04,006 - INFO - Using cached data for Price
2025-04-08 02:45:04,009 - INFO - Using cached data for ShoreCrane
2025-04-08 02:45:04,009 - INFO - Using cached data for Transfer
2025-04-08 02:45:04,009 - INFO - Using cached data for Price
2025-04-08 02:45:04,009 - INFO - Using cached data for Price
2025-04-08 02:45:04,010 - INFO - Using cached data for Transfer
2025-04-08 02:45:04,013 - INFO - Using cached data for ScowTransfer
2025-04-08 02:45:04,013 - INFO - Using cached data for ForkliftRecord
2025-04-08 02:45:04,014 - INFO - Processing dataframe category: stuffing
2025-04-08 02:45:04,014 - INFO - Processing dataframes: ['pallet_liner', 'container_plugin']
2025-04-08 02:45:04,014 - INFO - Processing dataframe pallet_liner of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 02:45:04,014 - INFO - Collecting LazyFrame for pallet_liner
2025-04-08 02:45:04,025 - INFO - Successfully processed dataframe pallet_liner
2025-04-08 02:45:04,025 - INFO - Writing to output/csv/pallet_liner.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-08 02:45:04,025 - INFO - Processing dataframe container_plugin of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-08 02:45:04,026 - INFO - Collecting LazyFrame for container_plugin
2025-04-08 02:45:04,026 - ERROR - Error processing dataframe container_plugin: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-08 02:45:04,030 - INFO - Successfully wrote pallet_liner to file
2025-04-08 02:45:04,030 - INFO - Successfully saved pallet_liner
2025-04-08 02:45:04,030 - ERROR - Error saving container_plugin: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-08 02:45:04,030 - INFO - Save completed
2025-04-08 02:45:04,030 - INFO - Successfully saved: pallet_liner
2025-04-08 02:45:04,030 - ERROR - Failed to save: container_plugin: vessel_client

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
DF []; PROJECT */0 COLUMNS
2025-04-19 15:18:02,720 - DEBUG - Using selector: EpollSelector
2025-04-19 15:18:02,754 - INFO - Starting application
2025-04-19 15:18:02,754 - INFO - Clearing screen
2025-04-19 15:18:04,891 - INFO - Selected: Save files
2025-04-19 15:18:04,892 - INFO - Clearing screen
2025-04-19 15:18:07,588 - INFO - Initiating save operation for all
2025-04-19 15:18:09,027 - INFO - Using cached data for Price
2025-04-19 15:18:10,741 - INFO - Loading container data from sheet
2025-04-19 15:18:13,697 - INFO - Using cached data for Price
2025-04-19 15:18:13,698 - INFO - Using cached data for Price
2025-04-19 15:18:14,964 - INFO - Using cached data for Price
2025-04-19 15:18:14,965 - INFO - Using cached data for Price
2025-04-19 15:18:14,973 - INFO - Using cached data for PTI
2025-04-19 15:18:14,973 - INFO - Using cached data for Price
2025-04-19 15:18:14,974 - INFO - Using cached data for Price
2025-04-19 15:18:14,981 - INFO - Using cached data for Price
2025-04-19 15:18:14,981 - INFO - Using cached data for Price
2025-04-19 15:18:17,701 - INFO - Using cached data for Price
2025-04-19 15:18:17,701 - INFO - Using cached data for Price
2025-04-19 15:18:17,705 - INFO - Using cached data for ScowTransfer
2025-04-19 15:18:17,706 - INFO - Using cached data for Price
2025-04-19 15:18:17,706 - INFO - Using cached data for Price
2025-04-19 15:18:17,710 - INFO - Using cached data for CCCSReport
2025-04-19 15:18:17,711 - INFO - Using cached data for Price
2025-04-19 15:18:17,711 - INFO - Using cached data for Price
2025-04-19 15:18:17,713 - INFO - Using cached data for CCCSReport
2025-04-19 15:18:17,714 - INFO - Using cached data for Price
2025-04-19 15:18:17,714 - INFO - Using cached data for Price
2025-04-19 15:18:17,717 - INFO - Using cached data for CCCSReport
2025-04-19 15:18:17,717 - INFO - Using cached data for Price
2025-04-19 15:18:17,717 - INFO - Using cached data for Price
2025-04-19 15:18:18,421 - INFO - Using cached data for Price
2025-04-19 15:18:18,422 - INFO - Using cached data for Price
2025-04-19 15:18:19,085 - INFO - Using cached data for Price
2025-04-19 15:18:19,085 - INFO - Using cached data for Price
2025-04-19 15:18:19,087 - INFO - Using cached data for CCCSReport
2025-04-19 15:18:19,854 - INFO - Using cached data for Client
2025-04-19 15:18:19,855 - INFO - Using cached data for Client
2025-04-19 15:18:19,856 - INFO - Using cached data for Client
2025-04-19 15:18:19,857 - INFO - Using cached data for Client
2025-04-19 15:18:19,859 - INFO - Using cached data for Client
2025-04-19 15:18:19,860 - INFO - Using cached data for Client
2025-04-19 15:18:19,861 - INFO - Using cached data for Client
2025-04-19 15:18:19,862 - INFO - Using cached data for Client
2025-04-19 15:18:19,863 - INFO - Using cached data for Client
2025-04-19 15:18:19,865 - INFO - Using cached data for Client
2025-04-19 15:18:19,866 - INFO - Using cached data for Client
2025-04-19 15:18:19,867 - INFO - Using cached data for Client
2025-04-19 15:18:19,870 - INFO - Using cached data for CCCSReport
2025-04-19 15:18:20,605 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-19 15:18:20,607 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-19 15:18:20,608 - INFO - Using cached data for CCCSReport
2025-04-19 15:18:20,610 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-19 15:18:20,613 - INFO - Using cached data for Price
2025-04-19 15:18:20,613 - INFO - Using cached data for Price
2025-04-19 15:18:25,634 - INFO - Using cached data for CCCSReport
2025-04-19 15:18:25,635 - INFO - Using cached data for Price
2025-04-19 15:18:25,635 - INFO - Using cached data for Price
2025-04-19 15:18:26,710 - INFO - Using cached data for Price
2025-04-19 15:18:26,710 - INFO - Using cached data for Price
2025-04-19 15:18:26,722 - INFO - Using cached data for UnloadingSummary
2025-04-19 15:18:26,723 - INFO - Using cached data for containerOperations
2025-04-19 15:18:26,726 - INFO - Using cached data for Price
2025-04-19 15:18:26,726 - INFO - Using cached data for Price
2025-04-19 15:18:26,733 - INFO - Using cached data for Price
2025-04-19 15:18:26,733 - INFO - Using cached data for Price
2025-04-19 15:18:26,734 - INFO - Using cached data for UnloadingSummary
2025-04-19 15:18:26,734 - INFO - Using cached data for RawData
2025-04-19 15:18:26,734 - INFO - Using cached data for CCCSReport
2025-04-19 15:18:26,735 - INFO - Using cached data for Price
2025-04-19 15:18:26,735 - INFO - Using cached data for Price
2025-04-19 15:18:26,735 - INFO - Using cached data for containerOperations
2025-04-19 15:18:26,739 - INFO - Using cached data for Price
2025-04-19 15:18:26,739 - INFO - Using cached data for Price
2025-04-19 15:18:26,751 - INFO - Using cached data for Price
2025-04-19 15:18:26,751 - INFO - Using cached data for Price
2025-04-19 15:18:26,752 - INFO - Using cached data for RawData
2025-04-19 15:18:27,540 - INFO - Using cached data for Price
2025-04-19 15:18:27,540 - INFO - Using cached data for Price
2025-04-19 15:18:28,864 - INFO - Using cached data for Price
2025-04-19 15:18:28,864 - INFO - Using cached data for Price
2025-04-19 15:18:28,886 - INFO - Using cached data for Client
2025-04-19 15:18:29,581 - INFO - Using cached data for Price
2025-04-19 15:18:29,581 - INFO - Using cached data for Price
2025-04-19 15:18:30,179 - INFO - Using cached data for Price
2025-04-19 15:18:30,179 - INFO - Using cached data for Price
2025-04-19 15:18:30,188 - INFO - Using cached data for containerOperations
2025-04-19 15:18:30,194 - INFO - Using cached data for Price
2025-04-19 15:18:30,194 - INFO - Using cached data for Price
2025-04-19 15:18:30,944 - INFO - Using cached data for Transfer
2025-04-19 15:18:30,945 - INFO - Using cached data for Price
2025-04-19 15:18:30,945 - INFO - Using cached data for Price
2025-04-19 15:18:30,957 - INFO - Using cached data for ScowTransfer
2025-04-19 15:18:32,000 - INFO - Processing all dataframe categories concurrently
2025-04-19 15:18:32,001 - INFO - Queueing category: emr
2025-04-19 15:18:32,001 - INFO - Queueing category: operations
2025-04-19 15:18:32,001 - INFO - Queueing category: netlist
2025-04-19 15:18:32,001 - INFO - Queueing category: bin_dispatch
2025-04-19 15:18:32,002 - INFO - Queueing category: shore_handling
2025-04-19 15:18:32,002 - INFO - Queueing category: stuffing
2025-04-19 15:18:32,002 - INFO - Queueing category: transport
2025-04-19 15:18:32,002 - INFO - Queueing category: miscellaneous
2025-04-19 15:18:32,008 - INFO - Processing dataframe shifting of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,008 - INFO - Collecting LazyFrame for shifting
2025-04-19 15:18:32,065 - ERROR - Error processing dataframe shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-04-19 15:18:32,067 - INFO - Processing dataframe washing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,068 - INFO - Collecting LazyFrame for washing
2025-04-19 15:18:32,099 - ERROR - Error processing dataframe washing: conversion from `str` to `enum` failed in column 'invoice_to' for 1 out of 68 values: ["RAWANQ"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-19 15:18:32,099 - INFO - Processing dataframe pti of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,099 - INFO - Collecting LazyFrame for pti
2025-04-19 15:18:32,120 - ERROR - Error processing dataframe pti: sub operation not supported for dtypes `str` and `str`
2025-04-19 15:18:32,121 - INFO - Processing dataframe ops of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,121 - INFO - Collecting LazyFrame for ops
2025-04-19 15:18:32,289 - INFO - Successfully processed dataframe ops
2025-04-19 15:18:32,290 - INFO - Writing to output/csv/ops.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-19 15:18:32,291 - INFO - Processing dataframe hatch_to_hatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,292 - INFO - Collecting LazyFrame for hatch_to_hatch
2025-04-19 15:18:32,522 - INFO - Successfully processed dataframe hatch_to_hatch
2025-04-19 15:18:32,523 - INFO - Writing to output/csv/hatch_to_hatch.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-19 15:18:32,523 - INFO - Processing dataframe net_list of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,542 - INFO - Collecting LazyFrame for net_list
2025-04-19 15:18:32,544 - ERROR - Error processing dataframe net_list: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-19 15:18:32,544 - INFO - Processing dataframe iot_container_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,544 - INFO - Collecting LazyFrame for iot_container_stuffing
2025-04-19 15:18:32,545 - ERROR - Error processing dataframe iot_container_stuffing: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), String(Stuffing).alias("Service")] 
  FILTER col("container_number").is_in([Series]) FROM
     SELECT [col("Date").alias("date"), col("Vessel").str.uppercase().alias("vessel"), col("startTime").alias("start_time"), col("Container (Destination)").alias("container_number"), col("overtime"), col("Storage").alias("storage"), col("endTime").alias("end_time"), col("Total Tonnage").alias("total_tonnage")] FROM
      DF ["Date", "Vessel", "startTime", "Container (Destination)", ...]; PROJECT */25 COLUMNS
2025-04-19 15:18:32,545 - INFO - Processing dataframe oss_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,545 - INFO - Collecting LazyFrame for oss_stuffing
2025-04-19 15:18:32,546 - ERROR - Error processing dataframe oss_stuffing: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-19 15:18:32,547 - INFO - Processing dataframe full_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,547 - INFO - Collecting LazyFrame for full_scows_transfer
2025-04-19 15:18:32,547 - ERROR - Error processing dataframe full_scows_transfer: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when([(col("movement_type")) == (String(Delivery))]).then(String(OUT)).otherwise(String(IN)).strict_cast(Enum(Some(local), Physical)).alias("movement_type"), when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  FILTER [(col("status")) == (String(Full))] FROM
     SELECT [col("date"), col("container_number").strict_cast(Enum(Some(local), Physical)), col("customer"), col("movement_type"), col("driver"), col("from"), col("time_out"), col("destination"), col("time_in"), col("status").strict_cast(Enum(Some(local), Physical)), col("remarks"), col("num_of_scows").strict_cast(Int64)] FROM
      DF ["date", "container_number", "customer", "movement_type", ...]; PROJECT */13 COLUMNS
2025-04-19 15:18:32,547 - INFO - Processing dataframe empty_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,548 - INFO - Collecting LazyFrame for empty_scows_transfer
2025-04-19 15:18:32,548 - ERROR - Error processing dataframe empty_scows_transfer: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when([(col("movement_type")) == (String(Delivery))]).then(String(OUT)).otherwise(String(IN)).strict_cast(Enum(Some(local), Physical)).alias("movement_type"), when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  FILTER [(col("status")) == (String(Empty))] FROM
     SELECT [col("date"), col("container_number").strict_cast(Enum(Some(local), Physical)), col("customer"), col("movement_type"), col("driver"), col("from"), col("time_out"), col("destination"), col("time_in"), col("status").strict_cast(Enum(Some(local), Physical)), col("remarks"), col("num_of_scows").strict_cast(Int64)] FROM
      DF ["date", "container_number", "customer", "movement_type", ...]; PROJECT */13 COLUMNS
2025-04-19 15:18:32,549 - INFO - Processing dataframe salt of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,549 - INFO - Collecting LazyFrame for salt
2025-04-19 15:18:32,550 - ERROR - Error processing dataframe salt: expected Date or Datetime, got str

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day_name").strict_cast(Enum(Some(local), Physical)), col("date"), col("vessel").strict_cast(Enum(Some(local), Physical)), col("customer").str.strip_chars([null]).strict_cast(Enum(Some(local), Physical)), col("start_time"), col("end_time"), col("duration"), col("operation_type"), col("tonnage")] FROM
  DF ["day_name", "date", "vessel", "customer", ...]; PROJECT */9 COLUMNS
2025-04-19 15:18:32,550 - INFO - Processing dataframe bin_tipping of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,551 - INFO - Collecting LazyFrame for bin_tipping
2025-04-19 15:18:32,551 - ERROR - Error processing dataframe bin_tipping: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("Date").is_in([Series])).then(String(PH)).otherwise(col("Date").dt.to_string()).alias("day_name"), String(IPHS Bin Tipping).alias("Service")] 
  FILTER [(col("Tonnage Tipped")) > (0.0)] FROM
    DF ["Date", "Customer", "movement_type", "No of Scows Transferred (CCCS)", ...]; PROJECT */11 COLUMNS
2025-04-19 15:18:32,552 - INFO - Processing dataframe pallet_liner of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,552 - INFO - Collecting LazyFrame for pallet_liner
2025-04-19 15:18:32,632 - INFO - Successfully processed dataframe pallet_liner
2025-04-19 15:18:32,633 - INFO - Writing to output/csv/pallet_liner.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-19 15:18:32,633 - INFO - Processing dataframe container_plugin of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,633 - INFO - Collecting LazyFrame for container_plugin
2025-04-19 15:18:32,736 - INFO - Successfully processed dataframe container_plugin
2025-04-19 15:18:32,736 - INFO - Writing to output/csv/container_plugin.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-19 15:18:32,738 - INFO - Processing dataframe shore_crane of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,738 - INFO - Collecting LazyFrame for shore_crane
2025-04-19 15:18:32,741 - ERROR - Error processing dataframe shore_crane: `hour` operation not supported for dtype `str`
2025-04-19 15:18:32,741 - INFO - Processing dataframe transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,742 - INFO - Collecting LazyFrame for transfer
2025-04-19 15:18:32,742 - ERROR - Error processing dataframe transfer: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), when([(col("size")) == (String(40'))]).then(String(Haulage FEU)).otherwise(when([(col("size")) == (String(20'))]).then(String(Haulage TEU)).otherwise(String(Err))).alias("Service"), when([(col("movement_type")) == (String(Collection))]).then(col("time_in")).otherwise(when([(col("movement_type")) == (String(Delivery))]).then(col("time_out")).otherwise(String(0))).alias("time")] 
   SELECT [col("date"), col("container_number"), col("line"), col("movement_type"), col("driver"), col("origin"), col("time_out"), col("destination"), col("time_in"), col("status"), col("type"), col("size"), col("remarks")] FROM
     WITH_COLUMNS:
     [col("date"), col("container_number").strict_cast(Enum(Some(local), Physical)), col("line"), col("movement_type").strict_cast(Enum(Some(local), Physical)), col("driver").strict_cast(Enum(Some(local), Physical))] 
      DF ["date", "container_number", "line", "movement_type", ...]; PROJECT */14 COLUMNS
2025-04-19 15:18:32,742 - INFO - Processing dataframe scow_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,742 - INFO - Collecting LazyFrame for scow_transfer
2025-04-19 15:18:32,747 - INFO - Successfully processed dataframe scow_transfer
2025-04-19 15:18:32,748 - INFO - Processing dataframe forklift of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,748 - INFO - Collecting LazyFrame for forklift
2025-04-19 15:18:32,748 - ERROR - Error processing dataframe forklift: expected Date or Datetime, got str

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("start_time"), col("end_time"), col("duration"), col("customer").strict_cast(String), col("invoiced_in"), col("service_type")] FROM
  FILTER col("service_type").is_in([Series]).not() FROM
    FILTER [(col("day")) != (String())] FROM
      DF ["day", "date", "forklift_driver", "forklift_number", ...]; PROJECT */11 COLUMNS
2025-04-19 15:18:32,748 - INFO - Processing dataframe static_loader of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,748 - INFO - Collecting LazyFrame for static_loader
2025-04-19 15:18:32,749 - INFO - Writing to output/csv/scow_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-19 15:18:32,760 - INFO - Successfully processed dataframe static_loader
2025-04-19 15:18:32,760 - INFO - Writing to output/csv/static_loader.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-19 15:18:32,760 - INFO - Processing dataframe dispatch_to_cargo of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,760 - INFO - Collecting LazyFrame for dispatch_to_cargo
2025-04-19 15:18:32,766 - INFO - Successfully processed dataframe dispatch_to_cargo
2025-04-19 15:18:32,766 - INFO - Writing to output/csv/dispatch_to_cargo.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-19 15:18:32,766 - INFO - Processing dataframe truck_to_cccs of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,767 - INFO - Collecting LazyFrame for truck_to_cccs
2025-04-19 15:18:32,772 - INFO - Successfully processed dataframe truck_to_cccs
2025-04-19 15:18:32,773 - INFO - Writing to output/csv/truck_to_cccs.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-19 15:18:32,773 - INFO - Processing dataframe cross_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,773 - INFO - Collecting LazyFrame for cross_stuffing
2025-04-19 15:18:32,774 - INFO - Successfully processed dataframe cross_stuffing
2025-04-19 15:18:32,775 - INFO - Writing to output/csv/cross_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-19 15:18:32,775 - INFO - Processing dataframe cccs_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,775 - INFO - Collecting LazyFrame for cccs_stuffing
2025-04-19 15:18:32,781 - INFO - Successfully processed dataframe cccs_stuffing
2025-04-19 15:18:32,781 - INFO - Successfully wrote ops to file
2025-04-19 15:18:32,782 - INFO - Successfully wrote hatch_to_hatch to file
2025-04-19 15:18:32,782 - INFO - Writing to output/csv/cccs_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-19 15:18:32,782 - INFO - Successfully wrote pallet_liner to file
2025-04-19 15:18:32,783 - INFO - Successfully wrote container_plugin to file
2025-04-19 15:18:32,783 - INFO - Successfully wrote scow_transfer to file
2025-04-19 15:18:32,783 - INFO - Successfully wrote static_loader to file
2025-04-19 15:18:32,783 - INFO - Successfully wrote dispatch_to_cargo to file
2025-04-19 15:18:32,783 - INFO - Successfully wrote truck_to_cccs to file
2025-04-19 15:18:32,784 - INFO - Successfully wrote cross_stuffing to file
2025-04-19 15:18:32,784 - INFO - Processing dataframe bycatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 15:18:32,784 - INFO - Collecting LazyFrame for bycatch
2025-04-19 15:18:32,785 - ERROR - Error processing dataframe bycatch: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).strict_cast(Enum(Some(local), Physical)).alias("day")] 
  DF ["date", "movement_type", "customer", "origin", ...]; PROJECT */11 COLUMNS
2025-04-19 15:18:32,785 - INFO - Successfully wrote cccs_stuffing to file
2025-04-19 15:18:32,785 - ERROR - Error saving shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-04-19 15:18:32,785 - ERROR - Error saving washing: conversion from `str` to `enum` failed in column 'invoice_to' for 1 out of 68 values: ["RAWANQ"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-19 15:18:32,785 - ERROR - Error saving pti: sub operation not supported for dtypes `str` and `str`
2025-04-19 15:18:32,785 - INFO - Successfully saved ops
2025-04-19 15:18:32,785 - INFO - Successfully saved hatch_to_hatch
2025-04-19 15:18:32,785 - ERROR - Error saving net_list: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-19 15:18:32,785 - ERROR - Error saving iot_container_stuffing: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), String(Stuffing).alias("Service")] 
  FILTER col("container_number").is_in([Series]) FROM
     SELECT [col("Date").alias("date"), col("Vessel").str.uppercase().alias("vessel"), col("startTime").alias("start_time"), col("Container (Destination)").alias("container_number"), col("overtime"), col("Storage").alias("storage"), col("endTime").alias("end_time"), col("Total Tonnage").alias("total_tonnage")] FROM
      DF ["Date", "Vessel", "startTime", "Container (Destination)", ...]; PROJECT */25 COLUMNS
2025-04-19 15:18:32,785 - ERROR - Error saving oss_stuffing: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-19 15:18:32,786 - ERROR - Error saving full_scows_transfer: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when([(col("movement_type")) == (String(Delivery))]).then(String(OUT)).otherwise(String(IN)).strict_cast(Enum(Some(local), Physical)).alias("movement_type"), when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  FILTER [(col("status")) == (String(Full))] FROM
     SELECT [col("date"), col("container_number").strict_cast(Enum(Some(local), Physical)), col("customer"), col("movement_type"), col("driver"), col("from"), col("time_out"), col("destination"), col("time_in"), col("status").strict_cast(Enum(Some(local), Physical)), col("remarks"), col("num_of_scows").strict_cast(Int64)] FROM
      DF ["date", "container_number", "customer", "movement_type", ...]; PROJECT */13 COLUMNS
2025-04-19 15:18:32,786 - ERROR - Error saving empty_scows_transfer: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when([(col("movement_type")) == (String(Delivery))]).then(String(OUT)).otherwise(String(IN)).strict_cast(Enum(Some(local), Physical)).alias("movement_type"), when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  FILTER [(col("status")) == (String(Empty))] FROM
     SELECT [col("date"), col("container_number").strict_cast(Enum(Some(local), Physical)), col("customer"), col("movement_type"), col("driver"), col("from"), col("time_out"), col("destination"), col("time_in"), col("status").strict_cast(Enum(Some(local), Physical)), col("remarks"), col("num_of_scows").strict_cast(Int64)] FROM
      DF ["date", "container_number", "customer", "movement_type", ...]; PROJECT */13 COLUMNS
2025-04-19 15:18:32,786 - ERROR - Error saving salt: expected Date or Datetime, got str

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day_name").strict_cast(Enum(Some(local), Physical)), col("date"), col("vessel").strict_cast(Enum(Some(local), Physical)), col("customer").str.strip_chars([null]).strict_cast(Enum(Some(local), Physical)), col("start_time"), col("end_time"), col("duration"), col("operation_type"), col("tonnage")] FROM
  DF ["day_name", "date", "vessel", "customer", ...]; PROJECT */9 COLUMNS
2025-04-19 15:18:32,786 - ERROR - Error saving bin_tipping: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("Date").is_in([Series])).then(String(PH)).otherwise(col("Date").dt.to_string()).alias("day_name"), String(IPHS Bin Tipping).alias("Service")] 
  FILTER [(col("Tonnage Tipped")) > (0.0)] FROM
    DF ["Date", "Customer", "movement_type", "No of Scows Transferred (CCCS)", ...]; PROJECT */11 COLUMNS
2025-04-19 15:18:32,786 - INFO - Successfully saved pallet_liner
2025-04-19 15:18:32,786 - INFO - Successfully saved container_plugin
2025-04-19 15:18:32,786 - ERROR - Error saving shore_crane: `hour` operation not supported for dtype `str`
2025-04-19 15:18:32,786 - ERROR - Error saving transfer: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), when([(col("size")) == (String(40'))]).then(String(Haulage FEU)).otherwise(when([(col("size")) == (String(20'))]).then(String(Haulage TEU)).otherwise(String(Err))).alias("Service"), when([(col("movement_type")) == (String(Collection))]).then(col("time_in")).otherwise(when([(col("movement_type")) == (String(Delivery))]).then(col("time_out")).otherwise(String(0))).alias("time")] 
   SELECT [col("date"), col("container_number"), col("line"), col("movement_type"), col("driver"), col("origin"), col("time_out"), col("destination"), col("time_in"), col("status"), col("type"), col("size"), col("remarks")] FROM
     WITH_COLUMNS:
     [col("date"), col("container_number").strict_cast(Enum(Some(local), Physical)), col("line"), col("movement_type").strict_cast(Enum(Some(local), Physical)), col("driver").strict_cast(Enum(Some(local), Physical))] 
      DF ["date", "container_number", "line", "movement_type", ...]; PROJECT */14 COLUMNS
2025-04-19 15:18:32,786 - INFO - Successfully saved scow_transfer
2025-04-19 15:18:32,786 - ERROR - Error saving forklift: expected Date or Datetime, got str

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("start_time"), col("end_time"), col("duration"), col("customer").strict_cast(String), col("invoiced_in"), col("service_type")] FROM
  FILTER col("service_type").is_in([Series]).not() FROM
    FILTER [(col("day")) != (String())] FROM
      DF ["day", "date", "forklift_driver", "forklift_number", ...]; PROJECT */11 COLUMNS
2025-04-19 15:18:32,786 - INFO - Successfully saved static_loader
2025-04-19 15:18:32,786 - INFO - Successfully saved dispatch_to_cargo
2025-04-19 15:18:32,786 - INFO - Successfully saved truck_to_cccs
2025-04-19 15:18:32,786 - INFO - Successfully saved cross_stuffing
2025-04-19 15:18:32,786 - INFO - Successfully saved cccs_stuffing
2025-04-19 15:18:32,786 - ERROR - Error saving bycatch: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).strict_cast(Enum(Some(local), Physical)).alias("day")] 
  DF ["date", "movement_type", "customer", "origin", ...]; PROJECT */11 COLUMNS
2025-04-19 15:18:32,786 - INFO - Save completed
2025-04-19 15:18:32,786 - INFO - Successfully saved: 10 files
2025-04-19 15:18:32,787 - ERROR - Failed to save: 14 files
2025-04-19 15:18:32,787 - ERROR -   - shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-04-19 15:18:32,787 - ERROR -   - washing: conversion from `str` to `enum` failed in column 'invoice_to' for 1 out of 68 values: ["RAWANQ"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-19 15:18:32,787 - ERROR -   - pti: sub operation not supported for dtypes `str` and `str`
2025-04-19 15:18:32,787 - ERROR -   - net_list: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-19 15:18:32,787 - ERROR -   - iot_container_stuffing: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), String(Stuffing).alias("Service")] 
  FILTER col("container_number").is_in([Series]) FROM
     SELECT [col("Date").alias("date"), col("Vessel").str.uppercase().alias("vessel"), col("startTime").alias("start_time"), col("Container (Destination)").alias("container_number"), col("overtime"), col("Storage").alias("storage"), col("endTime").alias("end_time"), col("Total Tonnage").alias("total_tonnage")] FROM
      DF ["Date", "Vessel", "startTime", "Container (Destination)", ...]; PROJECT */25 COLUMNS
2025-04-19 15:18:32,787 - ERROR -   - oss_stuffing: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-19 15:18:32,787 - ERROR -   - full_scows_transfer: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when([(col("movement_type")) == (String(Delivery))]).then(String(OUT)).otherwise(String(IN)).strict_cast(Enum(Some(local), Physical)).alias("movement_type"), when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  FILTER [(col("status")) == (String(Full))] FROM
     SELECT [col("date"), col("container_number").strict_cast(Enum(Some(local), Physical)), col("customer"), col("movement_type"), col("driver"), col("from"), col("time_out"), col("destination"), col("time_in"), col("status").strict_cast(Enum(Some(local), Physical)), col("remarks"), col("num_of_scows").strict_cast(Int64)] FROM
      DF ["date", "container_number", "customer", "movement_type", ...]; PROJECT */13 COLUMNS
2025-04-19 15:18:32,787 - ERROR -   - empty_scows_transfer: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when([(col("movement_type")) == (String(Delivery))]).then(String(OUT)).otherwise(String(IN)).strict_cast(Enum(Some(local), Physical)).alias("movement_type"), when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  FILTER [(col("status")) == (String(Empty))] FROM
     SELECT [col("date"), col("container_number").strict_cast(Enum(Some(local), Physical)), col("customer"), col("movement_type"), col("driver"), col("from"), col("time_out"), col("destination"), col("time_in"), col("status").strict_cast(Enum(Some(local), Physical)), col("remarks"), col("num_of_scows").strict_cast(Int64)] FROM
      DF ["date", "container_number", "customer", "movement_type", ...]; PROJECT */13 COLUMNS
2025-04-19 15:18:32,787 - ERROR -   - salt: expected Date or Datetime, got str

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day_name").strict_cast(Enum(Some(local), Physical)), col("date"), col("vessel").strict_cast(Enum(Some(local), Physical)), col("customer").str.strip_chars([null]).strict_cast(Enum(Some(local), Physical)), col("start_time"), col("end_time"), col("duration"), col("operation_type"), col("tonnage")] FROM
  DF ["day_name", "date", "vessel", "customer", ...]; PROJECT */9 COLUMNS
2025-04-19 15:18:32,787 - ERROR -   - bin_tipping: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("Date").is_in([Series])).then(String(PH)).otherwise(col("Date").dt.to_string()).alias("day_name"), String(IPHS Bin Tipping).alias("Service")] 
  FILTER [(col("Tonnage Tipped")) > (0.0)] FROM
    DF ["Date", "Customer", "movement_type", "No of Scows Transferred (CCCS)", ...]; PROJECT */11 COLUMNS
2025-04-19 15:18:32,787 - ERROR -   - shore_crane: `hour` operation not supported for dtype `str`
2025-04-19 15:18:32,788 - ERROR -   - transfer: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), when([(col("size")) == (String(40'))]).then(String(Haulage FEU)).otherwise(when([(col("size")) == (String(20'))]).then(String(Haulage TEU)).otherwise(String(Err))).alias("Service"), when([(col("movement_type")) == (String(Collection))]).then(col("time_in")).otherwise(when([(col("movement_type")) == (String(Delivery))]).then(col("time_out")).otherwise(String(0))).alias("time")] 
   SELECT [col("date"), col("container_number"), col("line"), col("movement_type"), col("driver"), col("origin"), col("time_out"), col("destination"), col("time_in"), col("status"), col("type"), col("size"), col("remarks")] FROM
     WITH_COLUMNS:
     [col("date"), col("container_number").strict_cast(Enum(Some(local), Physical)), col("line"), col("movement_type").strict_cast(Enum(Some(local), Physical)), col("driver").strict_cast(Enum(Some(local), Physical))] 
      DF ["date", "container_number", "line", "movement_type", ...]; PROJECT */14 COLUMNS
2025-04-19 15:18:32,788 - ERROR -   - forklift: expected Date or Datetime, got str

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date"), col("start_time"), col("end_time"), col("duration"), col("customer").strict_cast(String), col("invoiced_in"), col("service_type")] FROM
  FILTER col("service_type").is_in([Series]).not() FROM
    FILTER [(col("day")) != (String())] FROM
      DF ["day", "date", "forklift_driver", "forklift_number", ...]; PROJECT */11 COLUMNS
2025-04-19 15:18:32,788 - ERROR -   - bycatch: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).strict_cast(Enum(Some(local), Physical)).alias("day")] 
  DF ["date", "movement_type", "customer", "origin", ...]; PROJECT */11 COLUMNS
2025-04-19 17:31:51,707 - DEBUG - Using selector: EpollSelector
2025-04-19 17:31:51,707 - INFO - Starting application
2025-04-19 17:31:51,707 - INFO - Clearing screen
2025-04-19 17:31:53,524 - INFO - Selected: Save files
2025-04-19 17:31:53,525 - INFO - Clearing screen
2025-04-19 17:31:57,572 - INFO - Initiating save operation for emr
2025-04-19 17:31:58,813 - INFO - Using cached data for Price
2025-04-19 17:32:00,553 - INFO - Loading container data from sheet
2025-04-19 17:32:05,177 - INFO - Using cached data for Price
2025-04-19 17:32:05,177 - INFO - Using cached data for Price
2025-04-19 17:32:06,798 - INFO - Using cached data for Price
2025-04-19 17:32:06,799 - INFO - Using cached data for Price
2025-04-19 17:32:06,801 - INFO - Using cached data for PTI
2025-04-19 17:32:06,802 - INFO - Using cached data for Price
2025-04-19 17:32:06,802 - INFO - Using cached data for Price
2025-04-19 17:32:06,804 - INFO - Using cached data for Price
2025-04-19 17:32:06,805 - INFO - Using cached data for Price
2025-04-19 17:32:10,391 - INFO - Using cached data for Price
2025-04-19 17:32:10,392 - INFO - Using cached data for Price
2025-04-19 17:32:10,397 - INFO - Using cached data for ScowTransfer
2025-04-19 17:32:10,398 - INFO - Using cached data for Price
2025-04-19 17:32:10,398 - INFO - Using cached data for Price
2025-04-19 17:32:10,401 - INFO - Using cached data for CCCSReport
2025-04-19 17:32:10,402 - INFO - Using cached data for Price
2025-04-19 17:32:10,402 - INFO - Using cached data for Price
2025-04-19 17:32:10,405 - INFO - Using cached data for CCCSReport
2025-04-19 17:32:10,406 - INFO - Using cached data for Price
2025-04-19 17:32:10,406 - INFO - Using cached data for Price
2025-04-19 17:32:10,409 - INFO - Using cached data for CCCSReport
2025-04-19 17:32:10,409 - INFO - Using cached data for Price
2025-04-19 17:32:10,410 - INFO - Using cached data for Price
2025-04-19 17:32:11,307 - INFO - Using cached data for Price
2025-04-19 17:32:11,308 - INFO - Using cached data for Price
2025-04-19 17:32:12,311 - INFO - Using cached data for Price
2025-04-19 17:32:12,312 - INFO - Using cached data for Price
2025-04-19 17:32:12,314 - INFO - Using cached data for CCCSReport
2025-04-19 17:32:13,969 - INFO - Using cached data for Client
2025-04-19 17:32:13,970 - INFO - Using cached data for Client
2025-04-19 17:32:13,972 - INFO - Using cached data for Client
2025-04-19 17:32:13,973 - INFO - Using cached data for Client
2025-04-19 17:32:13,974 - INFO - Using cached data for Client
2025-04-19 17:32:13,976 - INFO - Using cached data for Client
2025-04-19 17:32:13,977 - INFO - Using cached data for Client
2025-04-19 17:32:13,978 - INFO - Using cached data for Client
2025-04-19 17:32:13,978 - INFO - Using cached data for Client
2025-04-19 17:32:13,978 - INFO - Using cached data for Client
2025-04-19 17:32:13,979 - INFO - Using cached data for Client
2025-04-19 17:32:13,979 - INFO - Using cached data for Client
2025-04-19 17:32:13,980 - INFO - Using cached data for CCCSReport
2025-04-19 17:32:14,891 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-19 17:32:14,891 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-19 17:32:14,892 - INFO - Using cached data for CCCSReport
2025-04-19 17:32:14,893 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-19 17:32:14,893 - INFO - Using cached data for Price
2025-04-19 17:32:14,893 - INFO - Using cached data for Price
2025-04-19 17:32:19,421 - INFO - Using cached data for CCCSReport
2025-04-19 17:32:19,422 - INFO - Using cached data for Price
2025-04-19 17:32:19,422 - INFO - Using cached data for Price
2025-04-19 17:32:20,927 - INFO - Using cached data for Price
2025-04-19 17:32:20,927 - INFO - Using cached data for Price
2025-04-19 17:32:20,937 - INFO - Using cached data for UnloadingSummary
2025-04-19 17:32:20,938 - INFO - Using cached data for containerOperations
2025-04-19 17:32:20,941 - INFO - Using cached data for Price
2025-04-19 17:32:20,941 - INFO - Using cached data for Price
2025-04-19 17:32:20,947 - INFO - Using cached data for Price
2025-04-19 17:32:20,947 - INFO - Using cached data for Price
2025-04-19 17:32:20,948 - INFO - Using cached data for UnloadingSummary
2025-04-19 17:32:20,948 - INFO - Using cached data for RawData
2025-04-19 17:32:20,949 - INFO - Using cached data for CCCSReport
2025-04-19 17:32:20,949 - INFO - Using cached data for Price
2025-04-19 17:32:20,950 - INFO - Using cached data for Price
2025-04-19 17:32:20,950 - INFO - Using cached data for containerOperations
2025-04-19 17:32:20,952 - INFO - Using cached data for Price
2025-04-19 17:32:20,952 - INFO - Using cached data for Price
2025-04-19 17:32:20,956 - INFO - Using cached data for Price
2025-04-19 17:32:20,956 - INFO - Using cached data for Price
2025-04-19 17:32:20,956 - INFO - Using cached data for RawData
2025-04-19 17:32:21,851 - INFO - Using cached data for Price
2025-04-19 17:32:21,851 - INFO - Using cached data for Price
2025-04-19 17:32:23,297 - INFO - Using cached data for Price
2025-04-19 17:32:23,297 - INFO - Using cached data for Price
2025-04-19 17:32:23,298 - INFO - Using cached data for Client
2025-04-19 17:32:24,205 - INFO - Using cached data for Price
2025-04-19 17:32:24,206 - INFO - Using cached data for Price
2025-04-19 17:32:25,217 - INFO - Using cached data for Price
2025-04-19 17:32:25,217 - INFO - Using cached data for Price
2025-04-19 17:32:25,228 - INFO - Using cached data for containerOperations
2025-04-19 17:32:25,238 - INFO - Using cached data for Price
2025-04-19 17:32:25,239 - INFO - Using cached data for Price
2025-04-19 17:32:26,273 - INFO - Using cached data for Transfer
2025-04-19 17:32:26,274 - INFO - Using cached data for Price
2025-04-19 17:32:26,274 - INFO - Using cached data for Price
2025-04-19 17:32:26,286 - INFO - Using cached data for ScowTransfer
2025-04-19 17:32:28,023 - INFO - Processing dataframe category: emr
2025-04-19 17:32:28,023 - INFO - Processing dataframes: ['shifting', 'washing', 'pti']
2025-04-19 17:32:28,024 - INFO - Processing dataframe shifting of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 17:32:28,024 - INFO - Collecting LazyFrame for shifting
2025-04-19 17:32:28,025 - ERROR - Error processing dataframe shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-04-19 17:32:28,025 - INFO - Processing dataframe washing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 17:32:28,025 - INFO - Collecting LazyFrame for washing
2025-04-19 17:32:28,031 - ERROR - Error processing dataframe washing: conversion from `str` to `enum` failed in column 'invoice_to' for 1 out of 68 values: ["OMAN PELAGIC"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-19 17:32:28,032 - INFO - Processing dataframe pti of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 17:32:28,032 - INFO - Collecting LazyFrame for pti
2025-04-19 17:32:28,038 - ERROR - Error processing dataframe pti: sub operation not supported for dtypes `str` and `str`
2025-04-19 17:32:28,038 - ERROR - Error saving shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-04-19 17:32:28,038 - ERROR - Error saving washing: conversion from `str` to `enum` failed in column 'invoice_to' for 1 out of 68 values: ["OMAN PELAGIC"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-19 17:32:28,038 - ERROR - Error saving pti: sub operation not supported for dtypes `str` and `str`
2025-04-19 17:32:28,038 - INFO - Save completed
2025-04-19 17:32:28,038 - INFO - Successfully saved: 
2025-04-19 17:32:28,038 - ERROR - Failed to save: shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS, washing: conversion from `str` to `enum` failed in column 'invoice_to' for 1 out of 68 values: ["OMAN PELAGIC"]

Ensure that all values in the input column are present in the categories of the enum datatype., pti: sub operation not supported for dtypes `str` and `str`
2025-04-19 17:33:14,229 - INFO - Exiting application
2025-04-19 17:33:17,804 - DEBUG - Using selector: EpollSelector
2025-04-19 17:33:17,804 - INFO - Starting application
2025-04-19 17:33:17,804 - INFO - Clearing screen
2025-04-19 17:33:20,917 - INFO - Selected: Save files
2025-04-19 17:33:20,917 - INFO - Clearing screen
2025-04-19 17:33:26,076 - INFO - Initiating save operation for emr
2025-04-19 17:33:27,085 - INFO - Using cached data for Price
2025-04-19 17:33:28,004 - INFO - Loading container data from sheet
2025-04-19 17:33:31,418 - INFO - Using cached data for Price
2025-04-19 17:33:31,418 - INFO - Using cached data for Price
2025-04-19 17:33:32,790 - INFO - Using cached data for Price
2025-04-19 17:33:32,790 - INFO - Using cached data for Price
2025-04-19 17:33:32,793 - INFO - Using cached data for PTI
2025-04-19 17:33:32,793 - INFO - Using cached data for Price
2025-04-19 17:33:32,794 - INFO - Using cached data for Price
2025-04-19 17:33:32,796 - INFO - Using cached data for Price
2025-04-19 17:33:32,796 - INFO - Using cached data for Price
2025-04-19 17:33:35,356 - INFO - Using cached data for Price
2025-04-19 17:33:35,356 - INFO - Using cached data for Price
2025-04-19 17:33:35,357 - INFO - Using cached data for ScowTransfer
2025-04-19 17:33:35,358 - INFO - Using cached data for Price
2025-04-19 17:33:35,358 - INFO - Using cached data for Price
2025-04-19 17:33:35,359 - INFO - Using cached data for CCCSReport
2025-04-19 17:33:35,359 - INFO - Using cached data for Price
2025-04-19 17:33:35,359 - INFO - Using cached data for Price
2025-04-19 17:33:35,361 - INFO - Using cached data for CCCSReport
2025-04-19 17:33:35,362 - INFO - Using cached data for Price
2025-04-19 17:33:35,362 - INFO - Using cached data for Price
2025-04-19 17:33:35,363 - INFO - Using cached data for CCCSReport
2025-04-19 17:33:35,364 - INFO - Using cached data for Price
2025-04-19 17:33:35,364 - INFO - Using cached data for Price
2025-04-19 17:33:36,299 - INFO - Using cached data for Price
2025-04-19 17:33:36,300 - INFO - Using cached data for Price
2025-04-19 17:33:37,303 - INFO - Using cached data for Price
2025-04-19 17:33:37,303 - INFO - Using cached data for Price
2025-04-19 17:33:37,304 - INFO - Using cached data for CCCSReport
2025-04-19 17:33:38,960 - INFO - Using cached data for Client
2025-04-19 17:33:38,962 - INFO - Using cached data for Client
2025-04-19 17:33:38,964 - INFO - Using cached data for Client
2025-04-19 17:33:38,964 - INFO - Using cached data for Client
2025-04-19 17:33:38,964 - INFO - Using cached data for Client
2025-04-19 17:33:38,965 - INFO - Using cached data for Client
2025-04-19 17:33:38,965 - INFO - Using cached data for Client
2025-04-19 17:33:38,965 - INFO - Using cached data for Client
2025-04-19 17:33:38,966 - INFO - Using cached data for Client
2025-04-19 17:33:38,966 - INFO - Using cached data for Client
2025-04-19 17:33:38,966 - INFO - Using cached data for Client
2025-04-19 17:33:38,967 - INFO - Using cached data for Client
2025-04-19 17:33:38,967 - INFO - Using cached data for CCCSReport
2025-04-19 17:33:39,917 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-19 17:33:39,919 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-19 17:33:39,920 - INFO - Using cached data for CCCSReport
2025-04-19 17:33:39,922 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-19 17:33:39,924 - INFO - Using cached data for Price
2025-04-19 17:33:39,924 - INFO - Using cached data for Price
2025-04-19 17:33:43,873 - INFO - Using cached data for CCCSReport
2025-04-19 17:33:43,874 - INFO - Using cached data for Price
2025-04-19 17:33:43,874 - INFO - Using cached data for Price
2025-04-19 17:33:45,185 - INFO - Using cached data for Price
2025-04-19 17:33:45,185 - INFO - Using cached data for Price
2025-04-19 17:33:45,194 - INFO - Using cached data for UnloadingSummary
2025-04-19 17:33:45,194 - INFO - Using cached data for containerOperations
2025-04-19 17:33:45,197 - INFO - Using cached data for Price
2025-04-19 17:33:45,197 - INFO - Using cached data for Price
2025-04-19 17:33:45,202 - INFO - Using cached data for Price
2025-04-19 17:33:45,202 - INFO - Using cached data for Price
2025-04-19 17:33:45,203 - INFO - Using cached data for UnloadingSummary
2025-04-19 17:33:45,203 - INFO - Using cached data for RawData
2025-04-19 17:33:45,203 - INFO - Using cached data for CCCSReport
2025-04-19 17:33:45,204 - INFO - Using cached data for Price
2025-04-19 17:33:45,204 - INFO - Using cached data for Price
2025-04-19 17:33:45,204 - INFO - Using cached data for containerOperations
2025-04-19 17:33:45,206 - INFO - Using cached data for Price
2025-04-19 17:33:45,207 - INFO - Using cached data for Price
2025-04-19 17:33:45,211 - INFO - Using cached data for Price
2025-04-19 17:33:45,211 - INFO - Using cached data for Price
2025-04-19 17:33:45,212 - INFO - Using cached data for RawData
2025-04-19 17:33:46,126 - INFO - Using cached data for Price
2025-04-19 17:33:46,126 - INFO - Using cached data for Price
2025-04-19 17:33:47,157 - INFO - Using cached data for Price
2025-04-19 17:33:47,158 - INFO - Using cached data for Price
2025-04-19 17:33:47,163 - INFO - Using cached data for Client
2025-04-19 17:33:48,179 - INFO - Using cached data for Price
2025-04-19 17:33:48,179 - INFO - Using cached data for Price
2025-04-19 17:33:49,172 - INFO - Using cached data for Price
2025-04-19 17:33:49,173 - INFO - Using cached data for Price
2025-04-19 17:33:49,177 - INFO - Using cached data for containerOperations
2025-04-19 17:33:49,180 - INFO - Using cached data for Price
2025-04-19 17:33:49,181 - INFO - Using cached data for Price
2025-04-19 17:33:50,230 - INFO - Using cached data for Transfer
2025-04-19 17:33:50,231 - INFO - Using cached data for Price
2025-04-19 17:33:50,231 - INFO - Using cached data for Price
2025-04-19 17:33:50,245 - INFO - Using cached data for ScowTransfer
2025-04-19 17:33:51,881 - INFO - Processing dataframe category: emr
2025-04-19 17:33:51,882 - INFO - Processing dataframes: ['shifting', 'washing', 'pti']
2025-04-19 17:33:51,883 - INFO - Processing dataframe shifting of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 17:33:51,883 - INFO - Collecting LazyFrame for shifting
2025-04-19 17:33:51,884 - ERROR - Error processing dataframe shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-04-19 17:33:51,884 - INFO - Processing dataframe washing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 17:33:51,884 - INFO - Collecting LazyFrame for washing
2025-04-19 17:33:51,924 - INFO - Successfully processed dataframe washing
2025-04-19 17:33:51,924 - INFO - Writing to output/csv/washing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-19 17:33:51,924 - INFO - Processing dataframe pti of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-19 17:33:51,925 - INFO - Collecting LazyFrame for pti
2025-04-19 17:33:51,931 - ERROR - Error processing dataframe pti: sub operation not supported for dtypes `str` and `str`
2025-04-19 17:33:51,931 - INFO - Successfully wrote washing to file
2025-04-19 17:33:51,932 - ERROR - Error saving shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-04-19 17:33:51,932 - INFO - Successfully saved washing
2025-04-19 17:33:51,932 - ERROR - Error saving pti: sub operation not supported for dtypes `str` and `str`
2025-04-19 17:33:51,932 - INFO - Save completed
2025-04-19 17:33:51,932 - INFO - Successfully saved: washing
2025-04-19 17:33:51,932 - ERROR - Failed to save: shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS, pti: sub operation not supported for dtypes `str` and `str`
2025-04-21 18:49:54,436 - DEBUG - Using selector: EpollSelector
2025-04-21 18:49:54,469 - INFO - Starting application
2025-04-21 18:49:54,469 - INFO - Clearing screen
2025-04-21 18:49:57,719 - INFO - Selected: View dataframe
2025-04-21 18:49:57,719 - INFO - Clearing screen
2025-04-21 18:49:59,615 - INFO - Selected: Save files
2025-04-21 18:49:59,615 - INFO - Clearing screen
2025-04-21 18:50:11,957 - INFO - Initiating save operation for bin_dispatch
2025-04-21 18:50:13,002 - INFO - Using cached data for Price
2025-04-21 18:50:14,442 - INFO - Loading container data from sheet
2025-04-21 18:50:17,104 - INFO - Using cached data for Price
2025-04-21 18:50:17,104 - INFO - Using cached data for Price
2025-04-21 18:50:18,449 - INFO - Using cached data for Price
2025-04-21 18:50:18,449 - INFO - Using cached data for Price
2025-04-21 18:50:18,459 - INFO - Using cached data for PTI
2025-04-21 18:50:18,460 - INFO - Using cached data for Price
2025-04-21 18:50:18,460 - INFO - Using cached data for Price
2025-04-21 18:50:18,467 - INFO - Using cached data for Price
2025-04-21 18:50:18,467 - INFO - Using cached data for Price
2025-04-21 18:50:21,972 - INFO - Using cached data for Price
2025-04-21 18:50:21,972 - INFO - Using cached data for Price
2025-04-21 18:50:21,973 - INFO - Using cached data for ScowTransfer
2025-04-21 18:50:21,974 - INFO - Using cached data for Price
2025-04-21 18:50:21,974 - INFO - Using cached data for Price
2025-04-21 18:50:21,975 - INFO - Using cached data for CCCSReport
2025-04-21 18:50:21,975 - INFO - Using cached data for Price
2025-04-21 18:50:21,975 - INFO - Using cached data for Price
2025-04-21 18:50:21,976 - INFO - Using cached data for CCCSReport
2025-04-21 18:50:21,977 - INFO - Using cached data for Price
2025-04-21 18:50:21,977 - INFO - Using cached data for Price
2025-04-21 18:50:21,979 - INFO - Using cached data for CCCSReport
2025-04-21 18:50:21,979 - INFO - Using cached data for Price
2025-04-21 18:50:21,979 - INFO - Using cached data for Price
2025-04-21 18:50:22,831 - INFO - Using cached data for Price
2025-04-21 18:50:22,832 - INFO - Using cached data for Price
2025-04-21 18:50:23,838 - INFO - Using cached data for Price
2025-04-21 18:50:23,838 - INFO - Using cached data for Price
2025-04-21 18:50:23,842 - INFO - Using cached data for CCCSReport
2025-04-21 18:50:24,959 - INFO - Using cached data for Client
2025-04-21 18:50:24,960 - INFO - Using cached data for Client
2025-04-21 18:50:24,962 - INFO - Using cached data for Client
2025-04-21 18:50:24,963 - INFO - Using cached data for Client
2025-04-21 18:50:24,964 - INFO - Using cached data for Client
2025-04-21 18:50:24,965 - INFO - Using cached data for Client
2025-04-21 18:50:24,965 - INFO - Using cached data for Client
2025-04-21 18:50:24,965 - INFO - Using cached data for Client
2025-04-21 18:50:24,965 - INFO - Using cached data for Client
2025-04-21 18:50:24,966 - INFO - Using cached data for Client
2025-04-21 18:50:24,966 - INFO - Using cached data for Client
2025-04-21 18:50:24,967 - INFO - Using cached data for Client
2025-04-21 18:50:24,967 - INFO - Using cached data for CCCSReport
2025-04-21 18:50:25,913 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 18:50:25,916 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 18:50:25,916 - INFO - Using cached data for CCCSReport
2025-04-21 18:50:25,917 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 18:50:25,917 - INFO - Using cached data for Price
2025-04-21 18:50:25,917 - INFO - Using cached data for Price
2025-04-21 18:50:31,048 - INFO - Using cached data for CCCSReport
2025-04-21 18:50:31,049 - INFO - Using cached data for Price
2025-04-21 18:50:31,049 - INFO - Using cached data for Price
2025-04-21 18:50:32,538 - INFO - Using cached data for Price
2025-04-21 18:50:32,538 - INFO - Using cached data for Price
2025-04-21 18:50:32,544 - INFO - Using cached data for UnloadingSummary
2025-04-21 18:50:32,544 - INFO - Using cached data for containerOperations
2025-04-21 18:50:32,545 - INFO - Using cached data for Price
2025-04-21 18:50:32,545 - INFO - Using cached data for Price
2025-04-21 18:50:32,548 - INFO - Using cached data for Price
2025-04-21 18:50:32,549 - INFO - Using cached data for Price
2025-04-21 18:50:32,549 - INFO - Using cached data for UnloadingSummary
2025-04-21 18:50:32,549 - INFO - Using cached data for RawData
2025-04-21 18:50:32,549 - INFO - Using cached data for CCCSReport
2025-04-21 18:50:32,550 - INFO - Using cached data for Price
2025-04-21 18:50:32,550 - INFO - Using cached data for Price
2025-04-21 18:50:32,550 - INFO - Using cached data for containerOperations
2025-04-21 18:50:32,552 - INFO - Using cached data for Price
2025-04-21 18:50:32,552 - INFO - Using cached data for Price
2025-04-21 18:50:32,556 - INFO - Using cached data for Price
2025-04-21 18:50:32,556 - INFO - Using cached data for Price
2025-04-21 18:50:32,556 - INFO - Using cached data for RawData
2025-04-21 18:50:33,991 - INFO - Using cached data for Price
2025-04-21 18:50:33,991 - INFO - Using cached data for Price
2025-04-21 18:50:35,640 - INFO - Using cached data for Price
2025-04-21 18:50:35,641 - INFO - Using cached data for Price
2025-04-21 18:50:35,645 - INFO - Using cached data for Client
2025-04-21 18:50:35,681 - INFO - Using cached data for SaltOperation
2025-04-21 18:50:35,681 - INFO - Using cached data for Price
2025-04-21 18:50:35,681 - INFO - Using cached data for Price
2025-04-21 18:50:35,684 - INFO - Using cached data for Client
2025-04-21 18:50:36,957 - INFO - Using cached data for Price
2025-04-21 18:50:36,958 - INFO - Using cached data for Price
2025-04-21 18:50:37,979 - INFO - Using cached data for Price
2025-04-21 18:50:37,980 - INFO - Using cached data for Price
2025-04-21 18:50:37,983 - INFO - Using cached data for containerOperations
2025-04-21 18:50:37,986 - INFO - Using cached data for Price
2025-04-21 18:50:37,986 - INFO - Using cached data for Price
2025-04-21 18:50:39,031 - INFO - Using cached data for Transfer
2025-04-21 18:50:39,031 - INFO - Using cached data for Price
2025-04-21 18:50:39,031 - INFO - Using cached data for Price
2025-04-21 18:50:39,035 - INFO - Using cached data for ScowTransfer
2025-04-21 18:50:40,612 - INFO - Processing dataframe category: bin_dispatch
2025-04-21 18:50:40,612 - INFO - Processing dataframes: ['full_scows_transfer', 'empty_scows_transfer']
2025-04-21 18:50:40,613 - INFO - Processing dataframe full_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 18:50:40,613 - INFO - Collecting LazyFrame for full_scows_transfer
2025-04-21 18:50:40,663 - ERROR - Error processing dataframe full_scows_transfer: datatypes of join keys don't match - `date`: date on left does not match `date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [[(col("total_tonnage")) - (col("overtime_tonnage").cast(Float64))].alias("normal_tonnage")] 
   SELECT [col("day").alias("day_name"), col("date"), col("movement_type").strict_cast(Enum(Some(local), Physical)), col("customer"), col("operation_type"), col("total_tonnage").abs().strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float32).round()] FROM
    FILTER col("operation_type").is_in([Series]) FROM
      FILTER [(col("date").dt.year()) >= (2024)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-21 18:50:40,663 - INFO - Processing dataframe empty_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 18:50:40,664 - INFO - Collecting LazyFrame for empty_scows_transfer
2025-04-21 18:50:40,665 - ERROR - Error processing dataframe empty_scows_transfer: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("Service"), col("Price"), col("Date")] FROM
  FILTER col("Service").is_in([Series]) FROM
     WITH_COLUMNS:
     [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
      DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-21 18:50:40,666 - ERROR - Error saving full_scows_transfer: datatypes of join keys don't match - `date`: date on left does not match `date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [[(col("total_tonnage")) - (col("overtime_tonnage").cast(Float64))].alias("normal_tonnage")] 
   SELECT [col("day").alias("day_name"), col("date"), col("movement_type").strict_cast(Enum(Some(local), Physical)), col("customer"), col("operation_type"), col("total_tonnage").abs().strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float32).round()] FROM
    FILTER col("operation_type").is_in([Series]) FROM
      FILTER [(col("date").dt.year()) >= (2024)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-21 18:50:40,666 - ERROR - Error saving empty_scows_transfer: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("Service"), col("Price"), col("Date")] FROM
  FILTER col("Service").is_in([Series]) FROM
     WITH_COLUMNS:
     [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
      DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-21 18:50:40,667 - INFO - Save completed
2025-04-21 18:50:40,667 - INFO - Successfully saved: 
2025-04-21 18:50:40,667 - ERROR - Failed to save: full_scows_transfer: datatypes of join keys don't match - `date`: date on left does not match `date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [[(col("total_tonnage")) - (col("overtime_tonnage").cast(Float64))].alias("normal_tonnage")] 
   SELECT [col("day").alias("day_name"), col("date"), col("movement_type").strict_cast(Enum(Some(local), Physical)), col("customer"), col("operation_type"), col("total_tonnage").abs().strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float32).round()] FROM
    FILTER col("operation_type").is_in([Series]) FROM
      FILTER [(col("date").dt.year()) >= (2024)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS, empty_scows_transfer: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("Service"), col("Price"), col("Date")] FROM
  FILTER col("Service").is_in([Series]) FROM
     WITH_COLUMNS:
     [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
      DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-21 18:54:39,168 - INFO - Exiting application
2025-04-21 18:54:42,793 - DEBUG - Using selector: EpollSelector
2025-04-21 18:54:42,793 - INFO - Starting application
2025-04-21 18:54:42,793 - INFO - Clearing screen
2025-04-21 18:54:44,921 - INFO - Selected: Save files
2025-04-21 18:54:44,921 - INFO - Clearing screen
2025-04-21 18:54:54,721 - INFO - Initiating save operation for bin_dispatch
2025-04-21 18:54:55,608 - INFO - Using cached data for Price
2025-04-21 18:54:56,598 - INFO - Loading container data from sheet
2025-04-21 18:54:59,386 - INFO - Using cached data for Price
2025-04-21 18:54:59,386 - INFO - Using cached data for Price
2025-04-21 18:55:00,698 - INFO - Using cached data for Price
2025-04-21 18:55:00,698 - INFO - Using cached data for Price
2025-04-21 18:55:00,705 - INFO - Using cached data for PTI
2025-04-21 18:55:00,705 - INFO - Using cached data for Price
2025-04-21 18:55:00,705 - INFO - Using cached data for Price
2025-04-21 18:55:00,708 - INFO - Using cached data for Price
2025-04-21 18:55:00,708 - INFO - Using cached data for Price
2025-04-21 18:55:03,805 - INFO - Using cached data for Price
2025-04-21 18:55:03,805 - INFO - Using cached data for Price
2025-04-21 18:55:03,809 - INFO - Using cached data for ScowTransfer
2025-04-21 18:55:03,810 - INFO - Using cached data for Price
2025-04-21 18:55:03,810 - INFO - Using cached data for Price
2025-04-21 18:55:03,813 - INFO - Using cached data for CCCSReport
2025-04-21 18:55:03,814 - INFO - Using cached data for Price
2025-04-21 18:55:03,814 - INFO - Using cached data for Price
2025-04-21 18:55:03,818 - INFO - Using cached data for CCCSReport
2025-04-21 18:55:03,820 - INFO - Using cached data for Price
2025-04-21 18:55:03,820 - INFO - Using cached data for Price
2025-04-21 18:55:03,824 - INFO - Using cached data for CCCSReport
2025-04-21 18:55:03,825 - INFO - Using cached data for Price
2025-04-21 18:55:03,825 - INFO - Using cached data for Price
2025-04-21 18:55:05,069 - INFO - Using cached data for Price
2025-04-21 18:55:05,070 - INFO - Using cached data for Price
2025-04-21 18:55:06,401 - INFO - Using cached data for Price
2025-04-21 18:55:06,402 - INFO - Using cached data for Price
2025-04-21 18:55:06,405 - INFO - Using cached data for CCCSReport
2025-04-21 18:55:07,788 - INFO - Using cached data for Client
2025-04-21 18:55:07,788 - INFO - Using cached data for Client
2025-04-21 18:55:07,789 - INFO - Using cached data for Client
2025-04-21 18:55:07,789 - INFO - Using cached data for Client
2025-04-21 18:55:07,789 - INFO - Using cached data for Client
2025-04-21 18:55:07,790 - INFO - Using cached data for Client
2025-04-21 18:55:07,790 - INFO - Using cached data for Client
2025-04-21 18:55:07,790 - INFO - Using cached data for Client
2025-04-21 18:55:07,791 - INFO - Using cached data for Client
2025-04-21 18:55:07,791 - INFO - Using cached data for Client
2025-04-21 18:55:07,791 - INFO - Using cached data for Client
2025-04-21 18:55:07,792 - INFO - Using cached data for Client
2025-04-21 18:55:07,792 - INFO - Using cached data for CCCSReport
2025-04-21 18:55:08,683 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 18:55:08,684 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 18:55:08,685 - INFO - Using cached data for CCCSReport
2025-04-21 18:55:08,686 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 18:55:08,687 - INFO - Using cached data for Price
2025-04-21 18:55:08,688 - INFO - Using cached data for Price
2025-04-21 18:55:12,867 - INFO - Using cached data for CCCSReport
2025-04-21 18:55:12,868 - INFO - Using cached data for Price
2025-04-21 18:55:12,868 - INFO - Using cached data for Price
2025-04-21 18:55:14,376 - INFO - Using cached data for Price
2025-04-21 18:55:14,377 - INFO - Using cached data for Price
2025-04-21 18:55:14,383 - INFO - Using cached data for UnloadingSummary
2025-04-21 18:55:14,383 - INFO - Using cached data for containerOperations
2025-04-21 18:55:14,385 - INFO - Using cached data for Price
2025-04-21 18:55:14,386 - INFO - Using cached data for Price
2025-04-21 18:55:14,391 - INFO - Using cached data for Price
2025-04-21 18:55:14,391 - INFO - Using cached data for Price
2025-04-21 18:55:14,392 - INFO - Using cached data for UnloadingSummary
2025-04-21 18:55:14,392 - INFO - Using cached data for RawData
2025-04-21 18:55:14,392 - INFO - Using cached data for CCCSReport
2025-04-21 18:55:14,393 - INFO - Using cached data for Price
2025-04-21 18:55:14,393 - INFO - Using cached data for Price
2025-04-21 18:55:14,394 - INFO - Using cached data for containerOperations
2025-04-21 18:55:14,396 - INFO - Using cached data for Price
2025-04-21 18:55:14,396 - INFO - Using cached data for Price
2025-04-21 18:55:14,400 - INFO - Using cached data for Price
2025-04-21 18:55:14,400 - INFO - Using cached data for Price
2025-04-21 18:55:14,400 - INFO - Using cached data for RawData
2025-04-21 18:55:15,571 - INFO - Using cached data for Price
2025-04-21 18:55:15,571 - INFO - Using cached data for Price
2025-04-21 18:55:16,820 - INFO - Using cached data for Price
2025-04-21 18:55:16,820 - INFO - Using cached data for Price
2025-04-21 18:55:16,822 - INFO - Using cached data for Client
2025-04-21 18:55:16,825 - INFO - Using cached data for SaltOperation
2025-04-21 18:55:16,825 - INFO - Using cached data for Price
2025-04-21 18:55:16,825 - INFO - Using cached data for Price
2025-04-21 18:55:16,827 - INFO - Using cached data for Client
2025-04-21 18:55:17,827 - INFO - Using cached data for Price
2025-04-21 18:55:17,827 - INFO - Using cached data for Price
2025-04-21 18:55:18,941 - INFO - Using cached data for Price
2025-04-21 18:55:18,941 - INFO - Using cached data for Price
2025-04-21 18:55:18,952 - INFO - Using cached data for containerOperations
2025-04-21 18:55:18,959 - INFO - Using cached data for Price
2025-04-21 18:55:18,960 - INFO - Using cached data for Price
2025-04-21 18:55:19,882 - INFO - Using cached data for Transfer
2025-04-21 18:55:19,882 - INFO - Using cached data for Price
2025-04-21 18:55:19,882 - INFO - Using cached data for Price
2025-04-21 18:55:19,897 - INFO - Using cached data for ScowTransfer
2025-04-21 18:55:21,445 - INFO - Processing dataframe category: bin_dispatch
2025-04-21 18:55:21,446 - INFO - Processing dataframes: ['full_scows_transfer', 'empty_scows_transfer']
2025-04-21 18:55:21,447 - INFO - Processing dataframe full_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 18:55:21,447 - INFO - Collecting LazyFrame for full_scows_transfer
2025-04-21 18:55:21,448 - ERROR - Error processing dataframe full_scows_transfer: datatypes of join keys don't match - `date`: date on left does not match `date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [[(col("total_tonnage")) - (col("overtime_tonnage").cast(Float64))].alias("normal_tonnage")] 
   SELECT [col("day").alias("day_name"), col("date"), col("movement_type").strict_cast(Enum(Some(local), Physical)), col("customer"), col("operation_type"), col("total_tonnage").abs().strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float32).round()] FROM
    FILTER col("operation_type").is_in([Series]) FROM
      FILTER [(col("date").dt.year()) >= (2024)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-21 18:55:21,449 - INFO - Processing dataframe empty_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 18:55:21,449 - INFO - Collecting LazyFrame for empty_scows_transfer
2025-04-21 18:55:21,595 - INFO - Successfully processed dataframe empty_scows_transfer
2025-04-21 18:55:21,596 - INFO - Writing to output/csv/empty_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-21 18:55:21,662 - INFO - Successfully wrote empty_scows_transfer to file
2025-04-21 18:55:21,662 - ERROR - Error saving full_scows_transfer: datatypes of join keys don't match - `date`: date on left does not match `date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [[(col("total_tonnage")) - (col("overtime_tonnage").cast(Float64))].alias("normal_tonnage")] 
   SELECT [col("day").alias("day_name"), col("date"), col("movement_type").strict_cast(Enum(Some(local), Physical)), col("customer"), col("operation_type"), col("total_tonnage").abs().strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float32).round()] FROM
    FILTER col("operation_type").is_in([Series]) FROM
      FILTER [(col("date").dt.year()) >= (2024)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-21 18:55:21,663 - INFO - Successfully saved empty_scows_transfer
2025-04-21 18:55:21,663 - INFO - Save completed
2025-04-21 18:55:21,663 - INFO - Successfully saved: empty_scows_transfer
2025-04-21 18:55:21,664 - ERROR - Failed to save: full_scows_transfer: datatypes of join keys don't match - `date`: date on left does not match `date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [[(col("total_tonnage")) - (col("overtime_tonnage").cast(Float64))].alias("normal_tonnage")] 
   SELECT [col("day").alias("day_name"), col("date"), col("movement_type").strict_cast(Enum(Some(local), Physical)), col("customer"), col("operation_type"), col("total_tonnage").abs().strict_cast(Float64).round(), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float32).round()] FROM
    FILTER col("operation_type").is_in([Series]) FROM
      FILTER [(col("date").dt.year()) >= (2024)] FROM
        DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-21 19:04:16,167 - INFO - Starting application
2025-04-21 19:04:16,168 - INFO - Clearing screen
2025-04-21 19:04:21,368 - INFO - Exiting application
2025-04-21 19:04:24,346 - DEBUG - Using selector: EpollSelector
2025-04-21 19:04:24,346 - INFO - Starting application
2025-04-21 19:04:24,346 - INFO - Clearing screen
2025-04-21 19:04:27,096 - INFO - Selected: Save files
2025-04-21 19:04:27,096 - INFO - Clearing screen
2025-04-21 19:04:37,425 - INFO - Initiating save operation for bin_dispatch
2025-04-21 19:04:38,475 - INFO - Using cached data for Price
2025-04-21 19:04:39,411 - INFO - Loading container data from sheet
2025-04-21 19:04:42,157 - INFO - Using cached data for Price
2025-04-21 19:04:42,157 - INFO - Using cached data for Price
2025-04-21 19:04:43,411 - INFO - Using cached data for Price
2025-04-21 19:04:43,412 - INFO - Using cached data for Price
2025-04-21 19:04:43,423 - INFO - Using cached data for PTI
2025-04-21 19:04:43,423 - INFO - Using cached data for Price
2025-04-21 19:04:43,424 - INFO - Using cached data for Price
2025-04-21 19:04:43,432 - INFO - Using cached data for Price
2025-04-21 19:04:43,432 - INFO - Using cached data for Price
2025-04-21 19:04:46,397 - INFO - Using cached data for Price
2025-04-21 19:04:46,398 - INFO - Using cached data for Price
2025-04-21 19:04:46,399 - INFO - Using cached data for ScowTransfer
2025-04-21 19:04:46,400 - INFO - Using cached data for Price
2025-04-21 19:04:46,400 - INFO - Using cached data for Price
2025-04-21 19:04:46,401 - INFO - Using cached data for CCCSReport
2025-04-21 19:04:46,401 - INFO - Using cached data for Price
2025-04-21 19:04:46,401 - INFO - Using cached data for Price
2025-04-21 19:04:46,403 - INFO - Using cached data for CCCSReport
2025-04-21 19:04:46,403 - INFO - Using cached data for Price
2025-04-21 19:04:46,403 - INFO - Using cached data for Price
2025-04-21 19:04:46,405 - INFO - Using cached data for CCCSReport
2025-04-21 19:04:46,405 - INFO - Using cached data for Price
2025-04-21 19:04:46,405 - INFO - Using cached data for Price
2025-04-21 19:04:47,619 - INFO - Using cached data for Price
2025-04-21 19:04:47,619 - INFO - Using cached data for Price
2025-04-21 19:04:48,900 - INFO - Using cached data for Price
2025-04-21 19:04:48,900 - INFO - Using cached data for Price
2025-04-21 19:04:48,902 - INFO - Using cached data for CCCSReport
2025-04-21 19:04:49,854 - INFO - Using cached data for Client
2025-04-21 19:04:49,856 - INFO - Using cached data for Client
2025-04-21 19:04:49,857 - INFO - Using cached data for Client
2025-04-21 19:04:49,859 - INFO - Using cached data for Client
2025-04-21 19:04:49,860 - INFO - Using cached data for Client
2025-04-21 19:04:49,861 - INFO - Using cached data for Client
2025-04-21 19:04:49,862 - INFO - Using cached data for Client
2025-04-21 19:04:49,864 - INFO - Using cached data for Client
2025-04-21 19:04:49,865 - INFO - Using cached data for Client
2025-04-21 19:04:49,866 - INFO - Using cached data for Client
2025-04-21 19:04:49,866 - INFO - Using cached data for Client
2025-04-21 19:04:49,866 - INFO - Using cached data for Client
2025-04-21 19:04:49,867 - INFO - Using cached data for CCCSReport
2025-04-21 19:04:50,894 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:04:50,896 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:04:50,898 - INFO - Using cached data for CCCSReport
2025-04-21 19:04:50,899 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:04:50,900 - INFO - Using cached data for Price
2025-04-21 19:04:50,900 - INFO - Using cached data for Price
2025-04-21 19:04:56,284 - INFO - Using cached data for CCCSReport
2025-04-21 19:04:56,285 - INFO - Using cached data for Price
2025-04-21 19:04:56,285 - INFO - Using cached data for Price
2025-04-21 19:04:59,002 - INFO - Using cached data for Price
2025-04-21 19:04:59,002 - INFO - Using cached data for Price
2025-04-21 19:04:59,020 - INFO - Using cached data for UnloadingSummary
2025-04-21 19:04:59,020 - INFO - Using cached data for containerOperations
2025-04-21 19:04:59,023 - INFO - Using cached data for Price
2025-04-21 19:04:59,024 - INFO - Using cached data for Price
2025-04-21 19:04:59,029 - INFO - Using cached data for Price
2025-04-21 19:04:59,029 - INFO - Using cached data for Price
2025-04-21 19:04:59,030 - INFO - Using cached data for UnloadingSummary
2025-04-21 19:04:59,030 - INFO - Using cached data for RawData
2025-04-21 19:04:59,031 - INFO - Using cached data for CCCSReport
2025-04-21 19:04:59,031 - INFO - Using cached data for Price
2025-04-21 19:04:59,032 - INFO - Using cached data for Price
2025-04-21 19:04:59,032 - INFO - Using cached data for containerOperations
2025-04-21 19:04:59,035 - INFO - Using cached data for Price
2025-04-21 19:04:59,035 - INFO - Using cached data for Price
2025-04-21 19:04:59,040 - INFO - Using cached data for Price
2025-04-21 19:04:59,040 - INFO - Using cached data for Price
2025-04-21 19:04:59,040 - INFO - Using cached data for RawData
2025-04-21 19:04:59,978 - INFO - Using cached data for Price
2025-04-21 19:04:59,979 - INFO - Using cached data for Price
2025-04-21 19:05:01,410 - INFO - Using cached data for Price
2025-04-21 19:05:01,410 - INFO - Using cached data for Price
2025-04-21 19:05:01,414 - INFO - Using cached data for Client
2025-04-21 19:05:01,419 - INFO - Using cached data for SaltOperation
2025-04-21 19:05:01,419 - INFO - Using cached data for Price
2025-04-21 19:05:01,419 - INFO - Using cached data for Price
2025-04-21 19:05:01,423 - INFO - Using cached data for Client
2025-04-21 19:05:02,442 - INFO - Using cached data for Price
2025-04-21 19:05:02,442 - INFO - Using cached data for Price
2025-04-21 19:05:03,550 - INFO - Using cached data for Price
2025-04-21 19:05:03,550 - INFO - Using cached data for Price
2025-04-21 19:05:03,561 - INFO - Using cached data for containerOperations
2025-04-21 19:05:03,568 - INFO - Using cached data for Price
2025-04-21 19:05:03,569 - INFO - Using cached data for Price
2025-04-21 19:05:04,487 - INFO - Using cached data for Transfer
2025-04-21 19:05:04,488 - INFO - Using cached data for Price
2025-04-21 19:05:04,488 - INFO - Using cached data for Price
2025-04-21 19:05:04,503 - INFO - Using cached data for ScowTransfer
2025-04-21 19:05:06,046 - INFO - Processing dataframe category: bin_dispatch
2025-04-21 19:05:06,046 - INFO - Processing dataframes: ['full_scows_transfer', 'empty_scows_transfer']
2025-04-21 19:05:06,047 - INFO - Processing dataframe full_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 19:05:06,047 - INFO - Collecting LazyFrame for full_scows_transfer
2025-04-21 19:05:06,074 - INFO - Successfully processed dataframe full_scows_transfer
2025-04-21 19:05:06,074 - INFO - Writing to output/csv/full_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-21 19:05:06,074 - INFO - Processing dataframe empty_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 19:05:06,075 - INFO - Collecting LazyFrame for empty_scows_transfer
2025-04-21 19:05:06,084 - INFO - Successfully processed dataframe empty_scows_transfer
2025-04-21 19:05:06,084 - INFO - Successfully wrote full_scows_transfer to file
2025-04-21 19:05:06,084 - INFO - Writing to output/csv/empty_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-21 19:05:06,085 - INFO - Successfully wrote empty_scows_transfer to file
2025-04-21 19:05:06,085 - INFO - Successfully saved full_scows_transfer
2025-04-21 19:05:06,086 - INFO - Successfully saved empty_scows_transfer
2025-04-21 19:05:06,086 - INFO - Save completed
2025-04-21 19:05:06,086 - INFO - Successfully saved: full_scows_transfer, empty_scows_transfer
2025-04-21 19:06:06,222 - INFO - Starting application
2025-04-21 19:06:06,222 - INFO - Clearing screen
2025-04-21 19:06:08,854 - INFO - Selected: Save files
2025-04-21 19:06:08,854 - INFO - Clearing screen
2025-04-21 19:06:18,262 - INFO - Initiating save operation for shore_handling
2025-04-21 19:06:18,262 - INFO - Using cached data for Price
2025-04-21 19:06:18,262 - INFO - Using cached data for Price
2025-04-21 19:06:18,265 - INFO - Using cached data for ContainerShifting
2025-04-21 19:06:18,268 - INFO - Using cached data for ContainerCleaning
2025-04-21 19:06:18,270 - INFO - Using cached data for Price
2025-04-21 19:06:18,270 - INFO - Using cached data for Price
2025-04-21 19:06:18,272 - INFO - Using cached data for PTI
2025-04-21 19:06:18,272 - INFO - Using cached data for Price
2025-04-21 19:06:18,272 - INFO - Using cached data for Price
2025-04-21 19:06:18,274 - INFO - Using cached data for PTI
2025-04-21 19:06:18,274 - INFO - Using cached data for Price
2025-04-21 19:06:18,274 - INFO - Using cached data for Price
2025-04-21 19:06:18,275 - INFO - Using cached data for Price
2025-04-21 19:06:18,275 - INFO - Using cached data for Price
2025-04-21 19:06:18,278 - INFO - Using cached data for ScowTransfer
2025-04-21 19:06:18,279 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:18,279 - INFO - Using cached data for Price
2025-04-21 19:06:18,279 - INFO - Using cached data for Price
2025-04-21 19:06:18,280 - INFO - Using cached data for ScowTransfer
2025-04-21 19:06:18,280 - INFO - Using cached data for Price
2025-04-21 19:06:18,280 - INFO - Using cached data for Price
2025-04-21 19:06:18,281 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:18,281 - INFO - Using cached data for Price
2025-04-21 19:06:18,281 - INFO - Using cached data for Price
2025-04-21 19:06:18,283 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:18,283 - INFO - Using cached data for Price
2025-04-21 19:06:18,283 - INFO - Using cached data for Price
2025-04-21 19:06:18,284 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:18,284 - INFO - Using cached data for Price
2025-04-21 19:06:18,284 - INFO - Using cached data for Price
2025-04-21 19:06:18,285 - INFO - Using cached data for CrossStuffing
2025-04-21 19:06:18,286 - INFO - Using cached data for Price
2025-04-21 19:06:18,286 - INFO - Using cached data for Price
2025-04-21 19:06:18,286 - INFO - Using cached data for CCCSContainerStuffing
2025-04-21 19:06:18,288 - INFO - Using cached data for Price
2025-04-21 19:06:18,288 - INFO - Using cached data for Price
2025-04-21 19:06:18,289 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:18,289 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:18,289 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:06:18,290 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:06:18,290 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:06:18,291 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:18,291 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:06:18,291 - INFO - Using cached data for Price
2025-04-21 19:06:18,291 - INFO - Using cached data for Price
2025-04-21 19:06:18,292 - INFO - Using cached data for UnloadingSummary
2025-04-21 19:06:18,292 - INFO - Using cached data for RawData
2025-04-21 19:06:18,292 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:18,293 - INFO - Using cached data for Price
2025-04-21 19:06:18,293 - INFO - Using cached data for Price
2025-04-21 19:06:18,293 - INFO - Using cached data for containerOperations
2025-04-21 19:06:18,295 - INFO - Using cached data for Price
2025-04-21 19:06:18,295 - INFO - Using cached data for Price
2025-04-21 19:06:18,298 - INFO - Using cached data for UnloadingSummary
2025-04-21 19:06:18,298 - INFO - Using cached data for containerOperations
2025-04-21 19:06:18,301 - INFO - Using cached data for Price
2025-04-21 19:06:18,301 - INFO - Using cached data for Price
2025-04-21 19:06:18,309 - INFO - Using cached data for Price
2025-04-21 19:06:18,309 - INFO - Using cached data for Price
2025-04-21 19:06:18,310 - INFO - Using cached data for UnloadingSummary
2025-04-21 19:06:18,310 - INFO - Using cached data for RawData
2025-04-21 19:06:18,310 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:18,311 - INFO - Using cached data for Price
2025-04-21 19:06:18,311 - INFO - Using cached data for Price
2025-04-21 19:06:18,311 - INFO - Using cached data for containerOperations
2025-04-21 19:06:18,313 - INFO - Using cached data for Price
2025-04-21 19:06:18,313 - INFO - Using cached data for Price
2025-04-21 19:06:18,318 - INFO - Using cached data for Price
2025-04-21 19:06:18,318 - INFO - Using cached data for Price
2025-04-21 19:06:18,319 - INFO - Using cached data for RawData
2025-04-21 19:06:18,319 - INFO - Using cached data for WelltoWell
2025-04-21 19:06:18,319 - INFO - Using cached data for Price
2025-04-21 19:06:18,319 - INFO - Using cached data for Price
2025-04-21 19:06:18,319 - INFO - Using cached data for SaltOperation
2025-04-21 19:06:18,320 - INFO - Using cached data for Price
2025-04-21 19:06:18,320 - INFO - Using cached data for Price
2025-04-21 19:06:18,320 - INFO - Using cached data for Client
2025-04-21 19:06:18,321 - INFO - Using cached data for SaltOperation
2025-04-21 19:06:18,321 - INFO - Using cached data for Price
2025-04-21 19:06:18,322 - INFO - Using cached data for Price
2025-04-21 19:06:18,322 - INFO - Using cached data for Client
2025-04-21 19:06:18,326 - INFO - Using cached data for BinTipping
2025-04-21 19:06:18,326 - INFO - Using cached data for Price
2025-04-21 19:06:18,326 - INFO - Using cached data for Price
2025-04-21 19:06:18,327 - INFO - Using cached data for LinerPallet
2025-04-21 19:06:18,329 - INFO - Using cached data for Price
2025-04-21 19:06:18,329 - INFO - Using cached data for Price
2025-04-21 19:06:18,331 - INFO - Using cached data for containerOperations
2025-04-21 19:06:18,333 - INFO - Using cached data for Price
2025-04-21 19:06:18,333 - INFO - Using cached data for Price
2025-04-21 19:06:18,336 - INFO - Using cached data for ShoreCrane
2025-04-21 19:06:18,336 - INFO - Using cached data for Transfer
2025-04-21 19:06:18,336 - INFO - Using cached data for Price
2025-04-21 19:06:18,336 - INFO - Using cached data for Price
2025-04-21 19:06:18,339 - INFO - Using cached data for ScowTransfer
2025-04-21 19:06:18,339 - INFO - Using cached data for ForkliftRecord
2025-04-21 19:06:18,340 - INFO - Processing dataframe category: shore_handling
2025-04-21 19:06:18,340 - INFO - Processing dataframes: ['salt', 'forklift_salt', 'bin_tipping']
2025-04-21 19:06:18,340 - INFO - Processing dataframe salt of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 19:06:18,340 - INFO - Collecting LazyFrame for salt
2025-04-21 19:06:18,358 - INFO - Successfully processed dataframe salt
2025-04-21 19:06:18,358 - INFO - Writing to output/csv/salt.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-21 19:06:18,358 - INFO - Processing dataframe forklift_salt of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 19:06:18,359 - INFO - Collecting LazyFrame for forklift_salt
2025-04-21 19:06:18,397 - INFO - Successfully processed dataframe forklift_salt
2025-04-21 19:06:18,398 - INFO - Writing to output/csv/forklift_salt.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-21 19:06:18,398 - INFO - Processing dataframe bin_tipping of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 19:06:18,398 - INFO - Collecting LazyFrame for bin_tipping
2025-04-21 19:06:18,433 - INFO - Successfully processed dataframe bin_tipping
2025-04-21 19:06:18,433 - INFO - Writing to output/csv/bin_tipping.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-21 19:06:18,433 - INFO - Successfully wrote salt to file
2025-04-21 19:06:18,434 - INFO - Successfully wrote forklift_salt to file
2025-04-21 19:06:18,434 - INFO - Successfully wrote bin_tipping to file
2025-04-21 19:06:18,434 - INFO - Successfully saved salt
2025-04-21 19:06:18,434 - INFO - Successfully saved forklift_salt
2025-04-21 19:06:18,434 - INFO - Successfully saved bin_tipping
2025-04-21 19:06:18,434 - INFO - Save completed
2025-04-21 19:06:18,434 - INFO - Successfully saved: salt, forklift_salt, bin_tipping
2025-04-21 19:06:37,690 - INFO - Starting application
2025-04-21 19:06:37,690 - INFO - Clearing screen
2025-04-21 19:06:39,930 - INFO - Selected: Save files
2025-04-21 19:06:39,930 - INFO - Clearing screen
2025-04-21 19:06:47,522 - INFO - Initiating save operation for netlist
2025-04-21 19:06:47,522 - INFO - Using cached data for Price
2025-04-21 19:06:47,523 - INFO - Using cached data for Price
2025-04-21 19:06:47,532 - INFO - Using cached data for ContainerShifting
2025-04-21 19:06:47,541 - INFO - Using cached data for ContainerCleaning
2025-04-21 19:06:47,548 - INFO - Using cached data for Price
2025-04-21 19:06:47,549 - INFO - Using cached data for Price
2025-04-21 19:06:47,556 - INFO - Using cached data for PTI
2025-04-21 19:06:47,556 - INFO - Using cached data for Price
2025-04-21 19:06:47,556 - INFO - Using cached data for Price
2025-04-21 19:06:47,562 - INFO - Using cached data for PTI
2025-04-21 19:06:47,562 - INFO - Using cached data for Price
2025-04-21 19:06:47,562 - INFO - Using cached data for Price
2025-04-21 19:06:47,567 - INFO - Using cached data for Price
2025-04-21 19:06:47,567 - INFO - Using cached data for Price
2025-04-21 19:06:47,575 - INFO - Using cached data for ScowTransfer
2025-04-21 19:06:47,576 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:47,577 - INFO - Using cached data for Price
2025-04-21 19:06:47,577 - INFO - Using cached data for Price
2025-04-21 19:06:47,579 - INFO - Using cached data for ScowTransfer
2025-04-21 19:06:47,579 - INFO - Using cached data for Price
2025-04-21 19:06:47,579 - INFO - Using cached data for Price
2025-04-21 19:06:47,580 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:47,581 - INFO - Using cached data for Price
2025-04-21 19:06:47,581 - INFO - Using cached data for Price
2025-04-21 19:06:47,583 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:47,583 - INFO - Using cached data for Price
2025-04-21 19:06:47,583 - INFO - Using cached data for Price
2025-04-21 19:06:47,585 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:47,585 - INFO - Using cached data for Price
2025-04-21 19:06:47,585 - INFO - Using cached data for Price
2025-04-21 19:06:47,586 - INFO - Using cached data for CrossStuffing
2025-04-21 19:06:47,587 - INFO - Using cached data for Price
2025-04-21 19:06:47,587 - INFO - Using cached data for Price
2025-04-21 19:06:47,588 - INFO - Using cached data for CCCSContainerStuffing
2025-04-21 19:06:47,590 - INFO - Using cached data for Price
2025-04-21 19:06:47,590 - INFO - Using cached data for Price
2025-04-21 19:06:47,591 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:47,592 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:47,592 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:06:47,593 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:06:47,593 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:06:47,593 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:47,594 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:06:47,594 - INFO - Using cached data for Price
2025-04-21 19:06:47,594 - INFO - Using cached data for Price
2025-04-21 19:06:47,595 - INFO - Using cached data for UnloadingSummary
2025-04-21 19:06:47,595 - INFO - Using cached data for RawData
2025-04-21 19:06:47,595 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:47,596 - INFO - Using cached data for Price
2025-04-21 19:06:47,596 - INFO - Using cached data for Price
2025-04-21 19:06:47,596 - INFO - Using cached data for containerOperations
2025-04-21 19:06:47,598 - INFO - Using cached data for Price
2025-04-21 19:06:47,598 - INFO - Using cached data for Price
2025-04-21 19:06:47,602 - INFO - Using cached data for UnloadingSummary
2025-04-21 19:06:47,602 - INFO - Using cached data for containerOperations
2025-04-21 19:06:47,603 - INFO - Using cached data for Price
2025-04-21 19:06:47,603 - INFO - Using cached data for Price
2025-04-21 19:06:47,606 - INFO - Using cached data for Price
2025-04-21 19:06:47,606 - INFO - Using cached data for Price
2025-04-21 19:06:47,607 - INFO - Using cached data for UnloadingSummary
2025-04-21 19:06:47,607 - INFO - Using cached data for RawData
2025-04-21 19:06:47,607 - INFO - Using cached data for CCCSReport
2025-04-21 19:06:47,608 - INFO - Using cached data for Price
2025-04-21 19:06:47,608 - INFO - Using cached data for Price
2025-04-21 19:06:47,608 - INFO - Using cached data for containerOperations
2025-04-21 19:06:47,610 - INFO - Using cached data for Price
2025-04-21 19:06:47,610 - INFO - Using cached data for Price
2025-04-21 19:06:47,613 - INFO - Using cached data for Price
2025-04-21 19:06:47,613 - INFO - Using cached data for Price
2025-04-21 19:06:47,614 - INFO - Using cached data for RawData
2025-04-21 19:06:47,614 - INFO - Using cached data for WelltoWell
2025-04-21 19:06:47,614 - INFO - Using cached data for Price
2025-04-21 19:06:47,614 - INFO - Using cached data for Price
2025-04-21 19:06:47,614 - INFO - Using cached data for SaltOperation
2025-04-21 19:06:47,614 - INFO - Using cached data for Price
2025-04-21 19:06:47,614 - INFO - Using cached data for Price
2025-04-21 19:06:47,615 - INFO - Using cached data for Client
2025-04-21 19:06:47,616 - INFO - Using cached data for SaltOperation
2025-04-21 19:06:47,616 - INFO - Using cached data for Price
2025-04-21 19:06:47,616 - INFO - Using cached data for Price
2025-04-21 19:06:47,616 - INFO - Using cached data for Client
2025-04-21 19:06:47,620 - INFO - Using cached data for BinTipping
2025-04-21 19:06:47,620 - INFO - Using cached data for Price
2025-04-21 19:06:47,620 - INFO - Using cached data for Price
2025-04-21 19:06:47,620 - INFO - Using cached data for LinerPallet
2025-04-21 19:06:47,622 - INFO - Using cached data for Price
2025-04-21 19:06:47,622 - INFO - Using cached data for Price
2025-04-21 19:06:47,624 - INFO - Using cached data for containerOperations
2025-04-21 19:06:47,627 - INFO - Using cached data for Price
2025-04-21 19:06:47,627 - INFO - Using cached data for Price
2025-04-21 19:06:47,629 - INFO - Using cached data for ShoreCrane
2025-04-21 19:06:47,629 - INFO - Using cached data for Transfer
2025-04-21 19:06:47,629 - INFO - Using cached data for Price
2025-04-21 19:06:47,629 - INFO - Using cached data for Price
2025-04-21 19:06:47,632 - INFO - Using cached data for ScowTransfer
2025-04-21 19:06:47,632 - INFO - Using cached data for ForkliftRecord
2025-04-21 19:06:47,633 - INFO - Processing dataframe category: netlist
2025-04-21 19:06:47,633 - INFO - Processing dataframes: ['net_list', 'iot_container_stuffing', 'oss_stuffing']
2025-04-21 19:06:47,633 - INFO - Processing dataframe net_list of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 19:06:47,633 - INFO - Collecting LazyFrame for net_list
2025-04-21 19:06:47,634 - ERROR - Error processing dataframe net_list: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-21 19:06:47,634 - INFO - Processing dataframe iot_container_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 19:06:47,634 - INFO - Collecting LazyFrame for iot_container_stuffing
2025-04-21 19:06:47,634 - ERROR - Error processing dataframe iot_container_stuffing: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), String(Stuffing).alias("Service")] 
  FILTER col("container_number").is_in([Series]) FROM
     SELECT [col("Date").alias("date"), col("Vessel").str.uppercase().alias("vessel"), col("startTime").alias("start_time"), col("Container (Destination)").alias("container_number"), col("overtime"), col("Storage").alias("storage"), col("endTime").alias("end_time"), col("Total Tonnage").alias("total_tonnage")] FROM
      DF ["Date", "Vessel", "startTime", "Container (Destination)", ...]; PROJECT */25 COLUMNS
2025-04-21 19:06:47,634 - INFO - Processing dataframe oss_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 19:06:47,634 - INFO - Collecting LazyFrame for oss_stuffing
2025-04-21 19:06:47,635 - ERROR - Error processing dataframe oss_stuffing: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-21 19:06:47,635 - ERROR - Error saving net_list: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-21 19:06:47,635 - ERROR - Error saving iot_container_stuffing: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), String(Stuffing).alias("Service")] 
  FILTER col("container_number").is_in([Series]) FROM
     SELECT [col("Date").alias("date"), col("Vessel").str.uppercase().alias("vessel"), col("startTime").alias("start_time"), col("Container (Destination)").alias("container_number"), col("overtime"), col("Storage").alias("storage"), col("endTime").alias("end_time"), col("Total Tonnage").alias("total_tonnage")] FROM
      DF ["Date", "Vessel", "startTime", "Container (Destination)", ...]; PROJECT */25 COLUMNS
2025-04-21 19:06:47,635 - ERROR - Error saving oss_stuffing: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-21 19:06:47,635 - INFO - Save completed
2025-04-21 19:06:47,635 - INFO - Successfully saved: 
2025-04-21 19:06:47,635 - ERROR - Failed to save: net_list: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS, iot_container_stuffing: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), String(Stuffing).alias("Service")] 
  FILTER col("container_number").is_in([Series]) FROM
     SELECT [col("Date").alias("date"), col("Vessel").str.uppercase().alias("vessel"), col("startTime").alias("start_time"), col("Container (Destination)").alias("container_number"), col("overtime"), col("Storage").alias("storage"), col("endTime").alias("end_time"), col("Total Tonnage").alias("total_tonnage")] FROM
      DF ["Date", "Vessel", "startTime", "Container (Destination)", ...]; PROJECT */25 COLUMNS, oss_stuffing: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-21 19:15:18,424 - INFO - Starting application
2025-04-21 19:15:18,425 - INFO - Clearing screen
2025-04-21 19:15:21,778 - INFO - Selected: Save files
2025-04-21 19:15:21,778 - INFO - Clearing screen
2025-04-21 19:15:30,808 - INFO - Initiating save operation for netlist
2025-04-21 19:15:30,809 - INFO - Using cached data for Price
2025-04-21 19:15:30,809 - INFO - Using cached data for Price
2025-04-21 19:15:30,817 - INFO - Using cached data for ContainerShifting
2025-04-21 19:15:30,820 - INFO - Using cached data for ContainerCleaning
2025-04-21 19:15:30,822 - INFO - Using cached data for Price
2025-04-21 19:15:30,822 - INFO - Using cached data for Price
2025-04-21 19:15:30,824 - INFO - Using cached data for PTI
2025-04-21 19:15:30,824 - INFO - Using cached data for Price
2025-04-21 19:15:30,824 - INFO - Using cached data for Price
2025-04-21 19:15:30,827 - INFO - Using cached data for PTI
2025-04-21 19:15:30,827 - INFO - Using cached data for Price
2025-04-21 19:15:30,827 - INFO - Using cached data for Price
2025-04-21 19:15:30,829 - INFO - Using cached data for Price
2025-04-21 19:15:30,830 - INFO - Using cached data for Price
2025-04-21 19:15:30,833 - INFO - Using cached data for ScowTransfer
2025-04-21 19:15:30,833 - INFO - Using cached data for CCCSReport
2025-04-21 19:15:30,833 - INFO - Using cached data for Price
2025-04-21 19:15:30,833 - INFO - Using cached data for Price
2025-04-21 19:15:30,834 - INFO - Using cached data for ScowTransfer
2025-04-21 19:15:30,834 - INFO - Using cached data for Price
2025-04-21 19:15:30,834 - INFO - Using cached data for Price
2025-04-21 19:15:30,835 - INFO - Using cached data for CCCSReport
2025-04-21 19:15:30,835 - INFO - Using cached data for Price
2025-04-21 19:15:30,835 - INFO - Using cached data for Price
2025-04-21 19:15:30,836 - INFO - Using cached data for CCCSReport
2025-04-21 19:15:30,836 - INFO - Using cached data for Price
2025-04-21 19:15:30,836 - INFO - Using cached data for Price
2025-04-21 19:15:30,837 - INFO - Using cached data for CCCSReport
2025-04-21 19:15:30,837 - INFO - Using cached data for Price
2025-04-21 19:15:30,837 - INFO - Using cached data for Price
2025-04-21 19:15:30,838 - INFO - Using cached data for CrossStuffing
2025-04-21 19:15:30,838 - INFO - Using cached data for Price
2025-04-21 19:15:30,838 - INFO - Using cached data for Price
2025-04-21 19:15:30,839 - INFO - Using cached data for CCCSContainerStuffing
2025-04-21 19:15:30,842 - INFO - Using cached data for Price
2025-04-21 19:15:30,842 - INFO - Using cached data for Price
2025-04-21 19:15:30,843 - INFO - Using cached data for CCCSReport
2025-04-21 19:15:30,843 - INFO - Using cached data for CCCSReport
2025-04-21 19:15:30,844 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:15:30,844 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:15:30,844 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:15:30,845 - INFO - Using cached data for CCCSReport
2025-04-21 19:15:30,845 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:15:30,845 - INFO - Using cached data for Price
2025-04-21 19:15:30,845 - INFO - Using cached data for Price
2025-04-21 19:15:30,846 - INFO - Using cached data for UnloadingSummary
2025-04-21 19:15:30,846 - INFO - Using cached data for RawData
2025-04-21 19:15:30,846 - INFO - Using cached data for CCCSReport
2025-04-21 19:15:30,847 - INFO - Using cached data for Price
2025-04-21 19:15:30,847 - INFO - Using cached data for Price
2025-04-21 19:15:30,847 - INFO - Using cached data for containerOperations
2025-04-21 19:15:30,849 - INFO - Using cached data for Price
2025-04-21 19:15:30,849 - INFO - Using cached data for Price
2025-04-21 19:15:30,852 - INFO - Using cached data for UnloadingSummary
2025-04-21 19:15:30,852 - INFO - Using cached data for containerOperations
2025-04-21 19:15:30,854 - INFO - Using cached data for Price
2025-04-21 19:15:30,854 - INFO - Using cached data for Price
2025-04-21 19:15:30,856 - INFO - Using cached data for Price
2025-04-21 19:15:30,857 - INFO - Using cached data for Price
2025-04-21 19:15:30,857 - INFO - Using cached data for UnloadingSummary
2025-04-21 19:15:30,857 - INFO - Using cached data for RawData
2025-04-21 19:15:30,857 - INFO - Using cached data for CCCSReport
2025-04-21 19:15:30,858 - INFO - Using cached data for Price
2025-04-21 19:15:30,858 - INFO - Using cached data for Price
2025-04-21 19:15:30,859 - INFO - Using cached data for containerOperations
2025-04-21 19:15:30,861 - INFO - Using cached data for Price
2025-04-21 19:15:30,861 - INFO - Using cached data for Price
2025-04-21 19:15:30,864 - INFO - Using cached data for Price
2025-04-21 19:15:30,864 - INFO - Using cached data for Price
2025-04-21 19:15:30,865 - INFO - Using cached data for RawData
2025-04-21 19:15:30,865 - INFO - Using cached data for WelltoWell
2025-04-21 19:15:30,865 - INFO - Using cached data for Price
2025-04-21 19:15:30,865 - INFO - Using cached data for Price
2025-04-21 19:15:30,866 - INFO - Using cached data for SaltOperation
2025-04-21 19:15:30,866 - INFO - Using cached data for Price
2025-04-21 19:15:30,866 - INFO - Using cached data for Price
2025-04-21 19:15:30,866 - INFO - Using cached data for Client
2025-04-21 19:15:30,867 - INFO - Using cached data for SaltOperation
2025-04-21 19:15:30,867 - INFO - Using cached data for Price
2025-04-21 19:15:30,867 - INFO - Using cached data for Price
2025-04-21 19:15:30,868 - INFO - Using cached data for Client
2025-04-21 19:15:30,871 - INFO - Using cached data for BinTipping
2025-04-21 19:15:30,871 - INFO - Using cached data for Price
2025-04-21 19:15:30,871 - INFO - Using cached data for Price
2025-04-21 19:15:30,872 - INFO - Using cached data for LinerPallet
2025-04-21 19:15:30,874 - INFO - Using cached data for Price
2025-04-21 19:15:30,874 - INFO - Using cached data for Price
2025-04-21 19:15:30,877 - INFO - Using cached data for containerOperations
2025-04-21 19:15:30,879 - INFO - Using cached data for Price
2025-04-21 19:15:30,879 - INFO - Using cached data for Price
2025-04-21 19:15:30,881 - INFO - Using cached data for ShoreCrane
2025-04-21 19:15:30,881 - INFO - Using cached data for Transfer
2025-04-21 19:15:30,881 - INFO - Using cached data for Price
2025-04-21 19:15:30,881 - INFO - Using cached data for Price
2025-04-21 19:15:30,884 - INFO - Using cached data for ScowTransfer
2025-04-21 19:15:30,884 - INFO - Using cached data for ForkliftRecord
2025-04-21 19:15:30,885 - INFO - Processing dataframe category: netlist
2025-04-21 19:15:30,885 - INFO - Processing dataframes: ['net_list', 'iot_container_stuffing', 'oss_stuffing']
2025-04-21 19:15:30,885 - INFO - Processing dataframe net_list of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 19:15:30,885 - INFO - Collecting LazyFrame for net_list
2025-04-21 19:15:30,885 - ERROR - Error processing dataframe net_list: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-21 19:15:30,886 - INFO - Processing dataframe iot_container_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 19:15:30,886 - INFO - Collecting LazyFrame for iot_container_stuffing
2025-04-21 19:15:30,886 - ERROR - Error processing dataframe iot_container_stuffing: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), String(Stuffing).alias("Service")] 
  FILTER col("container_number").is_in([Series]) FROM
     SELECT [col("Date").alias("date"), col("Vessel").str.uppercase().alias("vessel"), col("startTime").alias("start_time"), col("Container (Destination)").alias("container_number"), col("overtime"), col("Storage").alias("storage"), col("endTime").alias("end_time"), col("Total Tonnage").alias("total_tonnage")] FROM
      DF ["Date", "Vessel", "startTime", "Container (Destination)", ...]; PROJECT */25 COLUMNS
2025-04-21 19:15:30,886 - INFO - Processing dataframe oss_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 19:15:30,886 - INFO - Collecting LazyFrame for oss_stuffing
2025-04-21 19:15:30,886 - ERROR - Error processing dataframe oss_stuffing: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-21 19:15:30,887 - ERROR - Error saving net_list: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-21 19:15:30,887 - ERROR - Error saving iot_container_stuffing: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), String(Stuffing).alias("Service")] 
  FILTER col("container_number").is_in([Series]) FROM
     SELECT [col("Date").alias("date"), col("Vessel").str.uppercase().alias("vessel"), col("startTime").alias("start_time"), col("Container (Destination)").alias("container_number"), col("overtime"), col("Storage").alias("storage"), col("endTime").alias("end_time"), col("Total Tonnage").alias("total_tonnage")] FROM
      DF ["Date", "Vessel", "startTime", "Container (Destination)", ...]; PROJECT */25 COLUMNS
2025-04-21 19:15:30,887 - ERROR - Error saving oss_stuffing: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-21 19:15:30,887 - INFO - Save completed
2025-04-21 19:15:30,887 - INFO - Successfully saved: 
2025-04-21 19:15:30,887 - ERROR - Failed to save: net_list: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS, iot_container_stuffing: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), String(Stuffing).alias("Service")] 
  FILTER col("container_number").is_in([Series]) FROM
     SELECT [col("Date").alias("date"), col("Vessel").str.uppercase().alias("vessel"), col("startTime").alias("start_time"), col("Container (Destination)").alias("container_number"), col("overtime"), col("Storage").alias("storage"), col("endTime").alias("end_time"), col("Total Tonnage").alias("total_tonnage")] FROM
      DF ["Date", "Vessel", "startTime", "Container (Destination)", ...]; PROJECT */25 COLUMNS, oss_stuffing: datatypes of join keys don't match - `date`: str on left does not match `date_plugged`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("stuffing")] FROM
   WITH_COLUMNS:
   [when(col("operation_type").str.contains([String(Full)])).then(String(Full OSS)).otherwise(when(col("operation_type").str.contains([String(Basic)])).then(String(Basic OSS)).otherwise(String(Container Stuffing))).alias("stuffing")] 
    FILTER [(col("operation_type").str.contains([String(CCCS)]).not()) & (col("operation_type").str.contains_any([Series]))] FROM
       WITH_COLUMNS:
       [col("container_number").strict_cast(String), col("vessel_client").strict_cast(String)] 
         SELECT [col("vessel_client"), col("customer"), col("date_plugged"), col("container_number"), col("operation_type")] FROM
           WITH_COLUMNS:
           [[([(col("plugin_price")) + (col("monitoring_price"))]) + (col("total_electricity"))].alias("total")] 
             WITH_COLUMNS:
             [[(col("electricity_unit_price")) * (col("days_on_plug").cast(Float64))].alias("total_electricity")] 
               WITH_COLUMNS:
               [when([(col("location")) == (String(Plugin Only))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(when([(col("set_point")) == (-60)]).then(dyn float: 110.0).otherwise(when([(col("set_point")) == (-35)]).then(dyn float: 100.0).otherwise(dyn float: 70.0))).alias("electricity_unit_price")] 
                 WITH_COLUMNS:
                 [when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(0µs.strict_cast(Int64)).otherwise(when(col("location").is_in([Series])).then([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)).otherwise([([([(col("date_out")) - (col("date_plugged"))].dt.total_hours()) / (24)].strict_cast(Int64)) + (1)])).alias("days_on_plug"), when([(col("operation_type").str.contains([String(Direct)])) | (col("operation_type").str.contains([String(Exchange)]))]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 25.0).alias("plugin_price"), when([([(col("operation_type").str.contains([String(Direct)])) | (col("location").is_in([Series]))]) | ([(col("location")) == (String(Plugin Only))])]).then(dyn int: 0.strict_cast(Unknown(Float))).otherwise(dyn float: 30.0).alias("monitoring_price")] 
                   SELECT [col("vessel_client").str.uppercase().strict_cast(String), col("customer").strict_cast(Enum(Some(local), Physical)), col("date_plugged").str.strptime([String(raise)]), col("time_plugged").str.strptime([String(raise)]), col("container_number").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("shipping_line").strict_cast(Enum(Some(local), Physical)), col("plugged_status").strict_cast(Enum(Some(local), Physical)), col("tonnage"), col("set_point"), col("date_out").str.strptime([String(raise)]), col("location")] FROM
                    DF ["vessel_client", "customer", "date_plugged", "time_plugged", ...]; PROJECT */12 COLUMNS
2025-04-21 19:15:39,057 - INFO - Starting application
2025-04-21 19:15:39,057 - INFO - Clearing screen
2025-04-21 19:15:40,929 - INFO - Exiting application
2025-04-21 19:15:45,738 - DEBUG - Using selector: EpollSelector
2025-04-21 19:15:45,738 - INFO - Starting application
2025-04-21 19:15:45,738 - INFO - Clearing screen
2025-04-21 19:15:47,680 - INFO - Selected: Save files
2025-04-21 19:15:47,680 - INFO - Clearing screen
2025-04-21 19:15:56,312 - INFO - Initiating save operation for netlist
2025-04-21 19:15:57,505 - INFO - Using cached data for Price
2025-04-21 19:15:59,058 - INFO - Loading container data from sheet
2025-04-21 19:16:04,326 - INFO - Using cached data for Price
2025-04-21 19:16:04,326 - INFO - Using cached data for Price
2025-04-21 19:16:06,024 - INFO - Using cached data for Price
2025-04-21 19:16:06,024 - INFO - Using cached data for Price
2025-04-21 19:16:06,028 - INFO - Using cached data for PTI
2025-04-21 19:16:06,028 - INFO - Using cached data for Price
2025-04-21 19:16:06,028 - INFO - Using cached data for Price
2025-04-21 19:16:06,030 - INFO - Using cached data for Price
2025-04-21 19:16:06,030 - INFO - Using cached data for Price
2025-04-21 19:16:09,639 - INFO - Using cached data for Price
2025-04-21 19:16:09,640 - INFO - Using cached data for Price
2025-04-21 19:16:09,645 - INFO - Using cached data for ScowTransfer
2025-04-21 19:16:09,646 - INFO - Using cached data for Price
2025-04-21 19:16:09,647 - INFO - Using cached data for Price
2025-04-21 19:16:09,650 - INFO - Using cached data for CCCSReport
2025-04-21 19:16:09,651 - INFO - Using cached data for Price
2025-04-21 19:16:09,652 - INFO - Using cached data for Price
2025-04-21 19:16:09,656 - INFO - Using cached data for CCCSReport
2025-04-21 19:16:09,657 - INFO - Using cached data for Price
2025-04-21 19:16:09,658 - INFO - Using cached data for Price
2025-04-21 19:16:09,662 - INFO - Using cached data for CCCSReport
2025-04-21 19:16:09,663 - INFO - Using cached data for Price
2025-04-21 19:16:09,663 - INFO - Using cached data for Price
2025-04-21 19:16:10,933 - INFO - Using cached data for Price
2025-04-21 19:16:10,933 - INFO - Using cached data for Price
2025-04-21 19:16:11,922 - INFO - Using cached data for Price
2025-04-21 19:16:11,922 - INFO - Using cached data for Price
2025-04-21 19:16:11,923 - INFO - Using cached data for CCCSReport
2025-04-21 19:16:12,975 - INFO - Using cached data for Client
2025-04-21 19:16:12,977 - INFO - Using cached data for Client
2025-04-21 19:16:12,979 - INFO - Using cached data for Client
2025-04-21 19:16:12,980 - INFO - Using cached data for Client
2025-04-21 19:16:12,981 - INFO - Using cached data for Client
2025-04-21 19:16:12,983 - INFO - Using cached data for Client
2025-04-21 19:16:12,984 - INFO - Using cached data for Client
2025-04-21 19:16:12,986 - INFO - Using cached data for Client
2025-04-21 19:16:12,987 - INFO - Using cached data for Client
2025-04-21 19:16:12,988 - INFO - Using cached data for Client
2025-04-21 19:16:12,990 - INFO - Using cached data for Client
2025-04-21 19:16:12,991 - INFO - Using cached data for Client
2025-04-21 19:16:12,993 - INFO - Using cached data for CCCSReport
2025-04-21 19:16:13,883 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:16:13,886 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:16:13,888 - INFO - Using cached data for CCCSReport
2025-04-21 19:16:13,890 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-21 19:16:13,891 - INFO - Using cached data for Price
2025-04-21 19:16:13,892 - INFO - Using cached data for Price
2025-04-21 19:16:19,250 - INFO - Using cached data for CCCSReport
2025-04-21 19:16:19,251 - INFO - Using cached data for Price
2025-04-21 19:16:19,251 - INFO - Using cached data for Price
2025-04-21 19:16:20,855 - INFO - Using cached data for Price
2025-04-21 19:16:20,855 - INFO - Using cached data for Price
2025-04-21 19:16:20,860 - INFO - Using cached data for UnloadingSummary
2025-04-21 19:16:20,861 - INFO - Using cached data for containerOperations
2025-04-21 19:16:20,863 - INFO - Using cached data for Price
2025-04-21 19:16:20,864 - INFO - Using cached data for Price
2025-04-21 19:16:20,868 - INFO - Using cached data for Price
2025-04-21 19:16:20,868 - INFO - Using cached data for Price
2025-04-21 19:16:20,869 - INFO - Using cached data for UnloadingSummary
2025-04-21 19:16:20,869 - INFO - Using cached data for RawData
2025-04-21 19:16:20,869 - INFO - Using cached data for CCCSReport
2025-04-21 19:16:20,870 - INFO - Using cached data for Price
2025-04-21 19:16:20,870 - INFO - Using cached data for Price
2025-04-21 19:16:20,871 - INFO - Using cached data for containerOperations
2025-04-21 19:16:20,873 - INFO - Using cached data for Price
2025-04-21 19:16:20,873 - INFO - Using cached data for Price
2025-04-21 19:16:20,877 - INFO - Using cached data for Price
2025-04-21 19:16:20,877 - INFO - Using cached data for Price
2025-04-21 19:16:20,878 - INFO - Using cached data for RawData
2025-04-21 19:16:21,763 - INFO - Using cached data for Price
2025-04-21 19:16:21,764 - INFO - Using cached data for Price
2025-04-21 19:16:23,204 - INFO - Using cached data for Price
2025-04-21 19:16:23,204 - INFO - Using cached data for Price
2025-04-21 19:16:23,208 - INFO - Using cached data for Client
2025-04-21 19:16:23,212 - INFO - Using cached data for SaltOperation
2025-04-21 19:16:23,213 - INFO - Using cached data for Price
2025-04-21 19:16:23,213 - INFO - Using cached data for Price
2025-04-21 19:16:23,217 - INFO - Using cached data for Client
2025-04-21 19:16:24,476 - INFO - Using cached data for Price
2025-04-21 19:16:24,476 - INFO - Using cached data for Price
2025-04-21 19:16:25,547 - INFO - Using cached data for Price
2025-04-21 19:16:25,547 - INFO - Using cached data for Price
2025-04-21 19:16:25,559 - INFO - Using cached data for containerOperations
2025-04-21 19:16:25,567 - INFO - Using cached data for Price
2025-04-21 19:16:25,568 - INFO - Using cached data for Price
2025-04-21 19:16:26,662 - INFO - Using cached data for Transfer
2025-04-21 19:16:26,662 - INFO - Using cached data for Price
2025-04-21 19:16:26,663 - INFO - Using cached data for Price
2025-04-21 19:16:26,669 - INFO - Using cached data for ScowTransfer
2025-04-21 19:16:28,062 - INFO - Processing dataframe category: netlist
2025-04-21 19:16:28,062 - INFO - Processing dataframes: ['net_list', 'iot_container_stuffing', 'oss_stuffing']
2025-04-21 19:16:28,063 - INFO - Processing dataframe net_list of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 19:16:28,063 - INFO - Collecting LazyFrame for net_list
2025-04-21 19:16:28,065 - ERROR - Error processing dataframe net_list: datatypes of join keys don't match - `date`: str on left does not match `date`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
SORT BY [col("date")]
  AGGREGATE
  	[col("total_tonnage").sum(), col("overtime_tonnage").sum()] BY [col("date"), col("destination"), col("vessel"), col("storage_type")] FROM
     SELECT [col("day"), col("date").str.strptime([String(raise)]), col("movement_type"), col("destination"), col("vessel"), col("operation_type"), col("total_tonnage"), col("overtime_tonnage"), col("storage_type")] FROM
       WITH_COLUMNS:
       [String(CCCS ().str.concat_horizontal([col("customer").strict_cast(String), String())]).alias("destination")] 
        FILTER col("operation_type").is_in([Series]) FROM
          FILTER col("customer").is_in([Series]).not() FROM
             SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date").str.strptime([String(raise)]), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in"), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
              DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-21 19:16:28,066 - INFO - Processing dataframe iot_container_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 19:16:28,066 - INFO - Collecting LazyFrame for iot_container_stuffing
2025-04-21 19:16:28,066 - ERROR - Error processing dataframe iot_container_stuffing: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), String(Stuffing).alias("Service")] 
  FILTER col("container_number").is_in([Series]) FROM
     SELECT [col("Date").alias("date"), col("Vessel").str.uppercase().alias("vessel"), col("startTime").alias("start_time"), col("Container (Destination)").alias("container_number"), col("overtime"), col("Storage").alias("storage"), col("endTime").alias("end_time"), col("Total Tonnage").alias("total_tonnage")] FROM
      DF ["Date", "Vessel", "startTime", "Container (Destination)", ...]; PROJECT */25 COLUMNS
2025-04-21 19:16:28,067 - INFO - Processing dataframe oss_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-21 19:16:28,067 - INFO - Collecting LazyFrame for oss_stuffing
2025-04-21 19:16:28,068 - ERROR - Error processing dataframe oss_stuffing: datatypes of join keys don't match - `date`: str on left does not match `date`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
SORT BY [col("date")]
  AGGREGATE
  	[col("total_tonnage").sum(), col("overtime_tonnage").sum()] BY [col("date"), col("destination"), col("vessel"), col("storage_type")] FROM
     SELECT [col("day"), col("date").str.strptime([String(raise)]), col("movement_type"), col("destination"), col("vessel"), col("operation_type"), col("total_tonnage"), col("overtime_tonnage"), col("storage_type")] FROM
       WITH_COLUMNS:
       [String(CCCS ().str.concat_horizontal([col("customer").strict_cast(String), String())]).alias("destination")] 
        FILTER col("operation_type").is_in([Series]) FROM
          FILTER col("customer").is_in([Series]).not() FROM
             SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date").str.strptime([String(raise)]), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in"), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
              DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-21 19:16:28,069 - ERROR - Error saving net_list: datatypes of join keys don't match - `date`: str on left does not match `date`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
SORT BY [col("date")]
  AGGREGATE
  	[col("total_tonnage").sum(), col("overtime_tonnage").sum()] BY [col("date"), col("destination"), col("vessel"), col("storage_type")] FROM
     SELECT [col("day"), col("date").str.strptime([String(raise)]), col("movement_type"), col("destination"), col("vessel"), col("operation_type"), col("total_tonnage"), col("overtime_tonnage"), col("storage_type")] FROM
       WITH_COLUMNS:
       [String(CCCS ().str.concat_horizontal([col("customer").strict_cast(String), String())]).alias("destination")] 
        FILTER col("operation_type").is_in([Series]) FROM
          FILTER col("customer").is_in([Series]).not() FROM
             SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date").str.strptime([String(raise)]), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in"), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
              DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-21 19:16:28,069 - ERROR - Error saving iot_container_stuffing: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), String(Stuffing).alias("Service")] 
  FILTER col("container_number").is_in([Series]) FROM
     SELECT [col("Date").alias("date"), col("Vessel").str.uppercase().alias("vessel"), col("startTime").alias("start_time"), col("Container (Destination)").alias("container_number"), col("overtime"), col("Storage").alias("storage"), col("endTime").alias("end_time"), col("Total Tonnage").alias("total_tonnage")] FROM
      DF ["Date", "Vessel", "startTime", "Container (Destination)", ...]; PROJECT */25 COLUMNS
2025-04-21 19:16:28,069 - ERROR - Error saving oss_stuffing: datatypes of join keys don't match - `date`: str on left does not match `date`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
SORT BY [col("date")]
  AGGREGATE
  	[col("total_tonnage").sum(), col("overtime_tonnage").sum()] BY [col("date"), col("destination"), col("vessel"), col("storage_type")] FROM
     SELECT [col("day"), col("date").str.strptime([String(raise)]), col("movement_type"), col("destination"), col("vessel"), col("operation_type"), col("total_tonnage"), col("overtime_tonnage"), col("storage_type")] FROM
       WITH_COLUMNS:
       [String(CCCS ().str.concat_horizontal([col("customer").strict_cast(String), String())]).alias("destination")] 
        FILTER col("operation_type").is_in([Series]) FROM
          FILTER col("customer").is_in([Series]).not() FROM
             SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date").str.strptime([String(raise)]), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in"), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
              DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-21 19:16:28,069 - INFO - Save completed
2025-04-21 19:16:28,070 - INFO - Successfully saved: 
2025-04-21 19:16:28,070 - ERROR - Failed to save: net_list: datatypes of join keys don't match - `date`: str on left does not match `date`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
SORT BY [col("date")]
  AGGREGATE
  	[col("total_tonnage").sum(), col("overtime_tonnage").sum()] BY [col("date"), col("destination"), col("vessel"), col("storage_type")] FROM
     SELECT [col("day"), col("date").str.strptime([String(raise)]), col("movement_type"), col("destination"), col("vessel"), col("operation_type"), col("total_tonnage"), col("overtime_tonnage"), col("storage_type")] FROM
       WITH_COLUMNS:
       [String(CCCS ().str.concat_horizontal([col("customer").strict_cast(String), String())]).alias("destination")] 
        FILTER col("operation_type").is_in([Series]) FROM
          FILTER col("customer").is_in([Series]).not() FROM
             SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date").str.strptime([String(raise)]), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in"), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
              DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS, iot_container_stuffing: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name"), String(Stuffing).alias("Service")] 
  FILTER col("container_number").is_in([Series]) FROM
     SELECT [col("Date").alias("date"), col("Vessel").str.uppercase().alias("vessel"), col("startTime").alias("start_time"), col("Container (Destination)").alias("container_number"), col("overtime"), col("Storage").alias("storage"), col("endTime").alias("end_time"), col("Total Tonnage").alias("total_tonnage")] FROM
      DF ["Date", "Vessel", "startTime", "Container (Destination)", ...]; PROJECT */25 COLUMNS, oss_stuffing: datatypes of join keys don't match - `date`: str on left does not match `date`: date on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
SORT BY [col("date")]
  AGGREGATE
  	[col("total_tonnage").sum(), col("overtime_tonnage").sum()] BY [col("date"), col("destination"), col("vessel"), col("storage_type")] FROM
     SELECT [col("day"), col("date").str.strptime([String(raise)]), col("movement_type"), col("destination"), col("vessel"), col("operation_type"), col("total_tonnage"), col("overtime_tonnage"), col("storage_type")] FROM
       WITH_COLUMNS:
       [String(CCCS ().str.concat_horizontal([col("customer").strict_cast(String), String())]).alias("destination")] 
        FILTER col("operation_type").is_in([Series]) FROM
          FILTER col("customer").is_in([Series]).not() FROM
             SELECT [col("day").strict_cast(Enum(Some(local), Physical)), col("date").str.strptime([String(raise)]), col("movement_type"), col("customer"), col("origin"), col("vessel"), col("storage_type").strict_cast(Enum(Some(local), Physical)), col("operation_type"), col("total_tonnage"), col("bins_in"), [(col("bins_out").str.strip_chars([String(-)]).replace([String(), String(0)]).strict_cast(Int64)) * (-1)], col("static_loader").str.replace([String(), String(0)]).strict_cast(Float64), col("overtime_tonnage").str.replace([String(), String(0)]).strict_cast(Float64)] FROM
              DF ["date", "SUN/PH", "movement_type", "customer", ...]; PROJECT */16 COLUMNS
2025-04-25 14:53:43,875 - DEBUG - Using selector: EpollSelector
2025-04-25 14:53:43,916 - INFO - Starting application
2025-04-25 14:53:43,916 - INFO - Clearing screen
2025-04-25 14:53:46,545 - INFO - Selected: Save files
2025-04-25 14:53:46,545 - INFO - Clearing screen
2025-04-25 14:53:52,257 - INFO - Initiating save operation for netlist
2025-04-25 14:53:53,384 - INFO - Using cached data for Price
2025-04-25 14:53:54,623 - INFO - Loading container data from sheet
2025-04-25 14:53:58,022 - INFO - Using cached data for Price
2025-04-25 14:53:58,022 - INFO - Using cached data for Price
2025-04-25 14:53:59,614 - INFO - Using cached data for Price
2025-04-25 14:53:59,614 - INFO - Using cached data for Price
2025-04-25 14:53:59,616 - INFO - Using cached data for PTI
2025-04-25 14:53:59,616 - INFO - Using cached data for Price
2025-04-25 14:53:59,616 - INFO - Using cached data for Price
2025-04-25 14:53:59,618 - INFO - Using cached data for Price
2025-04-25 14:53:59,618 - INFO - Using cached data for Price
2025-04-25 14:54:06,674 - INFO - Using cached data for Price
2025-04-25 14:54:06,674 - INFO - Using cached data for Price
2025-04-25 14:54:06,675 - INFO - Using cached data for ScowTransfer
2025-04-25 14:54:06,675 - INFO - Using cached data for Price
2025-04-25 14:54:06,675 - INFO - Using cached data for Price
2025-04-25 14:54:06,676 - INFO - Using cached data for CCCSReport
2025-04-25 14:54:06,677 - INFO - Using cached data for Price
2025-04-25 14:54:06,677 - INFO - Using cached data for Price
2025-04-25 14:54:06,678 - INFO - Using cached data for CCCSReport
2025-04-25 14:54:06,678 - INFO - Using cached data for Price
2025-04-25 14:54:06,678 - INFO - Using cached data for Price
2025-04-25 14:54:06,680 - INFO - Using cached data for CCCSReport
2025-04-25 14:54:06,680 - INFO - Using cached data for Price
2025-04-25 14:54:06,680 - INFO - Using cached data for Price
2025-04-25 14:54:08,854 - INFO - Using cached data for Price
2025-04-25 14:54:08,855 - INFO - Using cached data for Price
2025-04-25 14:54:10,398 - INFO - Using cached data for Price
2025-04-25 14:54:10,398 - INFO - Using cached data for Price
2025-04-25 14:54:10,399 - INFO - Using cached data for CCCSReport
2025-04-25 14:54:11,397 - INFO - Using cached data for Client
2025-04-25 14:54:11,397 - INFO - Using cached data for Client
2025-04-25 14:54:11,398 - INFO - Using cached data for Client
2025-04-25 14:54:11,398 - INFO - Using cached data for Client
2025-04-25 14:54:11,398 - INFO - Using cached data for Client
2025-04-25 14:54:11,398 - INFO - Using cached data for Client
2025-04-25 14:54:11,399 - INFO - Using cached data for Client
2025-04-25 14:54:11,399 - INFO - Using cached data for Client
2025-04-25 14:54:11,399 - INFO - Using cached data for Client
2025-04-25 14:54:11,400 - INFO - Using cached data for Client
2025-04-25 14:54:11,400 - INFO - Using cached data for Client
2025-04-25 14:54:11,400 - INFO - Using cached data for Client
2025-04-25 14:54:11,401 - INFO - Using cached data for CCCSReport
2025-04-25 14:54:13,556 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-25 14:54:13,556 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-25 14:54:13,557 - INFO - Using cached data for CCCSReport
2025-04-25 14:54:13,557 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-25 14:54:13,558 - INFO - Using cached data for Price
2025-04-25 14:54:13,558 - INFO - Using cached data for Price
2025-04-25 14:54:17,850 - INFO - Using cached data for CCCSReport
2025-04-25 14:54:17,851 - INFO - Using cached data for Price
2025-04-25 14:54:17,851 - INFO - Using cached data for Price
2025-04-25 14:54:19,377 - INFO - Using cached data for Price
2025-04-25 14:54:19,377 - INFO - Using cached data for Price
2025-04-25 14:54:19,382 - INFO - Using cached data for UnloadingSummary
2025-04-25 14:54:19,382 - INFO - Using cached data for containerOperations
2025-04-25 14:54:19,385 - INFO - Using cached data for Price
2025-04-25 14:54:19,385 - INFO - Using cached data for Price
2025-04-25 14:54:19,391 - INFO - Using cached data for Price
2025-04-25 14:54:19,391 - INFO - Using cached data for Price
2025-04-25 14:54:19,392 - INFO - Using cached data for UnloadingSummary
2025-04-25 14:54:19,392 - INFO - Using cached data for RawData
2025-04-25 14:54:19,392 - INFO - Using cached data for CCCSReport
2025-04-25 14:54:19,393 - INFO - Using cached data for Price
2025-04-25 14:54:19,393 - INFO - Using cached data for Price
2025-04-25 14:54:19,393 - INFO - Using cached data for containerOperations
2025-04-25 14:54:19,396 - INFO - Using cached data for Price
2025-04-25 14:54:19,397 - INFO - Using cached data for Price
2025-04-25 14:54:19,401 - INFO - Using cached data for Price
2025-04-25 14:54:19,401 - INFO - Using cached data for Price
2025-04-25 14:54:19,402 - INFO - Using cached data for RawData
2025-04-25 14:54:20,210 - INFO - Using cached data for Price
2025-04-25 14:54:20,210 - INFO - Using cached data for Price
2025-04-25 14:54:21,878 - INFO - Using cached data for Price
2025-04-25 14:54:21,878 - INFO - Using cached data for Price
2025-04-25 14:54:21,879 - INFO - Using cached data for Client
2025-04-25 14:54:21,901 - INFO - Using cached data for SaltOperation
2025-04-25 14:54:21,901 - INFO - Using cached data for Price
2025-04-25 14:54:21,901 - INFO - Using cached data for Price
2025-04-25 14:54:21,902 - INFO - Using cached data for Client
2025-04-25 14:54:22,987 - INFO - Using cached data for Price
2025-04-25 14:54:22,987 - INFO - Using cached data for Price
2025-04-25 14:54:24,040 - INFO - Using cached data for Price
2025-04-25 14:54:24,040 - INFO - Using cached data for Price
2025-04-25 14:54:24,043 - INFO - Using cached data for containerOperations
2025-04-25 14:54:24,045 - INFO - Using cached data for Price
2025-04-25 14:54:24,045 - INFO - Using cached data for Price
2025-04-25 14:54:26,662 - INFO - Using cached data for Transfer
2025-04-25 14:54:26,662 - INFO - Using cached data for Price
2025-04-25 14:54:26,662 - INFO - Using cached data for Price
2025-04-25 14:54:26,681 - INFO - Using cached data for ScowTransfer
2025-04-25 14:54:28,629 - INFO - Processing dataframe category: netlist
2025-04-25 14:54:28,630 - INFO - Processing dataframes: ['net_list', 'iot_container_stuffing', 'oss_stuffing']
2025-04-25 14:54:28,630 - INFO - Processing dataframe net_list of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-25 14:54:28,630 - INFO - Collecting LazyFrame for net_list
2025-04-25 14:54:28,662 - INFO - Successfully processed dataframe net_list
2025-04-25 14:54:28,662 - INFO - Writing to output/csv/net_list.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-25 14:54:28,663 - INFO - Processing dataframe iot_container_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-25 14:54:28,663 - INFO - Collecting LazyFrame for iot_container_stuffing
2025-04-25 14:54:28,687 - INFO - Successfully processed dataframe iot_container_stuffing
2025-04-25 14:54:28,687 - INFO - Writing to output/csv/iot_container_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-25 14:54:28,687 - INFO - Processing dataframe oss_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-25 14:54:28,687 - INFO - Collecting LazyFrame for oss_stuffing
2025-04-25 14:54:28,724 - INFO - Successfully processed dataframe oss_stuffing
2025-04-25 14:54:28,724 - INFO - Writing to output/csv/oss_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-25 14:54:28,725 - INFO - Successfully wrote iot_container_stuffing to file
2025-04-25 14:54:28,725 - INFO - Successfully wrote net_list to file
2025-04-25 14:54:28,728 - INFO - Successfully wrote oss_stuffing to file
2025-04-25 14:54:28,728 - INFO - Successfully saved net_list
2025-04-25 14:54:28,728 - INFO - Successfully saved iot_container_stuffing
2025-04-25 14:54:28,728 - INFO - Successfully saved oss_stuffing
2025-04-25 14:54:28,728 - INFO - Save completed
2025-04-25 14:54:28,728 - INFO - Successfully saved: net_list, iot_container_stuffing, oss_stuffing
2025-04-28 16:04:17,221 - DEBUG - Using selector: EpollSelector
2025-04-28 16:04:17,278 - INFO - Starting application
2025-04-28 16:04:17,278 - INFO - Clearing screen
2025-04-28 16:04:21,347 - INFO - Selected: Save files
2025-04-28 16:04:21,347 - INFO - Clearing screen
2025-04-28 16:04:32,531 - INFO - Initiating save operation for all
2025-04-28 16:04:33,701 - INFO - Using cached data for Price
2025-04-28 16:04:34,928 - INFO - Loading container data from sheet
2025-04-28 16:04:38,585 - INFO - Using cached data for Price
2025-04-28 16:04:38,586 - INFO - Using cached data for Price
2025-04-28 16:04:40,005 - INFO - Using cached data for Price
2025-04-28 16:04:40,005 - INFO - Using cached data for Price
2025-04-28 16:04:40,008 - INFO - Using cached data for PTI
2025-04-28 16:04:40,008 - INFO - Using cached data for Price
2025-04-28 16:04:40,008 - INFO - Using cached data for Price
2025-04-28 16:04:40,010 - INFO - Using cached data for Price
2025-04-28 16:04:40,010 - INFO - Using cached data for Price
2025-04-28 16:04:42,521 - INFO - Using cached data for Price
2025-04-28 16:04:42,522 - INFO - Using cached data for Price
2025-04-28 16:04:42,526 - INFO - Using cached data for ScowTransfer
2025-04-28 16:04:42,527 - INFO - Using cached data for Price
2025-04-28 16:04:42,528 - INFO - Using cached data for Price
2025-04-28 16:04:42,532 - INFO - Using cached data for CCCSReport
2025-04-28 16:04:42,533 - INFO - Using cached data for Price
2025-04-28 16:04:42,534 - INFO - Using cached data for Price
2025-04-28 16:04:42,537 - INFO - Using cached data for CCCSReport
2025-04-28 16:04:42,537 - INFO - Using cached data for Price
2025-04-28 16:04:42,537 - INFO - Using cached data for Price
2025-04-28 16:04:42,540 - INFO - Using cached data for CCCSReport
2025-04-28 16:04:42,541 - INFO - Using cached data for Price
2025-04-28 16:04:42,541 - INFO - Using cached data for Price
2025-04-28 16:04:43,450 - INFO - Using cached data for Price
2025-04-28 16:04:43,450 - INFO - Using cached data for Price
2025-04-28 16:04:44,494 - INFO - Using cached data for Price
2025-04-28 16:04:44,494 - INFO - Using cached data for Price
2025-04-28 16:04:44,497 - INFO - Using cached data for CCCSReport
2025-04-28 16:04:45,498 - INFO - Using cached data for Client
2025-04-28 16:04:45,500 - INFO - Using cached data for Client
2025-04-28 16:04:45,501 - INFO - Using cached data for Client
2025-04-28 16:04:45,502 - INFO - Using cached data for Client
2025-04-28 16:04:45,504 - INFO - Using cached data for Client
2025-04-28 16:04:45,505 - INFO - Using cached data for Client
2025-04-28 16:04:45,507 - INFO - Using cached data for Client
2025-04-28 16:04:45,508 - INFO - Using cached data for Client
2025-04-28 16:04:45,509 - INFO - Using cached data for Client
2025-04-28 16:04:45,510 - INFO - Using cached data for Client
2025-04-28 16:04:45,511 - INFO - Using cached data for Client
2025-04-28 16:04:45,512 - INFO - Using cached data for Client
2025-04-28 16:04:45,514 - INFO - Using cached data for CCCSReport
2025-04-28 16:04:46,412 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-28 16:04:46,414 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-28 16:04:46,416 - INFO - Using cached data for CCCSReport
2025-04-28 16:04:46,417 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-28 16:04:46,420 - INFO - Using cached data for Price
2025-04-28 16:04:46,421 - INFO - Using cached data for Price
2025-04-28 16:04:50,615 - INFO - Using cached data for CCCSReport
2025-04-28 16:04:50,616 - INFO - Using cached data for Price
2025-04-28 16:04:50,616 - INFO - Using cached data for Price
2025-04-28 16:04:51,629 - INFO - Using cached data for Price
2025-04-28 16:04:51,629 - INFO - Using cached data for Price
2025-04-28 16:04:51,647 - INFO - Using cached data for UnloadingSummary
2025-04-28 16:04:51,648 - INFO - Using cached data for containerOperations
2025-04-28 16:04:51,657 - INFO - Using cached data for Price
2025-04-28 16:04:51,658 - INFO - Using cached data for Price
2025-04-28 16:04:51,671 - INFO - Using cached data for Price
2025-04-28 16:04:51,671 - INFO - Using cached data for Price
2025-04-28 16:04:51,673 - INFO - Using cached data for UnloadingSummary
2025-04-28 16:04:51,673 - INFO - Using cached data for RawData
2025-04-28 16:04:51,674 - INFO - Using cached data for CCCSReport
2025-04-28 16:04:51,676 - INFO - Using cached data for Price
2025-04-28 16:04:51,676 - INFO - Using cached data for Price
2025-04-28 16:04:51,676 - INFO - Using cached data for containerOperations
2025-04-28 16:04:51,680 - INFO - Using cached data for Price
2025-04-28 16:04:51,680 - INFO - Using cached data for Price
2025-04-28 16:04:51,686 - INFO - Using cached data for Price
2025-04-28 16:04:51,686 - INFO - Using cached data for Price
2025-04-28 16:04:51,686 - INFO - Using cached data for RawData
2025-04-28 16:04:52,550 - INFO - Using cached data for Price
2025-04-28 16:04:52,551 - INFO - Using cached data for Price
2025-04-28 16:04:54,231 - INFO - Using cached data for Price
2025-04-28 16:04:54,231 - INFO - Using cached data for Price
2025-04-28 16:04:54,235 - INFO - Using cached data for Client
2025-04-28 16:04:54,240 - INFO - Using cached data for SaltOperation
2025-04-28 16:04:54,241 - INFO - Using cached data for Price
2025-04-28 16:04:54,241 - INFO - Using cached data for Price
2025-04-28 16:04:54,250 - INFO - Using cached data for Client
2025-04-28 16:04:55,308 - INFO - Using cached data for Price
2025-04-28 16:04:55,308 - INFO - Using cached data for Price
2025-04-28 16:04:56,319 - INFO - Using cached data for Price
2025-04-28 16:04:56,320 - INFO - Using cached data for Price
2025-04-28 16:04:56,330 - INFO - Using cached data for containerOperations
2025-04-28 16:04:56,339 - INFO - Using cached data for Price
2025-04-28 16:04:56,339 - INFO - Using cached data for Price
2025-04-28 16:04:58,704 - INFO - Using cached data for Transfer
2025-04-28 16:04:58,704 - INFO - Using cached data for Price
2025-04-28 16:04:58,705 - INFO - Using cached data for Price
2025-04-28 16:04:58,724 - INFO - Using cached data for ScowTransfer
2025-04-28 16:05:00,537 - INFO - Processing all dataframe categories concurrently
2025-04-28 16:05:00,537 - INFO - Queueing category: emr
2025-04-28 16:05:00,537 - INFO - Queueing category: operations
2025-04-28 16:05:00,537 - INFO - Queueing category: netlist
2025-04-28 16:05:00,538 - INFO - Queueing category: bin_dispatch
2025-04-28 16:05:00,538 - INFO - Queueing category: shore_handling
2025-04-28 16:05:00,538 - INFO - Queueing category: stuffing
2025-04-28 16:05:00,538 - INFO - Queueing category: transport
2025-04-28 16:05:00,538 - INFO - Queueing category: miscellaneous
2025-04-28 16:05:00,538 - INFO - Processing dataframe shifting of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:00,538 - INFO - Collecting LazyFrame for shifting
2025-04-28 16:05:00,554 - ERROR - Error processing dataframe shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-04-28 16:05:00,555 - INFO - Processing dataframe washing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:00,555 - INFO - Collecting LazyFrame for washing
2025-04-28 16:05:00,593 - INFO - Successfully processed dataframe washing
2025-04-28 16:05:00,594 - INFO - Writing to output/csv/washing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:00,594 - INFO - Processing dataframe pti of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:00,594 - INFO - Collecting LazyFrame for pti
2025-04-28 16:05:00,646 - ERROR - Error processing dataframe pti: sub operation not supported for dtypes `str` and `str`
2025-04-28 16:05:00,646 - INFO - Processing dataframe ops of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:00,647 - INFO - Collecting LazyFrame for ops
2025-04-28 16:05:00,681 - INFO - Successfully processed dataframe ops
2025-04-28 16:05:00,681 - INFO - Writing to output/csv/ops.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:00,695 - INFO - Processing dataframe hatch_to_hatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:00,696 - INFO - Collecting LazyFrame for hatch_to_hatch
2025-04-28 16:05:00,745 - INFO - Successfully processed dataframe hatch_to_hatch
2025-04-28 16:05:00,746 - INFO - Writing to output/csv/hatch_to_hatch.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:00,747 - INFO - Processing dataframe net_list of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:00,747 - INFO - Collecting LazyFrame for net_list
2025-04-28 16:05:00,790 - INFO - Successfully processed dataframe net_list
2025-04-28 16:05:00,790 - INFO - Writing to output/csv/net_list.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:00,790 - INFO - Processing dataframe iot_container_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:00,862 - INFO - Collecting LazyFrame for iot_container_stuffing
2025-04-28 16:05:00,901 - INFO - Successfully processed dataframe iot_container_stuffing
2025-04-28 16:05:00,901 - INFO - Writing to output/csv/iot_container_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:00,902 - INFO - Processing dataframe oss_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:00,903 - INFO - Collecting LazyFrame for oss_stuffing
2025-04-28 16:05:00,942 - INFO - Successfully processed dataframe oss_stuffing
2025-04-28 16:05:00,943 - INFO - Processing dataframe full_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:00,944 - INFO - Collecting LazyFrame for full_scows_transfer
2025-04-28 16:05:00,943 - INFO - Writing to output/csv/oss_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:01,153 - INFO - Successfully processed dataframe full_scows_transfer
2025-04-28 16:05:01,153 - INFO - Writing to output/csv/full_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:01,154 - INFO - Processing dataframe empty_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,154 - INFO - Collecting LazyFrame for empty_scows_transfer
2025-04-28 16:05:01,178 - INFO - Successfully processed dataframe empty_scows_transfer
2025-04-28 16:05:01,178 - INFO - Processing dataframe salt of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,179 - INFO - Writing to output/csv/empty_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:01,179 - INFO - Collecting LazyFrame for salt
2025-04-28 16:05:01,213 - INFO - Successfully processed dataframe salt
2025-04-28 16:05:01,213 - INFO - Processing dataframe forklift_salt of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,213 - INFO - Writing to output/csv/salt.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:01,214 - INFO - Collecting LazyFrame for forklift_salt
2025-04-28 16:05:01,284 - INFO - Successfully processed dataframe forklift_salt
2025-04-28 16:05:01,285 - INFO - Successfully wrote washing to file
2025-04-28 16:05:01,285 - INFO - Successfully wrote ops to file
2025-04-28 16:05:01,286 - INFO - Successfully wrote hatch_to_hatch to file
2025-04-28 16:05:01,287 - INFO - Writing to output/csv/forklift_salt.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:01,287 - INFO - Successfully wrote net_list to file
2025-04-28 16:05:01,287 - INFO - Successfully wrote iot_container_stuffing to file
2025-04-28 16:05:01,288 - INFO - Successfully wrote oss_stuffing to file
2025-04-28 16:05:01,288 - INFO - Successfully wrote full_scows_transfer to file
2025-04-28 16:05:01,288 - INFO - Successfully wrote empty_scows_transfer to file
2025-04-28 16:05:01,289 - INFO - Successfully wrote salt to file
2025-04-28 16:05:01,289 - INFO - Processing dataframe bin_tipping of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,289 - INFO - Collecting LazyFrame for bin_tipping
2025-04-28 16:05:01,291 - INFO - Successfully processed dataframe bin_tipping
2025-04-28 16:05:01,292 - INFO - Writing to output/csv/bin_tipping.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:01,292 - INFO - Processing dataframe pallet_liner of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,292 - INFO - Collecting LazyFrame for pallet_liner
2025-04-28 16:05:01,300 - INFO - Successfully processed dataframe pallet_liner
2025-04-28 16:05:01,300 - INFO - Writing to output/csv/pallet_liner.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:01,301 - INFO - Processing dataframe container_plugin of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,301 - INFO - Collecting LazyFrame for container_plugin
2025-04-28 16:05:01,303 - ERROR - Error processing dataframe container_plugin: unable to add a column of length 0 to a DataFrame of height 1
2025-04-28 16:05:01,304 - INFO - Processing dataframe shore_crane of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,304 - INFO - Collecting LazyFrame for shore_crane
2025-04-28 16:05:01,305 - INFO - Successfully processed dataframe shore_crane
2025-04-28 16:05:01,305 - INFO - Processing dataframe transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,305 - INFO - Collecting LazyFrame for transfer
2025-04-28 16:05:01,306 - INFO - Writing to output/csv/shore_crane.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:01,326 - ERROR - Error processing dataframe transfer: conversion from `str` to `enum` failed in column 'destination' for 1 out of 109 values: ["HD Yard"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-28 16:05:01,326 - INFO - Processing dataframe scow_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,326 - INFO - Collecting LazyFrame for scow_transfer
2025-04-28 16:05:01,336 - INFO - Successfully processed dataframe scow_transfer
2025-04-28 16:05:01,337 - INFO - Writing to output/csv/scow_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:01,337 - INFO - Processing dataframe forklift of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,337 - INFO - Collecting LazyFrame for forklift
2025-04-28 16:05:01,338 - ERROR - Error in write_df_to_csv: datatype duration[ns] cannot be written to CSV

Consider using JSON or a binary format.
2025-04-28 16:05:01,345 - INFO - Successfully processed dataframe forklift
2025-04-28 16:05:01,345 - INFO - Writing to output/csv/forklift.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-28 16:05:01,356 - INFO - Processing dataframe static_loader of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,356 - INFO - Collecting LazyFrame for static_loader
2025-04-28 16:05:01,357 - ERROR - Error processing dataframe static_loader: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER [(col("Service")) == (String(Static Loader))] FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,358 - INFO - Processing dataframe dispatch_to_cargo of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,358 - INFO - Collecting LazyFrame for dispatch_to_cargo
2025-04-28 16:05:01,358 - ERROR - Error processing dataframe dispatch_to_cargo: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER [(col("Service")) == (String(Tipping Truck))] FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,359 - INFO - Processing dataframe truck_to_cccs of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,359 - INFO - Collecting LazyFrame for truck_to_cccs
2025-04-28 16:05:01,360 - ERROR - Error processing dataframe truck_to_cccs: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER [(col("Service")) == (String(Tipping Truck))] FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,360 - INFO - Processing dataframe cross_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,360 - INFO - Collecting LazyFrame for cross_stuffing
2025-04-28 16:05:01,360 - ERROR - Error processing dataframe cross_stuffing: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER col("Service").is_in([Series]) FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,360 - INFO - Processing dataframe cccs_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,360 - INFO - Collecting LazyFrame for cccs_stuffing
2025-04-28 16:05:01,361 - ERROR - Error processing dataframe cccs_stuffing: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER col("Service").is_in([Series]) FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,361 - INFO - Processing dataframe bycatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-28 16:05:01,361 - INFO - Collecting LazyFrame for bycatch
2025-04-28 16:05:01,361 - ERROR - Error processing dataframe bycatch: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).strict_cast(Enum(Some(local), Physical)).alias("day")] 
  DF ["date", "movement_type", "customer", "origin", ...]; PROJECT */11 COLUMNS
2025-04-28 16:05:01,361 - INFO - Successfully wrote forklift_salt to file
2025-04-28 16:05:01,361 - INFO - Successfully wrote bin_tipping to file
2025-04-28 16:05:01,361 - INFO - Successfully wrote pallet_liner to file
2025-04-28 16:05:01,362 - INFO - Successfully wrote shore_crane to file
2025-04-28 16:05:01,362 - ERROR - Error processing dataframe scow_transfer: datatype duration[ns] cannot be written to CSV

Consider using JSON or a binary format.
2025-04-28 16:05:01,362 - INFO - Successfully wrote forklift to file
2025-04-28 16:05:01,362 - ERROR - Error saving shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-04-28 16:05:01,362 - INFO - Successfully saved washing
2025-04-28 16:05:01,362 - ERROR - Error saving pti: sub operation not supported for dtypes `str` and `str`
2025-04-28 16:05:01,362 - INFO - Successfully saved ops
2025-04-28 16:05:01,362 - INFO - Successfully saved hatch_to_hatch
2025-04-28 16:05:01,362 - INFO - Successfully saved net_list
2025-04-28 16:05:01,362 - INFO - Successfully saved iot_container_stuffing
2025-04-28 16:05:01,362 - INFO - Successfully saved oss_stuffing
2025-04-28 16:05:01,363 - INFO - Successfully saved full_scows_transfer
2025-04-28 16:05:01,363 - INFO - Successfully saved empty_scows_transfer
2025-04-28 16:05:01,363 - INFO - Successfully saved salt
2025-04-28 16:05:01,363 - INFO - Successfully saved forklift_salt
2025-04-28 16:05:01,363 - INFO - Successfully saved bin_tipping
2025-04-28 16:05:01,363 - INFO - Successfully saved pallet_liner
2025-04-28 16:05:01,363 - ERROR - Error saving container_plugin: unable to add a column of length 0 to a DataFrame of height 1
2025-04-28 16:05:01,363 - INFO - Successfully saved shore_crane
2025-04-28 16:05:01,363 - ERROR - Error saving transfer: conversion from `str` to `enum` failed in column 'destination' for 1 out of 109 values: ["HD Yard"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-28 16:05:01,363 - ERROR - Error saving scow_transfer: datatype duration[ns] cannot be written to CSV

Consider using JSON or a binary format.
2025-04-28 16:05:01,363 - INFO - Successfully saved forklift
2025-04-28 16:05:01,363 - ERROR - Error saving static_loader: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER [(col("Service")) == (String(Static Loader))] FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,363 - ERROR - Error saving dispatch_to_cargo: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER [(col("Service")) == (String(Tipping Truck))] FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,363 - ERROR - Error saving truck_to_cccs: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER [(col("Service")) == (String(Tipping Truck))] FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,363 - ERROR - Error saving cross_stuffing: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER col("Service").is_in([Series]) FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,363 - ERROR - Error saving cccs_stuffing: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER col("Service").is_in([Series]) FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,363 - ERROR - Error saving bycatch: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).strict_cast(Enum(Some(local), Physical)).alias("day")] 
  DF ["date", "movement_type", "customer", "origin", ...]; PROJECT */11 COLUMNS
2025-04-28 16:05:01,363 - INFO - Save completed
2025-04-28 16:05:01,364 - INFO - Successfully saved: 14 files
2025-04-28 16:05:01,364 - ERROR - Failed to save: 11 files
2025-04-28 16:05:01,364 - ERROR -   - shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-04-28 16:05:01,364 - ERROR -   - pti: sub operation not supported for dtypes `str` and `str`
2025-04-28 16:05:01,364 - ERROR -   - container_plugin: unable to add a column of length 0 to a DataFrame of height 1
2025-04-28 16:05:01,364 - ERROR -   - transfer: conversion from `str` to `enum` failed in column 'destination' for 1 out of 109 values: ["HD Yard"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-04-28 16:05:01,364 - ERROR -   - scow_transfer: datatype duration[ns] cannot be written to CSV

Consider using JSON or a binary format.
2025-04-28 16:05:01,364 - ERROR -   - static_loader: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER [(col("Service")) == (String(Static Loader))] FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,365 - ERROR -   - dispatch_to_cargo: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER [(col("Service")) == (String(Tipping Truck))] FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,365 - ERROR -   - truck_to_cccs: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER [(col("Service")) == (String(Tipping Truck))] FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,365 - ERROR -   - cross_stuffing: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER col("Service").is_in([Series]) FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,365 - ERROR -   - cccs_stuffing: datatypes of join keys don't match - `date`: date on left does not match `Date`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
FILTER col("Service").is_in([Series]) FROM
   SELECT [col("Service"), col("Price"), col("Date")] FROM
    FILTER col("Service").is_in([Series]) FROM
       WITH_COLUMNS:
       [col("StartingDate").alias("Date"), col("EndingDate").str.strptime([String(raise)]).alias("end")] 
        DF ["Service", "Class", "Price", "StartingDate", ...]; PROJECT */7 COLUMNS
2025-04-28 16:05:01,366 - ERROR -   - bycatch: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).strict_cast(Enum(Some(local), Physical)).alias("day")] 
  DF ["date", "movement_type", "customer", "origin", ...]; PROJECT */11 COLUMNS
2025-04-30 12:24:24,493 - DEBUG - Using selector: EpollSelector
2025-04-30 12:24:24,533 - INFO - Starting application
2025-04-30 12:24:24,533 - INFO - Clearing screen
2025-04-30 12:24:28,073 - INFO - Selected: Save files
2025-04-30 12:24:28,073 - INFO - Clearing screen
2025-04-30 12:24:36,848 - INFO - Initiating save operation for miscellaneous
2025-04-30 12:24:39,137 - INFO - Using cached data for Price
2025-04-30 12:24:41,157 - INFO - Loading container data from sheet
2025-04-30 12:24:45,729 - INFO - Using cached data for Price
2025-04-30 12:24:45,729 - INFO - Using cached data for Price
2025-04-30 12:24:47,158 - INFO - Using cached data for Price
2025-04-30 12:24:47,158 - INFO - Using cached data for Price
2025-04-30 12:24:47,167 - INFO - Using cached data for PTI
2025-04-30 12:24:47,167 - INFO - Using cached data for Price
2025-04-30 12:24:47,168 - INFO - Using cached data for Price
2025-04-30 12:24:47,176 - INFO - Using cached data for Price
2025-04-30 12:24:47,176 - INFO - Using cached data for Price
2025-04-30 12:24:49,981 - INFO - Using cached data for Price
2025-04-30 12:24:49,981 - INFO - Using cached data for Price
2025-04-30 12:24:50,005 - INFO - Using cached data for ScowTransfer
2025-04-30 12:24:50,006 - INFO - Using cached data for Price
2025-04-30 12:24:50,006 - INFO - Using cached data for Price
2025-04-30 12:24:50,007 - INFO - Using cached data for CCCSReport
2025-04-30 12:24:50,008 - INFO - Using cached data for Price
2025-04-30 12:24:50,008 - INFO - Using cached data for Price
2025-04-30 12:24:50,009 - INFO - Using cached data for CCCSReport
2025-04-30 12:24:50,009 - INFO - Using cached data for Price
2025-04-30 12:24:50,010 - INFO - Using cached data for Price
2025-04-30 12:24:50,011 - INFO - Using cached data for CCCSReport
2025-04-30 12:24:50,012 - INFO - Using cached data for Price
2025-04-30 12:24:50,012 - INFO - Using cached data for Price
2025-04-30 12:24:50,969 - INFO - Using cached data for Price
2025-04-30 12:24:50,969 - INFO - Using cached data for Price
2025-04-30 12:24:52,078 - INFO - Using cached data for Price
2025-04-30 12:24:52,079 - INFO - Using cached data for Price
2025-04-30 12:24:52,080 - INFO - Using cached data for CCCSReport
2025-04-30 12:24:53,120 - INFO - Using cached data for Client
2025-04-30 12:24:53,121 - INFO - Using cached data for Client
2025-04-30 12:24:53,121 - INFO - Using cached data for Client
2025-04-30 12:24:53,121 - INFO - Using cached data for Client
2025-04-30 12:24:53,122 - INFO - Using cached data for Client
2025-04-30 12:24:53,122 - INFO - Using cached data for Client
2025-04-30 12:24:53,122 - INFO - Using cached data for Client
2025-04-30 12:24:53,122 - INFO - Using cached data for Client
2025-04-30 12:24:53,123 - INFO - Using cached data for Client
2025-04-30 12:24:53,123 - INFO - Using cached data for Client
2025-04-30 12:24:53,123 - INFO - Using cached data for Client
2025-04-30 12:24:53,124 - INFO - Using cached data for Client
2025-04-30 12:24:53,124 - INFO - Using cached data for CCCSReport
2025-04-30 12:24:54,145 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-30 12:24:54,146 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-30 12:24:54,147 - INFO - Using cached data for CCCSReport
2025-04-30 12:24:54,148 - INFO - Using cached data for IPHSBycatchTransfer
2025-04-30 12:24:54,150 - INFO - Using cached data for Price
2025-04-30 12:24:54,150 - INFO - Using cached data for Price
2025-04-30 12:24:59,032 - INFO - Using cached data for CCCSReport
2025-04-30 12:24:59,033 - INFO - Using cached data for Price
2025-04-30 12:24:59,033 - INFO - Using cached data for Price
2025-04-30 12:25:00,585 - INFO - Using cached data for Price
2025-04-30 12:25:00,586 - INFO - Using cached data for Price
2025-04-30 12:25:00,590 - INFO - Using cached data for UnloadingSummary
2025-04-30 12:25:00,590 - INFO - Using cached data for containerOperations
2025-04-30 12:25:00,593 - INFO - Using cached data for Price
2025-04-30 12:25:00,593 - INFO - Using cached data for Price
2025-04-30 12:25:00,599 - INFO - Using cached data for Price
2025-04-30 12:25:00,599 - INFO - Using cached data for Price
2025-04-30 12:25:00,600 - INFO - Using cached data for UnloadingSummary
2025-04-30 12:25:00,600 - INFO - Using cached data for RawData
2025-04-30 12:25:00,600 - INFO - Using cached data for CCCSReport
2025-04-30 12:25:00,602 - INFO - Using cached data for Price
2025-04-30 12:25:00,602 - INFO - Using cached data for Price
2025-04-30 12:25:00,602 - INFO - Using cached data for containerOperations
2025-04-30 12:25:00,609 - INFO - Using cached data for Price
2025-04-30 12:25:00,609 - INFO - Using cached data for Price
2025-04-30 12:25:00,614 - INFO - Using cached data for Price
2025-04-30 12:25:00,614 - INFO - Using cached data for Price
2025-04-30 12:25:00,615 - INFO - Using cached data for RawData
2025-04-30 12:25:01,539 - INFO - Using cached data for Price
2025-04-30 12:25:01,540 - INFO - Using cached data for Price
2025-04-30 12:25:02,950 - INFO - Using cached data for Price
2025-04-30 12:25:02,950 - INFO - Using cached data for Price
2025-04-30 12:25:02,988 - INFO - Using cached data for Client
2025-04-30 12:25:03,014 - INFO - Using cached data for SaltOperation
2025-04-30 12:25:03,014 - INFO - Using cached data for Price
2025-04-30 12:25:03,015 - INFO - Using cached data for Price
2025-04-30 12:25:03,019 - INFO - Using cached data for Client
2025-04-30 12:25:03,973 - INFO - Using cached data for Price
2025-04-30 12:25:03,973 - INFO - Using cached data for Price
2025-04-30 12:25:05,087 - INFO - Using cached data for Price
2025-04-30 12:25:05,087 - INFO - Using cached data for Price
2025-04-30 12:25:05,095 - INFO - Using cached data for containerOperations
2025-04-30 12:25:05,097 - INFO - Using cached data for Price
2025-04-30 12:25:05,097 - INFO - Using cached data for Price
2025-04-30 12:25:08,992 - INFO - Using cached data for Transfer
2025-04-30 12:25:08,993 - INFO - Using cached data for Price
2025-04-30 12:25:08,993 - INFO - Using cached data for Price
2025-04-30 12:25:09,014 - INFO - Using cached data for ScowTransfer
2025-04-30 12:25:11,065 - INFO - Processing dataframe category: miscellaneous
2025-04-30 12:25:11,065 - INFO - Processing dataframes: ['static_loader', 'dispatch_to_cargo', 'truck_to_cccs', 'cross_stuffing', 'cccs_stuffing', 'bycatch']
2025-04-30 12:25:11,065 - INFO - Processing dataframe static_loader of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-30 12:25:11,066 - INFO - Collecting LazyFrame for static_loader
2025-04-30 12:25:11,558 - INFO - Successfully processed dataframe static_loader
2025-04-30 12:25:11,559 - INFO - Writing to output/csv/static_loader.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-30 12:25:11,560 - INFO - Processing dataframe dispatch_to_cargo of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-30 12:25:11,561 - INFO - Collecting LazyFrame for dispatch_to_cargo
2025-04-30 12:25:11,615 - INFO - Successfully processed dataframe dispatch_to_cargo
2025-04-30 12:25:11,615 - INFO - Writing to output/csv/dispatch_to_cargo.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-30 12:25:11,616 - INFO - Processing dataframe truck_to_cccs of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-30 12:25:11,616 - INFO - Collecting LazyFrame for truck_to_cccs
2025-04-30 12:25:11,661 - INFO - Successfully processed dataframe truck_to_cccs
2025-04-30 12:25:11,661 - INFO - Writing to output/csv/truck_to_cccs.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-30 12:25:11,662 - INFO - Processing dataframe cross_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-30 12:25:11,662 - INFO - Collecting LazyFrame for cross_stuffing
2025-04-30 12:25:11,663 - INFO - Successfully processed dataframe cross_stuffing
2025-04-30 12:25:11,664 - INFO - Writing to output/csv/cross_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-30 12:25:11,664 - INFO - Processing dataframe cccs_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-30 12:25:11,664 - INFO - Collecting LazyFrame for cccs_stuffing
2025-04-30 12:25:11,669 - INFO - Successfully processed dataframe cccs_stuffing
2025-04-30 12:25:11,669 - INFO - Writing to output/csv/cccs_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-30 12:25:11,670 - INFO - Processing dataframe bycatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-04-30 12:25:11,670 - INFO - Collecting LazyFrame for bycatch
2025-04-30 12:25:11,879 - INFO - Successfully processed dataframe bycatch
2025-04-30 12:25:11,880 - INFO - Writing to output/csv/bycatch.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-04-30 12:25:11,880 - INFO - Successfully wrote static_loader to file
2025-04-30 12:25:11,881 - INFO - Successfully wrote dispatch_to_cargo to file
2025-04-30 12:25:11,881 - INFO - Successfully wrote truck_to_cccs to file
2025-04-30 12:25:11,882 - INFO - Successfully wrote cross_stuffing to file
2025-04-30 12:25:11,882 - INFO - Successfully wrote cccs_stuffing to file
2025-04-30 12:25:11,885 - INFO - Successfully wrote bycatch to file
2025-04-30 12:25:11,885 - INFO - Successfully saved static_loader
2025-04-30 12:25:11,886 - INFO - Successfully saved dispatch_to_cargo
2025-04-30 12:25:11,886 - INFO - Successfully saved truck_to_cccs
2025-04-30 12:25:11,886 - INFO - Successfully saved cross_stuffing
2025-04-30 12:25:11,886 - INFO - Successfully saved cccs_stuffing
2025-04-30 12:25:11,887 - INFO - Successfully saved bycatch
2025-04-30 12:25:11,887 - INFO - Save completed
2025-04-30 12:25:11,887 - INFO - Successfully saved: static_loader, dispatch_to_cargo, truck_to_cccs, cross_stuffing, cccs_stuffing, bycatch
2025-04-30 14:11:01,618 - INFO - Starting application
2025-04-30 14:11:01,811 - INFO - Clearing screen
2025-06-07 15:57:58,837 - DEBUG - Using selector: EpollSelector
2025-06-07 15:57:59,047 - INFO - Starting application
2025-06-07 15:57:59,047 - INFO - Clearing screen
2025-06-07 15:58:01,837 - INFO - Selected: Save files
2025-06-07 15:58:01,837 - INFO - Clearing screen
2025-06-07 15:58:05,580 - INFO - Initiating save operation for all
2025-06-07 15:58:08,695 - INFO - Using cached data for Price
2025-06-07 15:58:14,707 - INFO - Loading container data from sheet
2025-06-07 15:58:19,497 - INFO - Using cached data for Price
2025-06-07 15:58:19,497 - INFO - Using cached data for Price
2025-06-07 15:58:20,647 - INFO - Using cached data for Price
2025-06-07 15:58:20,647 - INFO - Using cached data for Price
2025-06-07 15:58:20,654 - INFO - Using cached data for PTI
2025-06-07 15:58:20,654 - INFO - Using cached data for Price
2025-06-07 15:58:20,655 - INFO - Using cached data for Price
2025-06-07 15:58:20,660 - INFO - Using cached data for Price
2025-06-07 15:58:20,661 - INFO - Using cached data for Price
2025-06-07 15:58:23,446 - INFO - Using cached data for Price
2025-06-07 15:58:23,446 - INFO - Using cached data for Price
2025-06-07 15:58:23,557 - INFO - Using cached data for ScowTransfer
2025-06-07 15:58:23,558 - INFO - Using cached data for Price
2025-06-07 15:58:23,558 - INFO - Using cached data for Price
2025-06-07 15:58:23,561 - INFO - Using cached data for CCCSReport
2025-06-07 15:58:23,561 - INFO - Using cached data for Price
2025-06-07 15:58:23,561 - INFO - Using cached data for Price
2025-06-07 15:58:23,564 - INFO - Using cached data for CCCSReport
2025-06-07 15:58:23,565 - INFO - Using cached data for Price
2025-06-07 15:58:23,566 - INFO - Using cached data for Price
2025-06-07 15:58:23,569 - INFO - Using cached data for CCCSReport
2025-06-07 15:58:23,570 - INFO - Using cached data for Price
2025-06-07 15:58:23,570 - INFO - Using cached data for Price
2025-06-07 15:58:24,240 - INFO - Using cached data for Price
2025-06-07 15:58:24,240 - INFO - Using cached data for Price
2025-06-07 15:58:24,840 - INFO - Using cached data for Price
2025-06-07 15:58:24,840 - INFO - Using cached data for Price
2025-06-07 15:58:24,842 - INFO - Using cached data for CCCSReport
2025-06-07 15:58:25,470 - INFO - Using cached data for Client
2025-06-07 15:58:25,471 - INFO - Using cached data for Client
2025-06-07 15:58:25,472 - INFO - Using cached data for Client
2025-06-07 15:58:25,474 - INFO - Using cached data for Client
2025-06-07 15:58:25,475 - INFO - Using cached data for Client
2025-06-07 15:58:25,476 - INFO - Using cached data for Client
2025-06-07 15:58:25,477 - INFO - Using cached data for Client
2025-06-07 15:58:25,479 - INFO - Using cached data for Client
2025-06-07 15:58:25,480 - INFO - Using cached data for Client
2025-06-07 15:58:25,481 - INFO - Using cached data for Client
2025-06-07 15:58:25,482 - INFO - Using cached data for Client
2025-06-07 15:58:25,484 - INFO - Using cached data for Client
2025-06-07 15:58:25,486 - INFO - Using cached data for CCCSReport
2025-06-07 15:58:26,136 - INFO - Using cached data for IPHSBycatchTransfer
2025-06-07 15:58:26,137 - INFO - Using cached data for IPHSBycatchTransfer
2025-06-07 15:58:26,137 - INFO - Using cached data for CCCSReport
2025-06-07 15:58:26,138 - INFO - Using cached data for IPHSBycatchTransfer
2025-06-07 15:58:26,139 - INFO - Using cached data for Price
2025-06-07 15:58:26,139 - INFO - Using cached data for Price
2025-06-07 15:58:34,083 - INFO - Using cached data for CCCSReport
2025-06-07 15:58:34,084 - INFO - Using cached data for Price
2025-06-07 15:58:34,084 - INFO - Using cached data for Price
2025-06-07 15:58:35,010 - INFO - Using cached data for Price
2025-06-07 15:58:35,010 - INFO - Using cached data for Price
2025-06-07 15:58:35,014 - INFO - Using cached data for UnloadingSummary
2025-06-07 15:58:35,014 - INFO - Using cached data for containerOperations
2025-06-07 15:58:35,016 - INFO - Using cached data for Price
2025-06-07 15:58:35,017 - INFO - Using cached data for Price
2025-06-07 15:58:35,020 - INFO - Using cached data for Price
2025-06-07 15:58:35,020 - INFO - Using cached data for Price
2025-06-07 15:58:35,021 - INFO - Using cached data for UnloadingSummary
2025-06-07 15:58:35,021 - INFO - Using cached data for RawData
2025-06-07 15:58:35,021 - INFO - Using cached data for CCCSReport
2025-06-07 15:58:35,022 - INFO - Using cached data for Price
2025-06-07 15:58:35,022 - INFO - Using cached data for Price
2025-06-07 15:58:35,023 - INFO - Using cached data for containerOperations
2025-06-07 15:58:35,025 - INFO - Using cached data for Price
2025-06-07 15:58:35,025 - INFO - Using cached data for Price
2025-06-07 15:58:35,031 - INFO - Using cached data for Price
2025-06-07 15:58:35,031 - INFO - Using cached data for Price
2025-06-07 15:58:35,032 - INFO - Using cached data for RawData
2025-06-07 15:58:35,705 - INFO - Using cached data for Price
2025-06-07 15:58:35,705 - INFO - Using cached data for Price
2025-06-07 15:58:37,023 - INFO - Using cached data for Price
2025-06-07 15:58:37,024 - INFO - Using cached data for Price
2025-06-07 15:58:37,361 - INFO - Using cached data for Client
2025-06-07 15:58:38,221 - INFO - Using cached data for SaltOperation
2025-06-07 15:58:38,221 - INFO - Using cached data for Price
2025-06-07 15:58:38,221 - INFO - Using cached data for Price
2025-06-07 15:58:38,223 - INFO - Using cached data for Client
2025-06-07 15:58:39,086 - INFO - Using cached data for Price
2025-06-07 15:58:39,086 - INFO - Using cached data for Price
2025-06-07 15:58:39,700 - INFO - Using cached data for Price
2025-06-07 15:58:39,700 - INFO - Using cached data for Price
2025-06-07 15:58:39,702 - INFO - Using cached data for containerOperations
2025-06-07 15:58:39,704 - INFO - Using cached data for Price
2025-06-07 15:58:39,704 - INFO - Using cached data for Price
2025-06-07 15:58:42,274 - INFO - Using cached data for Transfer
2025-06-07 15:58:42,274 - INFO - Using cached data for Price
2025-06-07 15:58:42,274 - INFO - Using cached data for Price
2025-06-07 15:58:42,395 - INFO - Using cached data for ScowTransfer
2025-06-07 15:58:44,077 - INFO - Processing all dataframe categories concurrently
2025-06-07 15:58:44,077 - INFO - Queueing category: emr
2025-06-07 15:58:44,077 - INFO - Queueing category: operations
2025-06-07 15:58:44,078 - INFO - Queueing category: netlist
2025-06-07 15:58:44,078 - INFO - Queueing category: bin_dispatch
2025-06-07 15:58:44,078 - INFO - Queueing category: shore_handling
2025-06-07 15:58:44,078 - INFO - Queueing category: stuffing
2025-06-07 15:58:44,078 - INFO - Queueing category: transport
2025-06-07 15:58:44,078 - INFO - Queueing category: miscellaneous
2025-06-07 15:58:44,079 - INFO - Processing dataframe shifting of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:44,079 - INFO - Collecting LazyFrame for shifting
2025-06-07 15:58:44,512 - ERROR - Error processing dataframe shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-06-07 15:58:44,512 - INFO - Processing dataframe washing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:44,513 - INFO - Collecting LazyFrame for washing
2025-06-07 15:58:45,238 - INFO - Successfully processed dataframe washing
2025-06-07 15:58:45,238 - INFO - Writing to output/csv/washing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:45,238 - INFO - Processing dataframe pti of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:45,238 - INFO - Collecting LazyFrame for pti
2025-06-07 15:58:46,098 - ERROR - Error processing dataframe pti: sub operation not supported for dtypes `str` and `str`
2025-06-07 15:58:46,099 - INFO - Processing dataframe ops of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:46,099 - INFO - Collecting LazyFrame for ops
2025-06-07 15:58:46,378 - INFO - Successfully processed dataframe ops
2025-06-07 15:58:46,378 - INFO - Writing to output/csv/ops.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:46,378 - INFO - Processing dataframe hatch_to_hatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:46,459 - INFO - Collecting LazyFrame for hatch_to_hatch
2025-06-07 15:58:47,642 - INFO - Successfully processed dataframe hatch_to_hatch
2025-06-07 15:58:47,642 - INFO - Writing to output/csv/hatch_to_hatch.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:47,642 - INFO - Processing dataframe net_list of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:47,642 - INFO - Collecting LazyFrame for net_list
2025-06-07 15:58:50,246 - INFO - Successfully processed dataframe net_list
2025-06-07 15:58:50,246 - INFO - Writing to output/csv/net_list.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:50,247 - INFO - Processing dataframe iot_container_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:50,248 - INFO - Collecting LazyFrame for iot_container_stuffing
2025-06-07 15:58:50,876 - INFO - Successfully processed dataframe iot_container_stuffing
2025-06-07 15:58:50,877 - INFO - Writing to output/csv/iot_container_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:50,877 - INFO - Processing dataframe oss_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:50,877 - INFO - Collecting LazyFrame for oss_stuffing
2025-06-07 15:58:51,074 - INFO - Successfully processed dataframe oss_stuffing
2025-06-07 15:58:51,074 - INFO - Writing to output/csv/oss_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:51,075 - INFO - Processing dataframe full_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:51,075 - INFO - Collecting LazyFrame for full_scows_transfer
2025-06-07 15:58:51,717 - INFO - Successfully processed dataframe full_scows_transfer
2025-06-07 15:58:51,717 - INFO - Writing to output/csv/full_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:51,718 - INFO - Processing dataframe empty_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:51,718 - INFO - Collecting LazyFrame for empty_scows_transfer
2025-06-07 15:58:51,728 - INFO - Successfully processed dataframe empty_scows_transfer
2025-06-07 15:58:51,729 - INFO - Writing to output/csv/empty_scows_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:51,729 - INFO - Processing dataframe salt of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:51,729 - INFO - Collecting LazyFrame for salt
2025-06-07 15:58:52,040 - INFO - Successfully processed dataframe salt
2025-06-07 15:58:52,041 - INFO - Writing to output/csv/salt.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:52,041 - INFO - Processing dataframe forklift_salt of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:52,041 - INFO - Collecting LazyFrame for forklift_salt
2025-06-07 15:58:52,538 - INFO - Successfully processed dataframe forklift_salt
2025-06-07 15:58:52,539 - INFO - Writing to output/csv/forklift_salt.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:52,539 - INFO - Successfully wrote washing to file
2025-06-07 15:58:52,632 - INFO - Successfully wrote ops to file
2025-06-07 15:58:52,633 - INFO - Successfully wrote hatch_to_hatch to file
2025-06-07 15:58:52,633 - INFO - Successfully wrote net_list to file
2025-06-07 15:58:52,634 - INFO - Successfully wrote iot_container_stuffing to file
2025-06-07 15:58:52,634 - INFO - Successfully wrote oss_stuffing to file
2025-06-07 15:58:52,634 - INFO - Successfully wrote full_scows_transfer to file
2025-06-07 15:58:52,635 - INFO - Successfully wrote empty_scows_transfer to file
2025-06-07 15:58:52,635 - INFO - Processing dataframe bin_tipping of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:52,636 - INFO - Collecting LazyFrame for bin_tipping
2025-06-07 15:58:52,768 - INFO - Successfully processed dataframe bin_tipping
2025-06-07 15:58:52,769 - INFO - Writing to output/csv/bin_tipping.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:52,769 - INFO - Processing dataframe pallet_liner of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:52,770 - INFO - Collecting LazyFrame for pallet_liner
2025-06-07 15:58:52,963 - INFO - Successfully processed dataframe pallet_liner
2025-06-07 15:58:52,963 - INFO - Writing to output/csv/pallet_liner.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:52,964 - INFO - Processing dataframe container_plugin of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:52,964 - INFO - Collecting LazyFrame for container_plugin
2025-06-07 15:58:53,234 - INFO - Successfully processed dataframe container_plugin
2025-06-07 15:58:53,234 - INFO - Writing to output/csv/container_plugin.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:53,235 - INFO - Processing dataframe shore_crane of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:53,235 - INFO - Collecting LazyFrame for shore_crane
2025-06-07 15:58:53,242 - INFO - Successfully processed dataframe shore_crane
2025-06-07 15:58:53,242 - INFO - Processing dataframe transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:53,243 - INFO - Collecting LazyFrame for transfer
2025-06-07 15:58:53,243 - INFO - Writing to output/csv/shore_crane.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:53,398 - ERROR - Error processing dataframe transfer: conversion from `str` to `time` failed in column 'time_out' for 1 out of 124 values: [""]
2025-06-07 15:58:53,399 - INFO - Processing dataframe scow_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:53,399 - INFO - Collecting LazyFrame for scow_transfer
2025-06-07 15:58:53,409 - INFO - Successfully processed dataframe scow_transfer
2025-06-07 15:58:53,410 - INFO - Writing to output/csv/scow_transfer.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:53,411 - INFO - Processing dataframe forklift of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:53,412 - INFO - Collecting LazyFrame for forklift
2025-06-07 15:58:53,443 - INFO - Successfully processed dataframe forklift
2025-06-07 15:58:53,444 - INFO - Writing to output/csv/forklift.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:53,444 - INFO - Processing dataframe static_loader of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:53,444 - INFO - Collecting LazyFrame for static_loader
2025-06-07 15:58:53,452 - ERROR - Error in write_df_to_csv: datatype duration[ns] cannot be written to CSV

Consider using JSON or a binary format.
2025-06-07 15:58:53,462 - INFO - Successfully processed dataframe static_loader
2025-06-07 15:58:53,572 - INFO - Writing to output/csv/static_loader.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:53,573 - INFO - Processing dataframe dispatch_to_cargo of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:53,573 - INFO - Collecting LazyFrame for dispatch_to_cargo
2025-06-07 15:58:53,580 - INFO - Successfully processed dataframe dispatch_to_cargo
2025-06-07 15:58:53,580 - INFO - Successfully wrote forklift_salt to file
2025-06-07 15:58:53,581 - INFO - Successfully wrote salt to file
2025-06-07 15:58:53,581 - INFO - Successfully wrote bin_tipping to file
2025-06-07 15:58:53,581 - INFO - Successfully wrote pallet_liner to file
2025-06-07 15:58:53,581 - INFO - Successfully wrote container_plugin to file
2025-06-07 15:58:53,581 - INFO - Successfully wrote shore_crane to file
2025-06-07 15:58:53,581 - ERROR - Error processing dataframe scow_transfer: datatype duration[ns] cannot be written to CSV

Consider using JSON or a binary format.
2025-06-07 15:58:53,581 - INFO - Processing dataframe truck_to_cccs of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:53,581 - INFO - Collecting LazyFrame for truck_to_cccs
2025-06-07 15:58:53,583 - INFO - Writing to output/csv/dispatch_to_cargo.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:53,594 - INFO - Successfully processed dataframe truck_to_cccs
2025-06-07 15:58:53,594 - INFO - Writing to output/csv/truck_to_cccs.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:53,594 - INFO - Processing dataframe cross_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:53,829 - INFO - Collecting LazyFrame for cross_stuffing
2025-06-07 15:58:53,836 - INFO - Successfully processed dataframe cross_stuffing
2025-06-07 15:58:53,837 - INFO - Writing to output/csv/cross_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:53,838 - INFO - Processing dataframe cccs_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:53,838 - INFO - Collecting LazyFrame for cccs_stuffing
2025-06-07 15:58:53,876 - INFO - Successfully processed dataframe cccs_stuffing
2025-06-07 15:58:53,876 - INFO - Writing to output/csv/cccs_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:53,877 - INFO - Processing dataframe bycatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-06-07 15:58:53,878 - INFO - Collecting LazyFrame for bycatch
2025-06-07 15:58:54,198 - INFO - Successfully processed dataframe bycatch
2025-06-07 15:58:54,198 - INFO - Successfully wrote forklift to file
2025-06-07 15:58:54,199 - INFO - Successfully wrote static_loader to file
2025-06-07 15:58:54,199 - INFO - Writing to output/csv/bycatch.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-06-07 15:58:54,200 - INFO - Successfully wrote dispatch_to_cargo to file
2025-06-07 15:58:54,200 - INFO - Successfully wrote truck_to_cccs to file
2025-06-07 15:58:54,200 - INFO - Successfully wrote cross_stuffing to file
2025-06-07 15:58:54,201 - INFO - Successfully wrote cccs_stuffing to file
2025-06-07 15:58:54,204 - INFO - Successfully wrote bycatch to file
2025-06-07 15:58:54,204 - ERROR - Error saving shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-06-07 15:58:54,204 - INFO - Successfully saved washing
2025-06-07 15:58:54,205 - ERROR - Error saving pti: sub operation not supported for dtypes `str` and `str`
2025-06-07 15:58:54,205 - INFO - Successfully saved ops
2025-06-07 15:58:54,205 - INFO - Successfully saved hatch_to_hatch
2025-06-07 15:58:54,205 - INFO - Successfully saved net_list
2025-06-07 15:58:54,205 - INFO - Successfully saved iot_container_stuffing
2025-06-07 15:58:54,205 - INFO - Successfully saved oss_stuffing
2025-06-07 15:58:54,206 - INFO - Successfully saved full_scows_transfer
2025-06-07 15:58:54,206 - INFO - Successfully saved empty_scows_transfer
2025-06-07 15:58:54,206 - INFO - Successfully saved salt
2025-06-07 15:58:54,206 - INFO - Successfully saved forklift_salt
2025-06-07 15:58:54,206 - INFO - Successfully saved bin_tipping
2025-06-07 15:58:54,206 - INFO - Successfully saved pallet_liner
2025-06-07 15:58:54,206 - INFO - Successfully saved container_plugin
2025-06-07 15:58:54,207 - INFO - Successfully saved shore_crane
2025-06-07 15:58:54,207 - ERROR - Error saving transfer: conversion from `str` to `time` failed in column 'time_out' for 1 out of 124 values: [""]
2025-06-07 15:58:54,207 - ERROR - Error saving scow_transfer: datatype duration[ns] cannot be written to CSV

Consider using JSON or a binary format.
2025-06-07 15:58:54,207 - INFO - Successfully saved forklift
2025-06-07 15:58:54,207 - INFO - Successfully saved static_loader
2025-06-07 15:58:54,207 - INFO - Successfully saved dispatch_to_cargo
2025-06-07 15:58:54,208 - INFO - Successfully saved truck_to_cccs
2025-06-07 15:58:54,208 - INFO - Successfully saved cross_stuffing
2025-06-07 15:58:54,208 - INFO - Successfully saved cccs_stuffing
2025-06-07 15:58:54,208 - INFO - Successfully saved bycatch
2025-06-07 15:58:54,208 - INFO - Save completed
2025-06-07 15:58:54,208 - INFO - Successfully saved: 21 files
2025-06-07 15:58:54,209 - ERROR - Failed to save: 4 files
2025-06-07 15:58:54,209 - ERROR -   - shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-06-07 15:58:54,209 - ERROR -   - pti: sub operation not supported for dtypes `str` and `str`
2025-06-07 15:58:54,209 - ERROR -   - transfer: conversion from `str` to `time` failed in column 'time_out' for 1 out of 124 values: [""]
2025-06-07 15:58:54,209 - ERROR -   - scow_transfer: datatype duration[ns] cannot be written to CSV

Consider using JSON or a binary format.
2025-06-15 08:13:01,348 - DEBUG - Using selector: EpollSelector
2025-06-15 08:13:01,394 - INFO - Starting application
2025-06-15 08:13:01,394 - INFO - Clearing screen
2025-06-15 08:13:04,021 - INFO - Exiting application
2025-07-12 09:54:31,854 - DEBUG - Using selector: EpollSelector
2025-07-12 09:54:31,924 - INFO - Starting application
2025-07-12 09:54:31,924 - INFO - Clearing screen
2025-07-12 09:54:38,333 - INFO - Selected: Save files
2025-07-12 09:54:38,334 - INFO - Clearing screen
2025-07-12 09:54:42,342 - INFO - Initiating save operation for all
2025-07-12 09:54:45,230 - INFO - Using cached data for Price
2025-07-12 09:54:46,828 - INFO - Using cached data for Price
2025-07-12 09:54:46,828 - INFO - Using cached data for Price
2025-07-12 09:54:47,039 - INFO - Using cached data for Price
2025-07-12 09:54:47,040 - INFO - Using cached data for Price
2025-07-12 09:54:47,045 - INFO - Using cached data for Price
2025-07-12 09:54:47,046 - INFO - Using cached data for Price
2025-07-12 09:54:47,049 - INFO - Loading container data from sheet
2025-07-12 09:54:47,050 - INFO - Loading container data from sheet
2025-07-12 09:54:47,051 - INFO - Using cached data for Price
2025-07-12 09:54:47,051 - INFO - Using cached data for Price
2025-07-12 09:54:47,302 - INFO - Using cached data for Price
2025-07-12 09:54:47,302 - INFO - Using cached data for Price
2025-07-12 09:54:47,305 - INFO - Using cached data for PTI
2025-07-12 09:54:47,305 - INFO - Using cached data for Price
2025-07-12 09:54:47,305 - INFO - Using cached data for Price
2025-07-12 09:54:47,307 - INFO - Using cached data for Price
2025-07-12 09:54:47,307 - INFO - Using cached data for Price
2025-07-12 09:54:47,308 - INFO - Loading container data from sheet
2025-07-12 09:54:47,310 - INFO - Using cached data for Price
2025-07-12 09:54:47,310 - INFO - Using cached data for Price
2025-07-12 09:54:47,373 - INFO - Loading container data from sheet
2025-07-12 09:54:47,374 - INFO - Using cached data for Price
2025-07-12 09:54:47,374 - INFO - Using cached data for Price
2025-07-12 09:54:47,375 - INFO - Using cached data for Price
2025-07-12 09:54:47,375 - INFO - Using cached data for Price
2025-07-12 09:54:47,402 - INFO - Using cached data for Price
2025-07-12 09:54:47,402 - INFO - Using cached data for Price
2025-07-12 09:54:47,915 - INFO - Using cached data for Price
2025-07-12 09:54:47,915 - INFO - Using cached data for Price
2025-07-12 09:54:47,916 - INFO - Loading container data from sheet
2025-07-12 09:54:47,916 - INFO - Using cached data for Transfer
2025-07-12 09:54:48,088 - INFO - Using cached data for Client
2025-07-12 09:54:48,090 - INFO - Using cached data for Client
2025-07-12 09:54:48,091 - INFO - Using cached data for Client
2025-07-12 09:54:48,091 - INFO - Using cached data for Client
2025-07-12 09:54:48,092 - INFO - Using cached data for Client
2025-07-12 09:54:48,093 - INFO - Using cached data for Client
2025-07-12 09:54:48,094 - INFO - Using cached data for Client
2025-07-12 09:54:48,096 - INFO - Using cached data for Client
2025-07-12 09:54:48,097 - INFO - Using cached data for Client
2025-07-12 09:54:48,098 - INFO - Using cached data for Client
2025-07-12 09:54:48,099 - INFO - Using cached data for Client
2025-07-12 09:54:48,102 - INFO - Using cached data for Client
2025-07-12 09:54:48,103 - INFO - Using cached data for Client
2025-07-12 09:54:48,518 - INFO - Using cached data for CCCSReport
2025-07-12 09:54:48,522 - INFO - Using cached data for Price
2025-07-12 09:54:48,522 - INFO - Using cached data for Price
2025-07-12 09:54:48,525 - INFO - Using cached data for Client
2025-07-12 09:54:48,668 - INFO - Using cached data for Price
2025-07-12 09:54:48,668 - INFO - Using cached data for Price
2025-07-12 09:54:48,698 - INFO - Using cached data for Price
2025-07-12 09:54:48,698 - INFO - Using cached data for Price
2025-07-12 09:54:48,822 - INFO - Using cached data for Price
2025-07-12 09:54:48,822 - INFO - Using cached data for Price
2025-07-12 09:54:48,884 - INFO - Using cached data for Price
2025-07-12 09:54:48,884 - INFO - Using cached data for Price
2025-07-12 09:54:48,899 - INFO - Using cached data for containerOperations
2025-07-12 09:54:48,902 - INFO - Using cached data for Price
2025-07-12 09:54:48,902 - INFO - Using cached data for Price
2025-07-12 09:54:48,914 - INFO - Using cached data for Price
2025-07-12 09:54:48,915 - INFO - Using cached data for Price
2025-07-12 09:54:49,399 - INFO - Using cached data for IPHSBycatchTransfer
2025-07-12 09:54:49,399 - INFO - Using cached data for IPHSBycatchTransfer
2025-07-12 09:54:49,400 - INFO - Using cached data for CCCSReport
2025-07-12 09:54:49,400 - INFO - Using cached data for IPHSBycatchTransfer
2025-07-12 09:54:49,401 - INFO - Using cached data for Price
2025-07-12 09:54:49,401 - INFO - Using cached data for Price
2025-07-12 09:54:49,610 - INFO - Using cached data for Price
2025-07-12 09:54:49,610 - INFO - Using cached data for Price
2025-07-12 09:54:52,400 - INFO - Using cached data for CCCSReport
2025-07-12 09:54:52,401 - INFO - Using cached data for Price
2025-07-12 09:54:52,401 - INFO - Using cached data for Price
2025-07-12 09:54:52,402 - INFO - Using cached data for containerOperations
2025-07-12 09:54:52,404 - INFO - Using cached data for Price
2025-07-12 09:54:52,404 - INFO - Using cached data for Price
2025-07-12 09:54:52,408 - INFO - Using cached data for Price
2025-07-12 09:54:52,409 - INFO - Using cached data for Price
2025-07-12 09:54:52,420 - INFO - Using cached data for CCCSReport
2025-07-12 09:54:52,422 - INFO - Using cached data for Price
2025-07-12 09:54:52,422 - INFO - Using cached data for Price
2025-07-12 09:54:52,422 - INFO - Using cached data for containerOperations
2025-07-12 09:54:52,426 - INFO - Using cached data for Price
2025-07-12 09:54:52,430 - INFO - Using cached data for Price
2025-07-12 09:54:52,437 - INFO - Processing all dataframe categories concurrently
2025-07-12 09:54:52,438 - INFO - Queueing category: emr
2025-07-12 09:54:52,438 - INFO - Queueing category: operations
2025-07-12 09:54:52,438 - INFO - Queueing category: netlist
2025-07-12 09:54:52,438 - INFO - Queueing category: bin_dispatch
2025-07-12 09:54:52,438 - INFO - Queueing category: shore_handling
2025-07-12 09:54:52,438 - INFO - Queueing category: stuffing
2025-07-12 09:54:52,438 - INFO - Queueing category: transport
2025-07-12 09:54:52,438 - INFO - Queueing category: miscellaneous
2025-07-12 09:54:52,438 - INFO - Processing dataframe shifting of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:52,438 - INFO - Collecting LazyFrame for shifting
2025-07-12 09:54:52,723 - ERROR - Error processing dataframe shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-07-12 09:54:52,724 - INFO - Processing dataframe washing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:52,724 - INFO - Collecting LazyFrame for washing
2025-07-12 09:54:52,789 - ERROR - Error processing dataframe washing: conversion from `str` to `enum` failed in column 'invoice_to' for 1 out of 79 values: ["AMIRANTE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-07-12 09:54:52,790 - INFO - Processing dataframe pti of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:52,790 - INFO - Collecting LazyFrame for pti
2025-07-12 09:54:52,999 - ERROR - Error processing dataframe pti: sub operation not supported for dtypes `str` and `str`
2025-07-12 09:54:52,999 - INFO - Processing dataframe ops of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:53,000 - INFO - Collecting LazyFrame for ops
2025-07-12 09:54:53,305 - INFO - Successfully processed dataframe ops
2025-07-12 09:54:53,306 - INFO - Writing to output/csv/ops.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:53,306 - INFO - Processing dataframe hatch_to_hatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:53,307 - INFO - Collecting LazyFrame for hatch_to_hatch
2025-07-12 09:54:53,750 - INFO - Successfully processed dataframe hatch_to_hatch
2025-07-12 09:54:53,750 - INFO - Writing to output/csv/hatch_to_hatch.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:53,751 - INFO - Processing dataframe net_list of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:53,751 - INFO - Collecting LazyFrame for net_list
2025-07-12 09:54:54,031 - INFO - Successfully processed dataframe net_list
2025-07-12 09:54:54,032 - INFO - Writing to output/csv/net_list.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,033 - INFO - Processing dataframe iot_container_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,033 - INFO - Collecting LazyFrame for iot_container_stuffing
2025-07-12 09:54:54,121 - INFO - Successfully processed dataframe iot_container_stuffing
2025-07-12 09:54:54,122 - INFO - Processing dataframe oss_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,122 - INFO - Collecting LazyFrame for oss_stuffing
2025-07-12 09:54:54,122 - INFO - Writing to output/csv/iot_container_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,188 - INFO - Successfully processed dataframe oss_stuffing
2025-07-12 09:54:54,188 - INFO - Writing to output/csv/oss_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,188 - INFO - Processing dataframe full_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,188 - INFO - Collecting LazyFrame for full_scows_transfer
2025-07-12 09:54:54,206 - ERROR - Error processing dataframe full_scows_transfer: conversion from `str` to `enum` failed in column 'customer' for 4 out of 25 values: ["ECHEBASTAR", "ECHEBASTAR", … "ECHEBASTAR"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-07-12 09:54:54,206 - INFO - Processing dataframe empty_scows_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,206 - INFO - Collecting LazyFrame for empty_scows_transfer
2025-07-12 09:54:54,209 - ERROR - Error processing dataframe empty_scows_transfer: conversion from `str` to `enum` failed in column 'customer' for 2 out of 24 values: ["ECHEBASTAR", "ECHEBASTAR"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-07-12 09:54:54,210 - INFO - Processing dataframe salt of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,210 - INFO - Collecting LazyFrame for salt
2025-07-12 09:54:54,238 - INFO - Successfully processed dataframe salt
2025-07-12 09:54:54,238 - INFO - Writing to output/csv/salt.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,238 - INFO - Processing dataframe forklift_salt of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,238 - INFO - Collecting LazyFrame for forklift_salt
2025-07-12 09:54:54,326 - INFO - Successfully processed dataframe forklift_salt
2025-07-12 09:54:54,326 - INFO - Writing to output/csv/forklift_salt.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,326 - INFO - Processing dataframe bin_tipping of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,350 - INFO - Collecting LazyFrame for bin_tipping
2025-07-12 09:54:54,352 - INFO - Successfully processed dataframe bin_tipping
2025-07-12 09:54:54,352 - INFO - Writing to output/csv/bin_tipping.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,352 - INFO - Processing dataframe pallet_liner of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,352 - INFO - Collecting LazyFrame for pallet_liner
2025-07-12 09:54:54,362 - INFO - Successfully processed dataframe pallet_liner
2025-07-12 09:54:54,362 - INFO - Writing to output/csv/pallet_liner.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,363 - INFO - Processing dataframe container_plugin of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,366 - INFO - Collecting LazyFrame for container_plugin
2025-07-12 09:54:54,404 - INFO - Successfully processed dataframe container_plugin
2025-07-12 09:54:54,405 - INFO - Successfully wrote ops to file
2025-07-12 09:54:54,405 - INFO - Writing to output/csv/container_plugin.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,406 - INFO - Successfully wrote hatch_to_hatch to file
2025-07-12 09:54:54,406 - INFO - Successfully wrote net_list to file
2025-07-12 09:54:54,406 - INFO - Successfully wrote iot_container_stuffing to file
2025-07-12 09:54:54,406 - INFO - Successfully wrote oss_stuffing to file
2025-07-12 09:54:54,407 - INFO - Successfully wrote salt to file
2025-07-12 09:54:54,407 - INFO - Successfully wrote forklift_salt to file
2025-07-12 09:54:54,407 - INFO - Successfully wrote bin_tipping to file
2025-07-12 09:54:54,407 - INFO - Successfully wrote pallet_liner to file
2025-07-12 09:54:54,407 - INFO - Processing dataframe shore_crane of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,407 - INFO - Collecting LazyFrame for shore_crane
2025-07-12 09:54:54,414 - ERROR - Error processing dataframe shore_crane: conversion from `str` to `time` failed in column 'overtime_hours' for 584 out of 584 values: ["00:00", "00:00", … "00:00"]
2025-07-12 09:54:54,414 - INFO - Processing dataframe transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,415 - INFO - Collecting LazyFrame for transfer
2025-07-12 09:54:54,423 - ERROR - Error processing dataframe transfer: conversion from `str` to `time` failed in column 'time_out' for 137 out of 137 values: ["15:12", "14:45", … "15:15"]
2025-07-12 09:54:54,424 - INFO - Processing dataframe scow_transfer of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,424 - INFO - Collecting LazyFrame for scow_transfer
2025-07-12 09:54:54,428 - ERROR - Error processing dataframe scow_transfer: conversion from `str` to `enum` failed in column 'customer' for 2 out of 24 values: ["ECHEBASTAR", "ECHEBASTAR"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-07-12 09:54:54,428 - INFO - Processing dataframe forklift of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,428 - INFO - Collecting LazyFrame for forklift
2025-07-12 09:54:54,439 - INFO - Successfully processed dataframe forklift
2025-07-12 09:54:54,440 - INFO - Processing dataframe static_loader of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,440 - INFO - Collecting LazyFrame for static_loader
2025-07-12 09:54:54,440 - INFO - Writing to output/csv/forklift.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,445 - INFO - Successfully processed dataframe static_loader
2025-07-12 09:54:54,445 - INFO - Writing to output/csv/static_loader.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,632 - INFO - Processing dataframe dispatch_to_cargo of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,633 - INFO - Collecting LazyFrame for dispatch_to_cargo
2025-07-12 09:54:54,646 - INFO - Successfully processed dataframe dispatch_to_cargo
2025-07-12 09:54:54,647 - INFO - Writing to output/csv/dispatch_to_cargo.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,647 - INFO - Processing dataframe truck_to_cccs of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,648 - INFO - Collecting LazyFrame for truck_to_cccs
2025-07-12 09:54:54,675 - INFO - Successfully processed dataframe truck_to_cccs
2025-07-12 09:54:54,676 - INFO - Writing to output/csv/truck_to_cccs.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,676 - INFO - Processing dataframe cross_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,677 - INFO - Collecting LazyFrame for cross_stuffing
2025-07-12 09:54:54,681 - INFO - Successfully processed dataframe cross_stuffing
2025-07-12 09:54:54,682 - INFO - Writing to output/csv/cross_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,682 - INFO - Processing dataframe cccs_stuffing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,683 - INFO - Collecting LazyFrame for cccs_stuffing
2025-07-12 09:54:54,699 - INFO - Successfully processed dataframe cccs_stuffing
2025-07-12 09:54:54,700 - INFO - Writing to output/csv/cccs_stuffing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,700 - INFO - Processing dataframe bycatch of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-12 09:54:54,701 - INFO - Collecting LazyFrame for bycatch
2025-07-12 09:54:54,757 - INFO - Successfully processed dataframe bycatch
2025-07-12 09:54:54,758 - INFO - Successfully wrote container_plugin to file
2025-07-12 09:54:54,758 - INFO - Successfully wrote forklift to file
2025-07-12 09:54:54,850 - INFO - Writing to output/csv/bycatch.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-12 09:54:54,850 - INFO - Successfully wrote dispatch_to_cargo to file
2025-07-12 09:54:54,851 - INFO - Successfully wrote truck_to_cccs to file
2025-07-12 09:54:54,852 - INFO - Successfully wrote static_loader to file
2025-07-12 09:54:54,852 - INFO - Successfully wrote cross_stuffing to file
2025-07-12 09:54:54,852 - INFO - Successfully wrote cccs_stuffing to file
2025-07-12 09:54:55,055 - INFO - Successfully wrote bycatch to file
2025-07-12 09:54:55,055 - ERROR - Error saving shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-07-12 09:54:55,055 - ERROR - Error saving washing: conversion from `str` to `enum` failed in column 'invoice_to' for 1 out of 79 values: ["AMIRANTE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-07-12 09:54:55,056 - ERROR - Error saving pti: sub operation not supported for dtypes `str` and `str`
2025-07-12 09:54:55,056 - INFO - Successfully saved ops
2025-07-12 09:54:55,056 - INFO - Successfully saved hatch_to_hatch
2025-07-12 09:54:55,056 - INFO - Successfully saved net_list
2025-07-12 09:54:55,056 - INFO - Successfully saved iot_container_stuffing
2025-07-12 09:54:55,056 - INFO - Successfully saved oss_stuffing
2025-07-12 09:54:55,056 - ERROR - Error saving full_scows_transfer: conversion from `str` to `enum` failed in column 'customer' for 4 out of 25 values: ["ECHEBASTAR", "ECHEBASTAR", … "ECHEBASTAR"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-07-12 09:54:55,056 - ERROR - Error saving empty_scows_transfer: conversion from `str` to `enum` failed in column 'customer' for 2 out of 24 values: ["ECHEBASTAR", "ECHEBASTAR"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-07-12 09:54:55,056 - INFO - Successfully saved salt
2025-07-12 09:54:55,056 - INFO - Successfully saved forklift_salt
2025-07-12 09:54:55,056 - INFO - Successfully saved bin_tipping
2025-07-12 09:54:55,056 - INFO - Successfully saved pallet_liner
2025-07-12 09:54:55,056 - INFO - Successfully saved container_plugin
2025-07-12 09:54:55,056 - ERROR - Error saving shore_crane: conversion from `str` to `time` failed in column 'overtime_hours' for 584 out of 584 values: ["00:00", "00:00", … "00:00"]
2025-07-12 09:54:55,056 - ERROR - Error saving transfer: conversion from `str` to `time` failed in column 'time_out' for 137 out of 137 values: ["15:12", "14:45", … "15:15"]
2025-07-12 09:54:55,056 - ERROR - Error saving scow_transfer: conversion from `str` to `enum` failed in column 'customer' for 2 out of 24 values: ["ECHEBASTAR", "ECHEBASTAR"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-07-12 09:54:55,056 - INFO - Successfully saved forklift
2025-07-12 09:54:55,056 - INFO - Successfully saved static_loader
2025-07-12 09:54:55,057 - INFO - Successfully saved dispatch_to_cargo
2025-07-12 09:54:55,057 - INFO - Successfully saved truck_to_cccs
2025-07-12 09:54:55,057 - INFO - Successfully saved cross_stuffing
2025-07-12 09:54:55,057 - INFO - Successfully saved cccs_stuffing
2025-07-12 09:54:55,057 - INFO - Successfully saved bycatch
2025-07-12 09:54:55,057 - INFO - Save completed
2025-07-12 09:54:55,057 - INFO - Successfully saved: 17 files
2025-07-12 09:54:55,057 - ERROR - Failed to save: 8 files
2025-07-12 09:54:55,057 - ERROR -   - shifting: 'is_in' cannot check for Date values in String data

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'sink' <---
 WITH_COLUMNS:
 [when(col("date").is_in([Series])).then(String(PH)).otherwise(col("date").dt.to_string()).alias("day_name")] 
  DF ["date", "container_number", "invoice_to", "service_remarks"]; PROJECT */4 COLUMNS
2025-07-12 09:54:55,057 - ERROR -   - washing: conversion from `str` to `enum` failed in column 'invoice_to' for 1 out of 79 values: ["AMIRANTE"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-07-12 09:54:55,057 - ERROR -   - pti: sub operation not supported for dtypes `str` and `str`
2025-07-12 09:54:55,057 - ERROR -   - full_scows_transfer: conversion from `str` to `enum` failed in column 'customer' for 4 out of 25 values: ["ECHEBASTAR", "ECHEBASTAR", … "ECHEBASTAR"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-07-12 09:54:55,057 - ERROR -   - empty_scows_transfer: conversion from `str` to `enum` failed in column 'customer' for 2 out of 24 values: ["ECHEBASTAR", "ECHEBASTAR"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-07-12 09:54:55,057 - ERROR -   - shore_crane: conversion from `str` to `time` failed in column 'overtime_hours' for 584 out of 584 values: ["00:00", "00:00", … "00:00"]
2025-07-12 09:54:55,057 - ERROR -   - transfer: conversion from `str` to `time` failed in column 'time_out' for 137 out of 137 values: ["15:12", "14:45", … "15:15"]
2025-07-12 09:54:55,057 - ERROR -   - scow_transfer: conversion from `str` to `enum` failed in column 'customer' for 2 out of 24 values: ["ECHEBASTAR", "ECHEBASTAR"]

Ensure that all values in the input column are present in the categories of the enum datatype.
2025-07-13 14:44:28,042 - INFO - Starting application
2025-07-13 14:44:28,052 - INFO - Clearing screen
2025-07-13 14:44:30,706 - INFO - Exiting application
2025-07-13 14:44:35,186 - DEBUG - Using selector: EpollSelector
2025-07-13 14:44:35,187 - INFO - Starting application
2025-07-13 14:44:35,188 - INFO - Clearing screen
2025-07-13 14:44:37,738 - INFO - Selected: Save files
2025-07-13 14:44:37,739 - INFO - Clearing screen
2025-07-13 14:44:41,897 - INFO - Initiating save operation for emr
2025-07-13 14:44:43,253 - INFO - Using cached data for Price
2025-07-13 14:44:43,332 - INFO - Using cached data for Price
2025-07-13 14:44:43,332 - INFO - Using cached data for Price
2025-07-13 14:44:43,341 - INFO - Using cached data for Price
2025-07-13 14:44:43,341 - INFO - Using cached data for Price
2025-07-13 14:44:43,348 - INFO - Using cached data for Price
2025-07-13 14:44:43,349 - INFO - Using cached data for Price
2025-07-13 14:44:43,464 - INFO - Using cached data for Price
2025-07-13 14:44:43,464 - INFO - Using cached data for Price
2025-07-13 14:44:43,469 - INFO - Using cached data for PTI
2025-07-13 14:44:43,469 - INFO - Using cached data for Price
2025-07-13 14:44:43,469 - INFO - Using cached data for Price
2025-07-13 14:44:43,473 - INFO - Using cached data for Price
2025-07-13 14:44:43,474 - INFO - Using cached data for Price
2025-07-13 14:44:43,478 - INFO - Loading container data from sheet
2025-07-13 14:44:43,505 - INFO - Loading container data from sheet
2025-07-13 14:44:43,776 - INFO - Loading container data from sheet
2025-07-13 14:44:43,859 - INFO - Using cached data for Price
2025-07-13 14:44:43,859 - INFO - Using cached data for Price
2025-07-13 14:44:44,051 - INFO - Using cached data for Price
2025-07-13 14:44:44,051 - INFO - Using cached data for Price
2025-07-13 14:44:44,125 - INFO - Loading container data from sheet
2025-07-13 14:44:44,159 - INFO - Using cached data for Price
2025-07-13 14:44:44,159 - INFO - Using cached data for Price
2025-07-13 14:44:44,212 - INFO - Using cached data for Client
2025-07-13 14:44:44,213 - INFO - Using cached data for Client
2025-07-13 14:44:44,213 - INFO - Using cached data for Client
2025-07-13 14:44:44,213 - INFO - Using cached data for Client
2025-07-13 14:44:44,213 - INFO - Using cached data for Client
2025-07-13 14:44:44,214 - INFO - Using cached data for Client
2025-07-13 14:44:44,214 - INFO - Using cached data for Client
2025-07-13 14:44:44,214 - INFO - Using cached data for Client
2025-07-13 14:44:44,215 - INFO - Using cached data for Client
2025-07-13 14:44:44,215 - INFO - Using cached data for Client
2025-07-13 14:44:44,215 - INFO - Using cached data for Client
2025-07-13 14:44:44,216 - INFO - Using cached data for Client
2025-07-13 14:44:44,216 - INFO - Using cached data for Client
2025-07-13 14:44:44,305 - INFO - Using cached data for Client
2025-07-13 14:44:44,333 - INFO - Loading container data from sheet
2025-07-13 14:44:44,461 - INFO - Loading container data from sheet
2025-07-13 14:44:44,542 - INFO - Using cached data for Price
2025-07-13 14:44:44,542 - INFO - Using cached data for Price
2025-07-13 14:44:44,774 - INFO - Using cached data for Price
2025-07-13 14:44:44,774 - INFO - Using cached data for Price
2025-07-13 14:44:44,876 - INFO - Using cached data for CCCSReport
2025-07-13 14:44:45,293 - INFO - Loading container data from sheet
2025-07-13 14:44:45,610 - INFO - Using cached data for IPHSBycatchTransfer
2025-07-13 14:44:45,612 - INFO - Using cached data for IPHSBycatchTransfer
2025-07-13 14:44:45,613 - INFO - Using cached data for CCCSReport
2025-07-13 14:44:45,615 - INFO - Using cached data for IPHSBycatchTransfer
2025-07-13 14:44:45,616 - INFO - Using cached data for Price
2025-07-13 14:44:45,616 - INFO - Using cached data for Price
2025-07-13 14:44:46,222 - INFO - Using cached data for Price
2025-07-13 14:44:46,283 - INFO - Using cached data for Price
2025-07-13 14:44:46,310 - INFO - Using cached data for Price
2025-07-13 14:44:46,310 - INFO - Using cached data for Price
2025-07-13 14:44:46,311 - INFO - Loading container data from sheet
2025-07-13 14:44:46,311 - INFO - Using cached data for Transfer
2025-07-13 14:44:46,375 - INFO - Using cached data for CCCSReport
2025-07-13 14:44:46,376 - INFO - Using cached data for Price
2025-07-13 14:44:46,376 - INFO - Using cached data for Price
2025-07-13 14:44:46,376 - INFO - Using cached data for containerOperations
2025-07-13 14:44:46,378 - INFO - Using cached data for Price
2025-07-13 14:44:46,379 - INFO - Using cached data for Price
2025-07-13 14:44:46,382 - INFO - Using cached data for Price
2025-07-13 14:44:46,382 - INFO - Using cached data for Price
2025-07-13 14:44:46,469 - INFO - Using cached data for CCCSReport
2025-07-13 14:44:46,470 - INFO - Using cached data for Price
2025-07-13 14:44:46,470 - INFO - Using cached data for Price
2025-07-13 14:44:46,471 - INFO - Using cached data for containerOperations
2025-07-13 14:44:46,473 - INFO - Using cached data for Price
2025-07-13 14:44:46,473 - INFO - Using cached data for Price
2025-07-13 14:44:46,508 - INFO - Using cached data for CCCSReport
2025-07-13 14:44:46,510 - INFO - Using cached data for Price
2025-07-13 14:44:46,510 - INFO - Using cached data for Price
2025-07-13 14:44:47,763 - INFO - Using cached data for Price
2025-07-13 14:44:47,763 - INFO - Using cached data for Price
2025-07-13 14:44:48,023 - INFO - Using cached data for Price
2025-07-13 14:44:48,023 - INFO - Using cached data for Price
2025-07-13 14:44:48,238 - INFO - Using cached data for Price
2025-07-13 14:44:48,238 - INFO - Using cached data for Price
2025-07-13 14:44:48,579 - INFO - Using cached data for Price
2025-07-13 14:44:48,579 - INFO - Using cached data for Price
2025-07-13 14:44:48,980 - INFO - Using cached data for Price
2025-07-13 14:44:48,981 - INFO - Using cached data for Price
2025-07-13 14:44:48,986 - INFO - Using cached data for Price
2025-07-13 14:44:48,987 - INFO - Using cached data for Price
2025-07-13 14:44:48,988 - INFO - Processing dataframe category: emr
2025-07-13 14:44:48,988 - INFO - Processing dataframes: ['shifting', 'washing', 'pti']
2025-07-13 14:44:48,989 - INFO - Processing dataframe shifting of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-13 14:44:48,989 - INFO - Collecting LazyFrame for shifting
2025-07-13 14:44:49,002 - INFO - Successfully processed dataframe shifting
2025-07-13 14:44:49,003 - INFO - Writing to output/csv/shifting.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-13 14:44:49,004 - INFO - Processing dataframe washing of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-13 14:44:49,004 - INFO - Collecting LazyFrame for washing
2025-07-13 14:44:49,038 - INFO - Successfully processed dataframe washing
2025-07-13 14:44:49,038 - INFO - Processing dataframe pti of type <class 'polars.lazyframe.frame.LazyFrame'>
2025-07-13 14:44:49,038 - INFO - Collecting LazyFrame for pti
2025-07-13 14:44:49,039 - INFO - Writing to output/csv/washing.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-13 14:44:49,101 - INFO - Successfully processed dataframe pti
2025-07-13 14:44:49,102 - INFO - Successfully wrote shifting to file
2025-07-13 14:44:49,102 - INFO - Writing to output/csv/pti.csv, df type: <class 'polars.dataframe.frame.DataFrame'>
2025-07-13 14:44:49,103 - INFO - Successfully wrote washing to file
2025-07-13 14:44:49,111 - INFO - Successfully wrote pti to file
2025-07-13 14:44:49,111 - INFO - Successfully saved shifting
2025-07-13 14:44:49,111 - INFO - Successfully saved washing
2025-07-13 14:44:49,111 - INFO - Successfully saved pti
2025-07-13 14:44:49,111 - INFO - Save completed
2025-07-13 14:44:49,111 - INFO - Successfully saved: shifting, washing, pti
